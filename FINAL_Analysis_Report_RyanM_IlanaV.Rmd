---
title: "Marketing Faculty Evaluation Final Analysis"
author: "Ryan McCollum and Ilana Vinnik"
date: "2024-10-02"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
if (!require("knitr")) install.packages("knitr")
if (!require("ggplot2")) install.packages("ggplot2")
if (!require("dplyr")) install.packages("dplyr")
if (!require("tidyverse")) install.packages("tidyverse")
if (!require("gridExtra")) install.packages("gridExtra")
if (!require("ggcorrplot")) install.packages("ggcorrplot")
if (!require("viridis")) install.packages("viridis")
if (!require("pheatmap")) install.packages("pheatmap")
if (!require("ggrepel")) install.packages("ggrepel")
if (!require("tidymodels")) install.packages("tidymodels")
if (!require("car")) install.packages("car")
if (!require("ShapleyValue")) install.packages("ShapleyValue")
if (!require("lme4")) install.packages("lme4")
if(!require("kableExtra")) install.packages("kableExtra")
if (!require("broom.mixed")) install.packages("broom.mixed")
if(!require("gt")) install.packages("gt")
if(!require("sjPlot")) install.packages("sjPlot")
library(knitr)
library(kableExtra)
library(ggplot2)
library(dplyr)
library(tidyverse)
library(gridExtra)
library(rstatix)
library(gridExtra)
library(ggcorrplot)
library(viridis)
library(pheatmap)
library(ggrepel)
library(tidymodels)
library(car)
library(ShapleyValue)

# May need to run this if lme4 isnt loading properly
#utils::install.packages("lme4", type = "source")
library(lme4)
library(lmerTest)
library(broom.mixed)
library(gt)
library(sjPlot)
```


# Introduction
Every year marketing professors at Miami University send out end of course evaluation forms. These forms include 14 instructor performance based questions, 6 student behavioral based questions and a final question rating the instructors overall performance throughout the course. All questions are asked on an integer scale from 0 to 4, with 0 being 'never' and 4 being 'always'. Labels and descriptions of each question are included in figure 01 below. These evaluations were collected from 2013 to 2017 for all marketing courses in 4 different course types: FSB core; MKT core; MKT elective; and MKT capstone. The data is collected in the form of overall course ratings, so each individual students response is not recorded, but instead the classes overall average rating for each question asked. 
The Marketing department is interested in 3 different questions pertaining to this data. The main question of the analyzation is to look into which questions relate the most to overall teacher performance. A bar chart created by the marketing department shows the average scores for 9 of the teacher questions in 2016 next to the overall rating, and the overall rating is about .2 smaller than all other ratings. Why is the overall rating on average the lowest and does this make sense? The analysis will look into which, if any, instructor performance questions can significantly predict the overall rating, then again to look at the student behavioral questions separately. Lastly, whether or not the type of course the students are partaking in being a significant predictor of instructor score, or in other words does the type of course the students are enrolled in effect the overall instructor score, or even which questions become significant?



### Figure 01: Instructor (i) and Student (s) Survery Questions
```{r, echo=FALSE}
###### NOTE IF YOU DO NOT HAVE IMAGES SAVED YOU WILL NEED TO CUT OUT THIS PORTION


knitr::include_graphics('C:/DESKTOP/SEMESTER 7/STA 660/MKT Faculty Evaluation Investigation/TeacherQuestions.jpg') 
knitr::include_graphics('C:/DESKTOP/SEMESTER 7/STA 660/MKT Faculty Evaluation Investigation/StudentQuestions.jpg') 

## Could not get website upload to work
#knitr::include_graphics('https://tinypic.host/image/TeacherQuestions.2Pz0X1')

```



# Methodology

## Data
As briefly mentioned before, this data set includes all marketing courses from 2013-2017, the instructor identifier, the number of students enrolled and that completed the evaluation, and then the average rating for each question asked. Although each question is asked and rated on an integer scale, the data displays continuous data, due to averaging all student responses. This data was collected through official University evaluations, and includes the entire population of marketing classes taught in the given years, so there is no reason to worry about whether the data was randomly collected or not. Summary statistics such as the mean and variance of each score are displayed in table 01, and it is evident that all questions have similar average ratings and standard deviations. Also, the average class size is around 32 students (standard deviation of 17.13), but only about 19 students complete the evaluation on average (standard deviation 11.05). Due to the possibility of course averages being 0, likely due to no students filling out an evaluation for a course, and other potential worries of averaging small sample sizes, this study only encapsulates courses with at least 6 completed evaluations. This way, courses with a small number of overall students are not completely ignored, but they must have a good completion percentage to stay in the study.
However, there is a big issue with the data and that is multicollinearity. Without any data exploration, we can assume that average ratings will be highly correlated, as if a professor does a good job with the questions they ask, then they likely are doing a good job at challenging the students as an example. This multicollinearity is displayed in figure 02 with high correlation values. Mostly these high correlations are seen between pairs of instructor variables and pairs of student variables. This analysis attempts to fix multicollinearity, as well as testing different methods for evaluating questions as predictors of overall instructor rating and comparing to see if results are similar.


```{r, include=FALSE}
#### Load in data


# Immediately, want at least 6 completed surveys or 75% completion rate (lowest class enrollment is 8, would give 6 out of 8)
MKTRaw <- read.csv("C:/DESKTOP/SEMESTER 7/STA 660/MKT Faculty Evaluation Investigation/CombinedData.csv") 


shapleyi <- read.csv("C:/DESKTOP/SEMESTER 7/STA 660/MKT Faculty Evaluation Investigation/ShapleyDatai.csv", header=TRUE) %>%
  rename(iChallenged = iChalleneged)

MKTRaw <- MKTRaw %>%
  mutate(CompRate = Completed/Enrolled) %>%
  filter(CompRate > .75 | Completed >= 6)

```

 

### Table 01: Summary Statistics
```{r, echo=FALSE, message=FALSE}
## Summary Statistics and correlation plots
MKTSumStats <- MKTRaw %>% select(-Term, -InstID, -CourseType) %>%
 summarise(across(where(is.numeric), .fns = 
                     list(Mean = mean,
                          Stdev = sd,
                          Min = min,
                          Q25 = ~quantile(., 0.25),
                          Median = median,
                          Q75 = ~quantile(., 0.75),
                          Max = max))) %>%
  pivot_longer(everything(), names_sep='_', names_to=c('Variable', '.value')) %>%
  mutate(Mean = round(Mean, digits=2),
         Stdev = round(Stdev, digits=2))

kable(MKTSumStats, booktabs = TRUE) %>%
  kable_styling(font_size = 8)
```




## Methods
Building one model based off of standardized variables and assuming the resulting beta coefficients are completely accurate does not seem appropriate with the amount of multicollinearity. One model on one data set may have some randomization as to which variables are chosen to have greater beta coefficients due to high correlations between variables. For this reason, it may be appropriate to bootstrap the data, or repeatedly build the same model on new sets of data that are random samples with replacement of the original data.
There are multiple potential approaches to dealing with the issue that independence between courses cannot be assumed. The first is to group all courses of one instructor together and averaging the scores for each variable, taking into account how many students completed the evaluation as a weight when averaging. However, when separating by course type, the data set becomes small (around 20 observations) so bootstrapping results become irrelevant. The other option, and the one chosen in this analysis is to fit a model with the instructor ID as an added random effect. When creating a model for each course type, the models tested are as follows:

*Instructor Question Model*
$$iRating = \beta_{1}si_{AnalyProb} + \beta_{1}si_{AnalyProb} +\beta_{2}si_{AskQues} +\beta_{3}si_{Challenged} +$$
$$\beta_{4}si_{Concepts} +\beta_{5}si_{Demo} +\beta_{6}si_{Enthusiasm} +\beta_{7}si_{Hours} +\beta_{8}si_{Participate} +\beta_{9}si_{Prepared} +$$
$$\beta_{10}si_{QuesEffect} +\beta_{11}si_{Standards} +\beta_{12}si_{Topic} +\beta_{13}si_{Understand} +\beta_{14}si_{WelQues} + \lambda_{1}InstID$$
Where "si" stands for standardized instructor questions and the lambda effect is that of the random effect of the instructor id. 

*Student Question Model*
$$iRating = \beta_{1}si_{AnalyProb} + \beta_{1}ss_{Attended} +\beta_{2}ss_{Engaged} +\beta_{3}ss_{Help} +$$
$$\beta_{4}ss_{Prepared} +\beta_{5}ss_{Positive} +\beta_{6}ss_{UpToDate} + \lambda_{1}InstID$$ 
Where "ss" stands for standardized student questions and the lambda effect is that of the random effect of the instructor id. 

Since the objective of modeling and bootstrapping is to get the mean and variance of each coefficient over 1000 models, the significance level of the coefficients is not particularly of interest. However when looking at models that include course type as a predictor, and for all other reasons, the level of significant will be set at $\alpha = 0.05$. 

When modeling to see if course type is a significant predictor, the model is built as follows:
*Course Type Model*
$$iRating = \beta_{1}si_{AnalyProb} + \beta_{1}si_{AnalyProb} +\beta_{2}si_{AskQues} +\beta_{3}si_{Challenged} +\beta_{4}si_{Concepts} +$$
$$\beta_{5}si_{Demo} +\beta_{6}si_{Enthusiasm} +\beta_{7}si_{Hours} +\beta_{8}si_{Participate} +\beta_{9}si_{Prepared} +$$
$$\beta_{10}si_{QuesEffect} +\beta_{11}si_{Standards} +\beta_{12}si_{Topic} +\beta_{13}si_{Understand} +\beta_{14}si_{WelQues} +$$
$$ + \beta_{15}ss_{Attended} +\beta_{16}ss_{Engaged} +\beta_{17}ss_{Help} +$$
$$\beta_{18}ss_{Prepared} +\beta_{19}ss_{Positive} +\beta_{20}ss_{UpToDate}$$ 
$$\beta_{21}CourseType2 +\beta_{22}CourseType3 +\beta_{23}CourseType4+ \lambda_{1}InstID$$
The limitations of this approach is that it assumes that by standardizing the coefficients and using instructor ID as a random effect will make the average coefficients balance out to show which questions are most significant over 1000 models despite the issue of multicollinearity. While standardizing does not help VIFs, as shown later, the hope is that by replicating the same model, correlations between variables balance out over time, and that since all variables are distributed the same then their coefficients can be directly compared. This also requires a lot of computer processing, since 8 models are fit 1000 times, with 2 models for each course type and within each course type 1 instructor variable model and 1 student variable model. This also does not account the final model that uses course type as a predictor. 


```{r, include=FALSE, warning=FALSE, echo=FALSE}

# Standardizing



## Grouping by CourseType

  #Weighting and then Standardizing:

# Step 2: Standardize the weighted variables
# Standardize all the weighted instructor and student behavior variables
CT <- MKTRaw  %>%
  group_by(CourseType) %>%
  rename(eInstID = InstID) %>%
  mutate(CourseType = factor(CourseType))


# Step 1: Weight the variables by the number of completed evaluations
# Create a new dataframe with weighted variables
WeightedData <- CT %>%
  mutate(across(starts_with("i"), ~ .x * Completed, .names = "w_{col}")) %>%
  mutate(across(starts_with("s"), ~ .x * Completed, .names = "w_{col}"))

# Step 2: Standardize the variables
# Standardize all the weighted instructor and student behavior variables
## FOR EACH COURSE TYPE
CTStdz_1 <- WeightedData %>%
  filter(CourseType==1) %>%
  mutate(across(starts_with("i"), ~ (scale(.x))[,1], .names = "s_{col}"),
         across(starts_with("s"), ~(scale(.x))[,1], .names = "s_{col}"),
         weights = Completed/sum(Completed)) %>%
  select(iRating, s_iAnalyProb, s_iAskQues, s_iChallenged, s_iConcepts, s_iDemo, s_iEnthusiasm, s_iHours, s_iParticipate, s_iPrepared, s_iQuesEffect, s_iStandards, s_iTopic, s_iUnderstand, s_iWelQues, s_sAttended, s_sEngaged, s_sHelp,  s_sPrepared, s_sPositive, s_sUpToDate, Completed, eInstID, weights)


CTStdz_2 <- WeightedData %>%
  filter(CourseType==2) %>%
  mutate(across(starts_with("i"), ~ (scale(.x))[,1], .names = "s_{col}"),
         across(starts_with("s"), ~(scale(.x))[,1], .names = "s_{col}"),
         weights = Completed/sum(Completed)) %>%
  select(iRating, s_iAnalyProb, s_iAskQues, s_iChallenged, s_iConcepts, s_iDemo, s_iEnthusiasm, s_iHours, s_iParticipate, s_iPrepared, s_iQuesEffect, s_iStandards, s_iTopic, s_iUnderstand, s_iWelQues, s_sAttended, s_sEngaged, s_sHelp,  s_sPrepared, s_sPositive, s_sUpToDate, Completed, eInstID, weights)


CTStdz_3 <- WeightedData %>%
  filter(CourseType==3) %>%
  mutate(across(starts_with("i"), ~ (scale(.x))[,1], .names = "s_{col}"),
         across(starts_with("s"), ~(scale(.x))[,1], .names = "s_{col}"),
         weights = Completed/sum(Completed)) %>%
  select(iRating, s_iAnalyProb, s_iAskQues, s_iChallenged, s_iConcepts, s_iDemo, s_iEnthusiasm, s_iHours, s_iParticipate, s_iPrepared, s_iQuesEffect, s_iStandards, s_iTopic, s_iUnderstand, s_iWelQues, s_sAttended, s_sEngaged, s_sHelp,  s_sPrepared, s_sPositive, s_sUpToDate, Completed, eInstID, weights)


CTStdz_4 <- WeightedData %>%
  filter(CourseType==4) %>%
  mutate(across(starts_with("i"), ~ (scale(.x))[,1], .names = "s_{col}"),
         across(starts_with("s"), ~(scale(.x))[,1], .names = "s_{col}"),
         weights = Completed/sum(Completed)) %>%
  select(iRating, s_iAnalyProb, s_iAskQues, s_iChallenged, s_iConcepts, s_iDemo, s_iEnthusiasm, s_iHours, s_iParticipate, s_iPrepared, s_iQuesEffect, s_iStandards, s_iTopic, s_iUnderstand, s_iWelQues, s_sAttended, s_sEngaged, s_sHelp,  s_sPrepared, s_sPositive, s_sUpToDate, Completed, eInstID, weights)
# Now, "std_weighted_*" columns contain standardized values


CTStdz_all <- WeightedData %>%
  mutate(across(starts_with("i"), ~ (scale(.x))[,1], .names = "s_{col}"),
         across(starts_with("s"), ~(scale(.x))[,1], .names = "s_{col}"),
         weights = Completed/sum(Completed)) %>%
  select(iRating, s_iAnalyProb, s_iAskQues, s_iChallenged, s_iConcepts, s_iDemo, s_iEnthusiasm, s_iHours, s_iParticipate, s_iPrepared, s_iQuesEffect, s_iStandards, s_iTopic, s_iUnderstand, s_iWelQues, s_sAttended, s_sEngaged, s_sHelp,  s_sPrepared, s_sPositive, s_sUpToDate, Completed, eInstID, weights)

# View a sample of the data

# Get the names of all standardized variables except the target variable
#CTStdz_i1 <- CTStdz_1 %>%
#  select(-s_sAttended, -s_sEngaged, -s_sHelp,  -s_sPrepared, -s_sPositive, -s_sUpToDate)
#predictor_vars_i <- names(CTStdz_i1)[grepl("^s_", names(CTStdz_i1)) & names(CTStdz_i1) != "std_iRating"]
#CTStdz_s1 <- CTStdz_1 %>%
#  select(s_sAttended, s_sEngaged, s_sHelp,  s_sPrepared, s_sPositive, s_sUpToDate, eInstID, Completed)
#predictor_vars_s <- names(CTStdz_s1)[grepl("^s_", names(CTStdz_s1)) & names(CTStdz_s1) != "s_iRating"]

```

### Table 02: VIF Comparison: Standardized Model vs Not Standardized
```{r, echo=FALSE, include=5}


model.CT1i  <- lmer(iRating ~ ((s_iAnalyProb+ s_iAskQues+ s_iChallenged+ s_iConcepts+ s_iDemo + s_iEnthusiasm+ s_iHours+ s_iParticipate+ s_iPrepared+ s_iQuesEffect+ s_iStandards+ s_iTopic+ s_iUnderstand+ s_iWelQues) + (1 | eInstID)), weights=weights, data = CTStdz_1)
#summary(model.CT1i)

## Create CourseType 1 data set to show difference
CT1_vifTest <- MKTRaw  %>%
  filter(CourseType==1) %>%
  mutate(weights = Completed/sum(Completed))

model.CT1i_noStdz  <- lmer(iRating ~ ((iAnalyProb+ iAskQues+ iChallenged+ iConcepts+ iDemo + iEnthusiasm+ iHours+ iParticipate+ iPrepared+ iQuesEffect+ iStandards+ iTopic+ iUnderstand+ iWelQues) + (1 | InstID)), weights=weights, data = CT1_vifTest)
#summary(model.CT1i_noStdz)

# Calculate VIF values and compare
vif_values_stdz <- vif(model.CT1i)
vif_values_reg <-vif(model.CT1i_noStdz)
vifComp <- data.frame(Standardized = vif_values_stdz, Regular=vif_values_reg) %>%
  mutate(Difference = Standardized-Regular)

kable(vifComp, booktabs = TRUE) %>%
  kable_styling(font_size = 8)
```
As displayed in table 02, standardizing does not help with the VIF values at all, which means that it is not reducing multicoliniearity, the biggest concern of this data. However, it still transforms all variables to the same scale and distribution, so that their coefficients can be directly compared when modeling.


## Software References
R Core Team (2024). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria.
Wickham, H. (2016). ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York.
Wickham, H., et al. (2019). Welcome to the tidyverse. Journal of Open Source Software, 4(43), 1686.
Auguie, B. (2017). gridExtra: Miscellaneous Functions for "Grid" Graphics. R package version 2.3.
Kassambara, A. (2019). ggcorrplot: Visualization of a Correlation Matrix using 'ggplot2'. R package version 0.1.3.
Kolde, R. (2019). pheatmap: Pretty Heatmaps. R package version 1.0.12.
Garnier, S. (2018). viridis: Default Color Maps from 'matplotlib'. R package version 0.5.1.
Slowikowski, K. (2022). ggrepel: Automatically Position Non-Overlapping Text Labels with 'ggplot2'. R package version 0.9.1.
Kuhn, M., & Wickham, H. (2020). tidymodels: A Collection of Packages for Modeling and Machine Learning using Tidyverse Principles. R package version 0.1.1.
Bates, D., Mächler, M., Bolker, B., & Walker, S. (2015). Fitting Linear Mixed-Effects Models Using lme4. Journal of Statistical Software, 67(1), 1-48.
Fox, J., & Weisberg, S. (2019). An R Companion to Applied Regression. Sage Publications.
Azzalini, A. (2022). ShapleyValue: Implementation of the Shapley Value. R package version 0.1.
```{r, include=FALSE, message=FALSE, echo=FALSE}
citation('knitr')
citation('kableExtra')
citation('ggplot2')
citation('dplyr')
citation('tidyverse')
citation('gridExtra')
citation('rstatix')
citation('ggcorrplot')
citation('viridis')
citation('pheatmap')
citation('ggrepel')
citation('tidymodels')
citation('car')
citation('ShapleyValue')
citation('lme4')
```



# Results

## Descriptive Statistics

The initial analysis provided a general overview of the dataset, including the distribution of instructor and student evaluation scores, response rates, and other key variables. Summary statistics revealed that the mean overall instructor rating was approximately 3.5 on a 4-point scale, with a standard deviation of 0.6 seen in Table 01. Similarly, student-related variables such as engagement, attendance, and preparedness showed positive skewness, indicating that most students rated these aspects highly. These descriptive statistics laid the groundwork for further investigation into relationships between instructor and student behaviors.


## Exploratory Data Analysis

The exploratory analysis revealed important patterns in the data, emphasizing the relationships between instructor performance and student behavior. Figure 02 shows a correlation heatmap that highlights strong correlations between variables related to instructor performance (like enthusiasm and preparedness) and student behaviors (like engagement and attendance). This suggests the presence of multicollinearity, an issue that needs to be addressed during the modeling phase to avoid interpretation difficulties.

The analysis was conducted separately for instructor-related and student-related variables to better understand how each group of factors influences overall instructor ratings. For example, the scatter plots in Figures 03 and 04 focus on the relationship between student ratings (e.g., how well-prepared students felt) and overall instructor ratings. These plots confirm a positive correlation, with most ratings clustered between 3 and 4. This finding suggests that student evaluations serve as strong predictors of instructor performance.

Additionally, Figure 04 shows that course type also influences the relationship between student ratings and instructor ratings. This insight indicates that different course types may lead to variations in how students rate their instructors, which is a critical factor to consider in the subsequent modeling phase.

By separating these two sets of variables (instructor- and student-related), we gain a clearer picture of how each independently and collectively influences instructor ratings across different types of courses.


### Figure 02: Correlation Plot

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Select numeric columns from the dataset
survey_data <- MKTRaw %>%
  select_if(is.numeric)

# Calculate the correlation matrix using complete observations
corr_matrix <- cor(survey_data, use = "complete.obs")

# Plot the heatmap with clustering
pheatmap(corr_matrix,
         clustering_distance_rows = "euclidean",  # Can be changed to "correlation" for a correlation-based distance
         clustering_distance_cols = "euclidean",
         clustering_method = "complete",          # Clustering method, e.g., "complete", "average", "single"
         color = viridis::viridis(100),           # Use the viridis color scale
         main = "Correlation Heatmap with Clustering",
         display_numbers = FALSE,                 # Remove numbers from the cells
         fontsize_row = 10,                       # Adjust row font size for readability
         fontsize_col = 10,                       # Adjust column font size for readability
         legend = TRUE                            # Display the color legend
)

```
Figure 02 displays the correlation between different variables in the dataset, with hierarchical clustering used to group related variables. High correlations between instructor performance metrics and student behavior-related questions suggest potential multicollinearity, which should be addressed during the modeling process.

### Figure 03: Scatter Plot: Instructor Rating Versus Average of Student Rating
```{r, echo=FALSE, warning=FALSE}

# Look at average student self eval scores versus teacher evaluation rating
MKTOverall <- MKTRaw %>%
  mutate(sRating = round((sPositive+sAttended+sPrepared+sEngaged+sUpToDate+sHelp)/6, digits=2),
         CourseType=factor(CourseType),
         TotaliRating = Completed*iRating,
         TotalsRating = Completed*sRating) %>%
# Notice if no one filled out evaluation, then scores are 0, can remove
  filter(Completed!=0)

ggplot(MKTOverall, aes(x=sRating, y=iRating, color=CourseType)) +
  geom_point()+
  theme_minimal() +
  scale_x_continuous(limits = c(0,4)) +
  scale_y_continuous(limits = c(0,4)) +
  labs(title="Student Self-Eval Average Rating versus Professors Rating",
       y="Instructor Rating",
       x="Student Average Rating")
```
Figure 03 shows that the average of all 6 student ratings across a class seems to have a positive correlation with the overall instructor rating. Most points are clumped between 3 and 4 for both ratings, and although there seems to be some outliers, this chart shows that student behavioral questions most likely can be used to explain the overall instructor rating.


### Figure 04: Student Rating vs Teacher Rating grouped by Instructor
```{r, echo=FALSE, message=FALSE, include=1, warning=FALSE}
## Grouping by professor
TeacherGroup <- MKTOverall %>%
  group_by(InstID, CourseType) %>%
  mutate(CompletedTotal = sum(Completed),
         iRatingTotal = sum(TotaliRating),
         iRatingAverage = iRatingTotal/CompletedTotal,
         sRatingTotal = sum(TotalsRating),
         sRatingAverage = sRatingTotal/CompletedTotal) %>%
  select(iRatingAverage, CompletedTotal, iRatingTotal, sRatingTotal, sRatingAverage, CourseType, InstID) %>%
  distinct()

TeacherGroup1 <- TeacherGroup %>% filter(CourseType==1)
TeacherGroup2 <- TeacherGroup %>% filter(CourseType==2)
TeacherGroup3 <- TeacherGroup %>% filter(CourseType==3)
TeacherGroup4 <- TeacherGroup %>% filter(CourseType==4)
#model1 <- lm(iRatingAverage~sRatingAverage, data=TeacherGroup1)
#summary(model1)
group1x <- 1.9883
group1start <- -4.3299 + 2.1777*group1x
group1end <- -4.3299 + 2.1777*4
#model2 <- lm(iRatingAverage~sRatingAverage, data=TeacherGroup2)
#summary(model2)
group2x <- 1.4
group2start <- -2.1017 + 1.5011*group2x
group2end <- -2.1017 + 1.5011*4
#model3 <- lm(iRatingAverage~sRatingAverage, data=TeacherGroup3)
#summary(model3)

group3x <- 0.7215
group3start <- -0.8469 + 1.1738*group3x
group3end <- -0.8469 + 1.1738*4
#model4 <- lm(iRatingAverage~sRatingAverage, data=TeacherGroup4)
#summary(model4)

group4x <- 2.7851
group4start <- -9.692 + 3.480*group4x
group4end <- -9.692 + 3.480*4

ggplot(data=TeacherGroup, aes(x=sRatingAverage, y=iRatingAverage, color=CourseType)) +
  geom_point() +
  theme_minimal() +
  scale_x_continuous(limits=c(0, 4)) +
  #scale_y_continuous(limits=c(0,4)) +
  labs(title="Student Self-Eval Average Rating versus Professors Rating",
  subtitle="Teacher and Student ratings averaged across all of a professors courses, with a regression line for each course type",
       y="Instructor Average Rating",
       x="Student Average Rating") +
  annotate(geom="segment", x=group1x, xend=4, y=group1start, yend=group1end, color="red", size=.75) +
  annotate(geom="segment", x=group2x, xend=4, y=group2start, yend=group2end, color="green", size=.75) +
  annotate(geom="segment", x=group3x, xend=4, y=group3start, yend=group3end, color="skyblue3", size=.75) +
  annotate(geom="segment", x=group4x, xend=4, y=group4start, yend=group4end, color="purple1", size=.75)
```

Another potential problem in the data set is that each instructor can appear multiple times for multiple courses, so assuming each course is independent would be naive. Figure 04 displays a similar scatter plot as seen in figure 03, except the points are now an aggregate of all courses taught by a professor. Additionally, regression lines are placed, one for each course type and it appears that the course type being taught has an effect on the relationship between the average student behavioral rating and the average overall instructor rating.



## Figure 05: Instructor Questions vs Instructor Rating Scatter Plots
```{r, echo=FALSE, message=FALSE, echo=FALSE, warning=FALSE}

plotAnalyProb <- ggplot(MKTOverall, aes(y=iRating, x=iAnalyProb, color=CourseType)) +
  geom_point() +
  theme_minimal() +
  theme(legend.position="none")
#  labs(title="Professors Overall Rating versus AnalyProb Rating",
#       y="Instructor Average Rating",
#       x="AnalyProb Rating")

plotChallenged <- ggplot(MKTOverall, aes(y=iRating, x=iChallenged, color=CourseType)) +
  geom_point() +
  theme_minimal() +
  theme(legend.position="none")
#  labs(title="Professors Overall Rating versus Challenged Rating",
#       y="Instructor Average Rating",
#       x="Challenged Rating")


plotConcepts <- ggplot(MKTOverall, aes(y=iRating, x=iConcepts, color=CourseType)) +
  geom_point() +
  theme_minimal() +
  theme(legend.position="none")
 # labs(title="Professors Overall Rating versus Concepts Rating",
#       y="Instructor Average Rating",
#       x="Concepts Rating")


plotDemo <- ggplot(MKTOverall, aes(y=iRating, x=iDemo, color=CourseType)) +
  geom_point() +
  theme_minimal() +
  theme(legend.position="none")
#  labs(title="Professors Overall Rating versus Demo Rating",
#       y="Instructor Average Rating",
#       x="Demo Rating")

plotHours <- ggplot(MKTOverall, aes(y=iRating, x=iHours, color=CourseType)) +
  geom_point() +
  theme_minimal() +
  theme(legend.position="none")
#  labs(title="Professors Overall Rating versus Hours Rating",
#       y="Instructor Average Rating",
#       x="Hours Rating")

plotParticipate <- ggplot(MKTOverall, aes(y=iRating, x=iParticipate, color=CourseType)) +
  geom_point() +
  theme_minimal() +
  theme(legend.position="none")
#  labs(title="Professors Overall Rating versus Participate Rating",
#       y="Instructor Average Rating",
#       x="Participate Rating")

plotPrepared <- ggplot(MKTOverall, aes(y=iRating, x=iPrepared, color=CourseType)) +
  geom_point() +
  theme_minimal() +
  theme(legend.position="none")
#  labs(title="Professors Overall Rating versus Prepared Rating",
#       y="Instructor Average Rating",
#       x="Prepared Rating")

plotQuesEffect <- ggplot(MKTOverall, aes(y=iRating, x=iQuesEffect, color=CourseType)) +
  geom_point() +
  theme_minimal() +
  theme(legend.position="none")
#  labs(title="Professors Overall Rating versus QuesEffect Rating",
#       y="Instructor Average Rating",
#       x="QuesEffect Rating")

plotStandards <- ggplot(MKTOverall, aes(y=iRating, x=iStandards, color=CourseType)) +
  geom_point() +
  theme_minimal() +
  theme(legend.position="none")
#  labs(title="Professors Overall Rating versus Standards Rating",
#       y="Instructor Average Rating",
#       x="Standards Rating")

plotTopic <- ggplot(MKTOverall, aes(y=iRating, x=iTopic, color=CourseType)) +
  geom_point() +
  theme_minimal() +
  theme(legend.position="none")
 # labs(title="Professors Overall Rating versus Topic Rating",
 #      y="Instructor Average Rating",
#       x="Topic Rating")

plotUnderstand <- ggplot(MKTOverall, aes(y=iRating, x=iUnderstand, color=CourseType)) +
  geom_point() +
  theme_minimal() +
  theme(legend.position="none")
  #labs(title="Professors Overall Rating versus Understand Rating",
 #      y="Instructor Average Rating",
 #      x="Understand Rating")

plotWelQues <- ggplot(MKTOverall, aes(y=iRating, x=iWelQues, color=CourseType)) +
  geom_point() +
  theme_minimal() +
  theme(legend.position="none")
 # labs(title="Professors Overall Rating versus WelQues Rating",
#       y="Instructor Average Rating",
 #      x="WelQues Rating")


grid.arrange(plotAnalyProb, plotChallenged,
plotConcepts,
plotDemo,
plotHours,
plotParticipate,
plotPrepared,
plotQuesEffect,
plotStandards,
plotTopic,
plotUnderstand,
plotWelQues,
ncol=3, nrow = 4)
```

Figure 05 show a seemingly strong positive correlation between all of the individual teacher performance variable and their relationship to the overall instructor rating. This shows that all variables could potentially be viable in a model to predict instructor rating. Similarly, the grid of plots that follows in 

## Figure 06: Student Questions vs Instructor Rating Scatter Plots
```{r, echo=FALSE, warning=FALSE}
plotAttended <- ggplot(MKTOverall, aes(y=iRating, x=sAttended, color=CourseType)) +
  geom_point() +
  theme_minimal() +
  theme(legend.position="none")
#  labs(title="Professors Overall Rating versus student Attended Rating",
#       y="Instructor Average Rating",
#       x="Prepared Rating")

plotEngaged <- ggplot(MKTOverall, aes(y=iRating, x=sEngaged, color=CourseType)) +
  geom_point() +
  theme_minimal() +
  theme(legend.position="none")
#  labs(title="Professors Overall Rating versus student Engaged Rating",
#       y="Instructor Average Rating",
#       x="QuesEffect Rating")

plotHelp <- ggplot(MKTOverall, aes(y=iRating, x=sHelp, color=CourseType)) +
  geom_point() +
  theme_minimal() +
  theme(legend.position="none")
#  labs(title="Professors Overall Rating versus student Help Rating",
#       y="Instructor Average Rating",
#       x="Standards Rating")

plotPrepared <- ggplot(MKTOverall, aes(y=iRating, x=sPrepared, color=CourseType)) +
  geom_point() +
  theme_minimal() +
  theme(legend.position="none")
 # labs(title="Professors Overall Rating versus student Prepared Rating",
 #      y="Instructor Average Rating",
#       x="Topic Rating")

plotPositive <- ggplot(MKTOverall, aes(y=iRating, x=sPositive, color=CourseType)) +
  geom_point() +
  theme_minimal() +
  theme(legend.position="none")
  #labs(title="Professors Overall Rating versus student Positive Rating",
 #      y="Instructor Average Rating",
 #      x="Understand Rating")

plotUpToDate <- ggplot(MKTOverall, aes(y=iRating, x=sUpToDate, color=CourseType)) +
  geom_point() +
  theme_minimal() +
  theme(legend.position="none")
 # labs(title="Professors Overall Rating versus student UpToDate Rating",
#       y="Instructor Average Rating",
 #      x="WelQues Rating")


grid.arrange(plotAttended, plotEngaged, plotHelp, plotPrepared, plotPositive, plotUpToDate,
ncol=2, nrow = 3)
```
Figure 06 shows the relationship between all individual student ratings and overal instructore rating, in which there appears to be a strong positive correlation for all of the variables again.


## Shapely Values

Shapley regression was discovered as a potential way to limit multicollinearity in model building through external research. It was performed separately for instructor-related and student-related variables to evaluate the contribution of each variable to the model's explanatory power. By running a regression model for every possible combination of predictors, Shapley values calculate the impact of each variable on the model’s R² using weighted averages, thereby identifying which variables contribute the most to improving the R².

For instructor-related variables, the analysis revealed that in Course Type 1, or FSB core courses, variables such as iDemo, iTopic, iEnthusiasm, and iParticipate were the most significant contributors to the model's R². These variables consistently showed a strong influence on instructor ratings across the iterations of the Shapley value calculation.

For student-related variables, Shapley values suggested that sPositive, sEngaged, and sHelp were the most impactful variables across all course types. However, like instructor variables, this analysis doesn't fully account for the potential dependence between courses, especially when the same instructors teach multiple courses, which might affect the independence of the predictors.

## Table 04: Instructor Variable Shapely Values
```{r, echo=FALSE, warning=FALSE}
#iRating <- CT1_vifTest$iRating
#x <- as.data.frame(CT1_vifTest[,12:26]) %>%
 # select(-iRating)
#shapleyvalue(iRating, x)
shapleyiTable <- shapleyi %>% pivot_longer(cols=c('iAnalyProb', 'iAskQues', 'iChallenged', 'iConcepts', 'iDemo', 'iEnthusiasm', 'iHours', 'iParticipate', 'iPrepared', 'iQuesEffect', 'iStandards', 'iTopic', 'iUnderstand', 'iWelQues'),
                          names_to="Variable",
                          values_to="Shapely") %>%
  arrange(desc(Shapely)) %>%
  filter(S=='Standardized Shapley Value')
kable(shapleyiTable)
```

### Table 05: Student Variable Shapely Values
```{r, echo=FALSE, warning=FALSE}
iRating <- CT1_vifTest$iRating
xs <- as.data.frame(CT1_vifTest[,6:11])
 # select(-iRating)
shapleys <- shapleyvalue(iRating, xs) %>%
  mutate(S = c('Shapely Value', 'Standardized Shapley Value'))
shapleysTable <- shapleys %>% pivot_longer(cols=c('sAttended', 'sEngaged', 'sHelp', 'sPositive', 'sPrepared', 'sUpToDate'),
                          names_to="Variable",
                          values_to="Shapely") %>%
  arrange(desc(Shapely)) %>%
  filter(S=='Standardized Shapley Value')
kable(shapleysTable)

```

## Model Building and Coefficient Testing


The models used to predict instructor ratings were fit separately for both instructor-related and student-related variables. This approach allowed us to better isolate the unique contributions of each set of variables. Both sets of models were tested using bootstrapping with 1000 iterations to obtain stable mean estimates of the beta coefficients. Despite the high multicollinearity detected in the exploratory analysis, replicating the model after standardizing the variables allowed for meaningful interpretation and comparison of the influence each variable had on overall instructor ratings.

For instructor-related variables, the best predictors for course type 1 were consistently iDemo, iTopic, iEnthusiasm, and iParticipate, while iPrepared emerged as the strongest predictor for course type 4, as shown in Figure 07. These variables consistently had large absolute beta coefficient values, indicating a strong influence on the instructor ratings for these course types. It is also interesting to see that all of the coefficients seemed to have similar variances depending on the course type. For FSB core courses, the standard deviation error bars are all similar in size and close to 0.025, where in the MKT capstone courses the error bars are much larger at around 0.08. In fact, the MKT capstone variances for each coefficient are so large, it may be worth additional investigation into the capstone courses specifically. It is also noticeable that across all course types there are no questions that rank in the top 25% of average coefficient value, but questions such as iAskQues, iHours, and iStandards are always in or very close to the bottom 25%, suggesting they are not very helpful in any course evaluations at predicting overall instructor rating.

On the other hand, the models that focused on student-related variables revealed in Figure 08 that sPositive and sEngaged were the best predictors across all course types, with the small exception that sPrepared was very slightly better than sEngaged in MKT elective courses. These two student variables showed consistently high absolute beta coefficients, suggesting their significant impact on instructor ratings regardless of the course type. Unlike in figure 07, no variables were in the bottom 25% on all 4 course types, but sHelp and sUpToDate appeared in the bottom 25% 3 out of 4 times. Also, the differences in standard deviation between course types are not as drastic as what is seen in the instructor variable plots, but MKT capstone courses still have the highest variability within coefficients out of all courses. 

Both figures mostly agree with what the Shapley values suggested were the most important predictors earlier. So the shapely analysis concurs with the bootstrap analysis findings.


```{r, message=FALSE, warning=FALSE, include=FALSE, echo=FALSE}
## Bootstrap 1000 models for CourseType 1 instructor variables


set.seed(09272024)

## Idea for full model
##full.modeli.1 <- lm(data=Teacher1Stdz, iRating ~ iAskQuesS + iAnalyProbS + iChallengedS + iConceptsS +iDemoS +iEnthusiasmS +iHoursS + iParticipateS + iPreparedS + iQuesEffectS + iStandardsS + iTopicS + iUnderstandS + iWelQuesS )
##summary(full.modeli.1)

## BOOTSRAPPING BY HAND

sample_coef_intercept <- NULL
sample_coef_df_x1 <- NULL
sample_coef_df_x2 <- NULL
sample_coef_df_x3 <- NULL
sample_coef_df_x4 <- NULL
sample_coef_df_x5 <- NULL
sample_coef_df_x6 <- NULL
sample_coef_df_x7 <- NULL
sample_coef_df_x8 <- NULL
sample_coef_df_x9 <- NULL
sample_coef_df_x10 <- NULL
sample_coef_df_x11 <- NULL
sample_coef_df_x12 <- NULL
sample_coef_df_x13 <- NULL
sample_coef_df_x14 <- NULL


for (i in 1:1000) {
  #Creating a resampled dataset from the sample data
  sample_d = CTStdz_1[sample(1:nrow(CTStdz_1), nrow(CTStdz_1), replace = TRUE), ]
 # sample_d_totalcompleted <-  sample_d %>% summarize(totalcomp = sum(Completed))
  sample_d_w <- sample_d %>%
    mutate(weight = Completed/sum(Completed))
  
  #Running the regression on these data
  model_bootstrap  <- lmer(iRating ~ ((s_iAnalyProb+ s_iAskQues+ s_iChallenged+ s_iConcepts+ s_iDemo + s_iEnthusiasm+ s_iHours+ s_iParticipate+ s_iPrepared+ s_iQuesEffect+ s_iStandards+ s_iTopic+ s_iUnderstand+ s_iWelQues) + (1 | eInstID)), weights=weight, data = sample_d_w)
  bootsum <- summary(model_bootstrap)
  
    #Saving the coefficients
  sample_coef_intercept <-
    c(sample_coef_intercept, bootsum$coefficients[1])
  
  sample_coef_df_x1 <- c(sample_coef_df_x1, bootsum$coefficients[2])
  sample_coef_df_x2 <- c(sample_coef_df_x2, bootsum$coefficients[3])
  sample_coef_df_x3 <- c(sample_coef_df_x3, bootsum$coefficients[4])
  sample_coef_df_x4 <- c(sample_coef_df_x4, bootsum$coefficients[5])
  sample_coef_df_x5 <- c(sample_coef_df_x5, bootsum$coefficients[6])
  sample_coef_df_x6 <- c(sample_coef_df_x6, bootsum$coefficients[7])
  sample_coef_df_x7 <- c(sample_coef_df_x7, bootsum$coefficients[8])
  sample_coef_df_x8 <- c(sample_coef_df_x8, bootsum$coefficients[9])
  sample_coef_df_x9 <- c(sample_coef_df_x9, bootsum$coefficients[10])
  sample_coef_df_x10 <- c(sample_coef_df_x10, bootsum$coefficients[11])
  sample_coef_df_x11 <- c(sample_coef_df_x11, bootsum$coefficients[12])
  sample_coef_df_x12 <- c(sample_coef_df_x12, bootsum$coefficients[13])
  sample_coef_df_x13 <- c(sample_coef_df_x13, bootsum$coefficients[14])
  sample_coef_df_x14 <- c(sample_coef_df_x14, bootsum$coefficients[15])
}

## Want ABSOLUTE values to show overall affect on iRating (-.3 has as much of an effect as .3)
absCoefsDF <- data.frame(iAnalyProbC=abs(sample_coef_df_x1), 
                      iAskQuesC=abs(sample_coef_df_x2),
                      iChallengedC=abs(sample_coef_df_x3),
                      iConceptsC=abs(sample_coef_df_x4),
                      iDemoC=abs(sample_coef_df_x5),
                      iEnthusiasmC=abs(sample_coef_df_x6),
                      iHoursC=abs(sample_coef_df_x7),
                      iParticipateC=abs(sample_coef_df_x8),
                      iPreparedC=abs(sample_coef_df_x9),
                      iQuesEffectC=abs(sample_coef_df_x10),
                      iStandardsC=abs(sample_coef_df_x11),
                      iTopicC=abs(sample_coef_df_x12),
                      iUnderstandC=abs(sample_coef_df_x13),
                      iWelQuesC=abs(sample_coef_df_x14))

BootstrapData <- absCoefsDF %>%
  summarize(meaniAnalyProbC = mean(iAnalyProbC), variAnalyProbC = var(iAnalyProbC),q1iAnalyProbC = quantile(iAnalyProbC, probs=.25), q2iAnalyProbC = quantile(iAnalyProbC, probs=.5), q3iAnalyProbC = quantile(iAnalyProbC, probs=.75),
            meaniAskQuesC = mean(iAskQuesC), variAskQuesC = var(iAskQuesC), q1iAskQuesC = quantile(iAskQuesC, probs=.25), q2iAskQuesC = quantile(iAskQuesC, probs=.5), q3iAskQuesC = quantile(iAskQuesC, probs=.75),
            meaniChallengedC = mean(iChallengedC), variChallengedC = var(iChallengedC), q1iChallengedC = quantile(iChallengedC, probs=.25), q2iChallengedC = quantile(iChallengedC, probs=.5), q3iChallengedC = quantile(iChallengedC, probs=.75),
            meaniConceptsC = mean(iConceptsC), variConceptsC = var(iConceptsC), q1iConceptsC = quantile(iConceptsC, probs=.25), q2iConceptsC = quantile(iConceptsC, probs=.5), q3iConceptsC = quantile(iConceptsC, probs=.75),
            meaniDemoC = mean(iDemoC), variDemoC = var(iDemoC), q1iDemoC = quantile(iDemoC, probs=.25), q2iDemoC = quantile(iDemoC, probs=.5), q3iDemoC = quantile(iDemoC, probs=.75), 
            meaniEnthusiasmC = mean(iEnthusiasmC), variEnthusiasmC = var(iEnthusiasmC), q1iEnthusiasmC = quantile(iEnthusiasmC, probs=.25), q2iEnthusiasmC = quantile(iEnthusiasmC, probs=.5), q3iEnthusiasmC = quantile(iEnthusiasmC, probs=.75),
            meaniHoursC = mean(iHoursC), variHoursC = var(iHoursC), q1iHoursC = quantile(iHoursC, probs=.25), q2iHoursC = quantile(iHoursC, probs=.5), q3iHoursC = quantile(iHoursC, probs=.75),
            meaniParticipateC = mean(iParticipateC), variParticipateC = var(iParticipateC), q1iParticipateC = quantile(iParticipateC, probs=.25), q2iParticipateC = quantile(iParticipateC, probs=.5), q3iParticipateC = quantile(iParticipateC, probs=.75),
            meaniPreparedC = mean(iPreparedC), variPreparedC = var(iPreparedC), q1iPreparedC = quantile(iPreparedC, probs=.25), q2iPreparedC = quantile(iPreparedC, probs=.5), q3iPreparedC = quantile(iPreparedC, probs=.75),
            meaniQuesEffectC = mean(iQuesEffectC), variQuesEffectC = var(iQuesEffectC), q1iQuesEffectC = quantile(iQuesEffectC, probs=.25), q2iQuesEffectC = quantile(iQuesEffectC, probs=.5), q3iQuesEffectC = quantile(iQuesEffectC, probs=.75),
            meaniStandardsC = mean(iStandardsC), variStandardsC = var(iStandardsC), q1iStandardsC = quantile(iStandardsC, probs=.25),  q2iStandardsC = quantile(iStandardsC, probs=.5), q3iStandardsC = quantile(iStandardsC, probs=.75),
            meaniTopicC = mean(iTopicC), variTopicC = var(iTopicC), q1iTopicC = quantile(iTopicC, probs=.25), q2iTopicC = quantile(iTopicC, probs=.5), q3iTopicC = quantile(iTopicC, probs=.75),
            meaniUnderstandC = mean(iUnderstandC), variUnderstandC = var(iUnderstandC), q1iUnderstandC = quantile(iUnderstandC, probs=.25), q2iUnderstandC = quantile(iUnderstandC, probs=.5), q3iUnderstandC = quantile(iUnderstandC, probs=.75),
            meaniWelQuesC = mean(iWelQuesC), variWelQuesC = var(iWelQuesC), q1iWelQuesC = quantile(iWelQuesC, probs=.25), q2iWelQuesC = quantile(iWelQuesC, probs=.5), q3iWelQuesC = quantile(iWelQuesC, probs=.75))

# Pivot Data
LBootstrapData <- BootstrapData%>% pivot_longer(cols=c(meaniAnalyProbC,  meaniAskQuesC, meaniChallengedC , meaniConceptsC,  meaniDemoC, meaniEnthusiasmC, meaniHoursC, meaniParticipateC, meaniPreparedC, meaniQuesEffectC, meaniStandardsC, meaniTopicC, meaniUnderstandC, meaniWelQuesC),
                                        names_to='Variable1',
                                        values_to='Mean')
## Pivot again for variance
LBootstrapData <- LBootstrapData %>% pivot_longer(cols=c(variAnalyProbC, variAskQuesC,  variChallengedC ,  variConceptsC, variDemoC, variEnthusiasmC, variHoursC, variParticipateC, variPreparedC, variQuesEffectC, variStandardsC, variTopicC , variUnderstandC, variWelQuesC),
                                        names_to='Variable2',
                                        values_to='Variance') %>%
  
  select(Variable1, Variable2, Variance, Mean) %>%
  mutate(Variable_1 = str_replace(Variable1, "mean", ""),
         Variable_2 = str_replace(Variable2, "var", "")) %>%
  filter(Variable_2==Variable_1) %>%
  rename(Variable=Variable_1) %>%
  select(Variable, Mean, Variance) %>%
  mutate(x=c(1,2,3,4,5,6,7,8,9,10,11,12,13,14))
```



```{r, message=FALSE, warning=FALSE, include=FALSE, echo=FALSE}
# Plotting Averages i, coursetyp 1
# Plotting Coursetype 1 instructor vars
quantiles <- quantile(abs(LBootstrapData$Mean), probs=c(.25, .75))


CT1iplot <- ggplot(data=LBootstrapData, aes(y=abs(Mean), x=x)) +
  geom_point()  +
  geom_errorbar(aes(ymin=Mean-sqrt(Variance), ymax=Mean+sqrt(Variance)), width=.3) +
  geom_label_repel(aes(label=Variable)) +
  #geom_jitter(height=0, width=.5) +
  theme_minimal() +
  scale_x_continuous(breaks = (7),
                     minor_breaks= NULL,
                     labels=("Separation Factor"))+
  annotate("rect", xmin=-1, xmax=15, ymin=0, ymax=quantiles[1], fill="red", alpha=.2) +
  annotate("rect", xmin=-1, xmax=15, ymin=quantiles[1], ymax=quantiles[2], fill="yellow", alpha=.2) +
  annotate("rect", xmin=-1, xmax=15, ymin=quantiles[2], ymax=.27, fill="green", alpha=.2) +
  annotate('text', x=1.5, y=(quantiles[2]+.1), label="Top 25% of Coefficients", color='forestgreen') +
  annotate('text', x=1.5, y=(quantiles[2]+.09), label="Middle 50% of Coefficients", color='yellow4') +
  annotate('text', x=1.5, y=(quantiles[2]+.08), label="Bottom 25% of Coefficients", color='firebrick4') +
  labs(title='Beta Coefficient Averages of Standardized test Variables for FSB Core Instructors',
       subtitle='Ignoring horizontal placement, variables with the highest absolute value of their beta coefficient have\n the largest affect on a teachers rating when all variables are treated on the same scale',
       y="Average of Absolute Value of Beta Coefficients of Standardized\n Questions and 1 Standard Deviation Above and Below the Mean",
       x="Values do not Matter, Just here to Separate Coefficeint Averages in Alphabetical Order")

```



```{r, message=FALSE, warning=FALSE, include=FALSE, echo=FALSE}
set.seed(09272024)

# Bootsrtapping Model for Overall Rating Using Standardized Predictors for CourseType 2 Instructor Questions


## BOOTSRAPPING BY HAND

sample_coef_intercept <- NULL
sample_coef_df_x1 <- NULL
sample_coef_df_x2 <- NULL
sample_coef_df_x3 <- NULL
sample_coef_df_x4 <- NULL
sample_coef_df_x5 <- NULL
sample_coef_df_x6 <- NULL
sample_coef_df_x7 <- NULL
sample_coef_df_x8 <- NULL
sample_coef_df_x9 <- NULL
sample_coef_df_x10 <- NULL
sample_coef_df_x11 <- NULL
sample_coef_df_x12 <- NULL
sample_coef_df_x13 <- NULL
sample_coef_df_x14 <- NULL


for (i in 1:1000) {
  #Creating a resampled dataset from the sample data
  sample_d = CTStdz_2[sample(1:nrow(CTStdz_2), nrow(CTStdz_2), replace = TRUE), ]
 # sample_d_totalcompleted <-  sample_d %>% summarize(totalcomp = sum(Completed))
  sample_d_w <- sample_d %>%
    mutate(weight = Completed/sum(Completed))
  
  #Running the regression on these data
  model_bootstrap  <- lmer(iRating ~ ((s_iAnalyProb+ s_iAskQues+ s_iChallenged+ s_iConcepts+ s_iDemo + s_iEnthusiasm+ s_iHours+ s_iParticipate+ s_iPrepared+ s_iQuesEffect+ s_iStandards+ s_iTopic+ s_iUnderstand+ s_iWelQues) + (1 | eInstID)), weights=weight, data = sample_d_w)
  bootsum <- summary(model_bootstrap)
  
    #Saving the coefficients
  sample_coef_intercept <-
    c(sample_coef_intercept, bootsum$coefficients[1])
  
  sample_coef_df_x1 <- c(sample_coef_df_x1, bootsum$coefficients[2])
  sample_coef_df_x2 <- c(sample_coef_df_x2, bootsum$coefficients[3])
  sample_coef_df_x3 <- c(sample_coef_df_x3, bootsum$coefficients[4])
  sample_coef_df_x4 <- c(sample_coef_df_x4, bootsum$coefficients[5])
  sample_coef_df_x5 <- c(sample_coef_df_x5, bootsum$coefficients[6])
  sample_coef_df_x6 <- c(sample_coef_df_x6, bootsum$coefficients[7])
  sample_coef_df_x7 <- c(sample_coef_df_x7, bootsum$coefficients[8])
  sample_coef_df_x8 <- c(sample_coef_df_x8, bootsum$coefficients[9])
  sample_coef_df_x9 <- c(sample_coef_df_x9, bootsum$coefficients[10])
  sample_coef_df_x10 <- c(sample_coef_df_x10, bootsum$coefficients[11])
  sample_coef_df_x11 <- c(sample_coef_df_x11, bootsum$coefficients[12])
  sample_coef_df_x12 <- c(sample_coef_df_x12, bootsum$coefficients[13])
  sample_coef_df_x13 <- c(sample_coef_df_x13, bootsum$coefficients[14])
  sample_coef_df_x14 <- c(sample_coef_df_x14, bootsum$coefficients[15])
}

## Want ABSOLUTE values to show overall affect on iRating (-.3 has as much of an effect as .3)
absCoefsDF <- data.frame(iAnalyProbC=abs(sample_coef_df_x1), 
                      iAskQuesC=abs(sample_coef_df_x2),
                      iChallengedC=abs(sample_coef_df_x3),
                      iConceptsC=abs(sample_coef_df_x4),
                      iDemoC=abs(sample_coef_df_x5),
                      iEnthusiasmC=abs(sample_coef_df_x6),
                      iHoursC=abs(sample_coef_df_x7),
                      iParticipateC=abs(sample_coef_df_x8),
                      iPreparedC=abs(sample_coef_df_x9),
                      iQuesEffectC=abs(sample_coef_df_x10),
                      iStandardsC=abs(sample_coef_df_x11),
                      iTopicC=abs(sample_coef_df_x12),
                      iUnderstandC=abs(sample_coef_df_x13),
                      iWelQuesC=abs(sample_coef_df_x14))

BootstrapData <- absCoefsDF %>%
  summarize(meaniAnalyProbC = mean(iAnalyProbC), variAnalyProbC = var(iAnalyProbC),q1iAnalyProbC = quantile(iAnalyProbC, probs=.25), q2iAnalyProbC = quantile(iAnalyProbC, probs=.5), q3iAnalyProbC = quantile(iAnalyProbC, probs=.75),
            meaniAskQuesC = mean(iAskQuesC), variAskQuesC = var(iAskQuesC), q1iAskQuesC = quantile(iAskQuesC, probs=.25), q2iAskQuesC = quantile(iAskQuesC, probs=.5), q3iAskQuesC = quantile(iAskQuesC, probs=.75),
            meaniChallengedC = mean(iChallengedC), variChallengedC = var(iChallengedC), q1iChallengedC = quantile(iChallengedC, probs=.25), q2iChallengedC = quantile(iChallengedC, probs=.5), q3iChallengedC = quantile(iChallengedC, probs=.75),
            meaniConceptsC = mean(iConceptsC), variConceptsC = var(iConceptsC), q1iConceptsC = quantile(iConceptsC, probs=.25), q2iConceptsC = quantile(iConceptsC, probs=.5), q3iConceptsC = quantile(iConceptsC, probs=.75),
            meaniDemoC = mean(iDemoC), variDemoC = var(iDemoC), q1iDemoC = quantile(iDemoC, probs=.25), q2iDemoC = quantile(iDemoC, probs=.5), q3iDemoC = quantile(iDemoC, probs=.75), 
            meaniEnthusiasmC = mean(iEnthusiasmC), variEnthusiasmC = var(iEnthusiasmC), q1iEnthusiasmC = quantile(iEnthusiasmC, probs=.25), q2iEnthusiasmC = quantile(iEnthusiasmC, probs=.5), q3iEnthusiasmC = quantile(iEnthusiasmC, probs=.75),
            meaniHoursC = mean(iHoursC), variHoursC = var(iHoursC), q1iHoursC = quantile(iHoursC, probs=.25), q2iHoursC = quantile(iHoursC, probs=.5), q3iHoursC = quantile(iHoursC, probs=.75),
            meaniParticipateC = mean(iParticipateC), variParticipateC = var(iParticipateC), q1iParticipateC = quantile(iParticipateC, probs=.25), q2iParticipateC = quantile(iParticipateC, probs=.5), q3iParticipateC = quantile(iParticipateC, probs=.75),
            meaniPreparedC = mean(iPreparedC), variPreparedC = var(iPreparedC), q1iPreparedC = quantile(iPreparedC, probs=.25), q2iPreparedC = quantile(iPreparedC, probs=.5), q3iPreparedC = quantile(iPreparedC, probs=.75),
            meaniQuesEffectC = mean(iQuesEffectC), variQuesEffectC = var(iQuesEffectC), q1iQuesEffectC = quantile(iQuesEffectC, probs=.25), q2iQuesEffectC = quantile(iQuesEffectC, probs=.5), q3iQuesEffectC = quantile(iQuesEffectC, probs=.75),
            meaniStandardsC = mean(iStandardsC), variStandardsC = var(iStandardsC), q1iStandardsC = quantile(iStandardsC, probs=.25),  q2iStandardsC = quantile(iStandardsC, probs=.5), q3iStandardsC = quantile(iStandardsC, probs=.75),
            meaniTopicC = mean(iTopicC), variTopicC = var(iTopicC), q1iTopicC = quantile(iTopicC, probs=.25), q2iTopicC = quantile(iTopicC, probs=.5), q3iTopicC = quantile(iTopicC, probs=.75),
            meaniUnderstandC = mean(iUnderstandC), variUnderstandC = var(iUnderstandC), q1iUnderstandC = quantile(iUnderstandC, probs=.25), q2iUnderstandC = quantile(iUnderstandC, probs=.5), q3iUnderstandC = quantile(iUnderstandC, probs=.75),
            meaniWelQuesC = mean(iWelQuesC), variWelQuesC = var(iWelQuesC), q1iWelQuesC = quantile(iWelQuesC, probs=.25), q2iWelQuesC = quantile(iWelQuesC, probs=.5), q3iWelQuesC = quantile(iWelQuesC, probs=.75))

# Pivot Data
LBootstrapData <- BootstrapData %>% pivot_longer(cols=c(meaniAnalyProbC,  meaniAskQuesC, meaniChallengedC , meaniConceptsC,  meaniDemoC, meaniEnthusiasmC, meaniHoursC, meaniParticipateC, meaniPreparedC, meaniQuesEffectC, meaniStandardsC, meaniTopicC, meaniUnderstandC, meaniWelQuesC),
                                        names_to='Variable1',
                                        values_to='Mean')
## Pivot again for variance
LBootstrapData <- LBootstrapData %>% pivot_longer(cols=c(variAnalyProbC, variAskQuesC,  variChallengedC ,  variConceptsC, variDemoC, variEnthusiasmC, variHoursC, variParticipateC, variPreparedC, variQuesEffectC, variStandardsC, variTopicC , variUnderstandC, variWelQuesC),
                                        names_to='Variable2',
                                        values_to='Variance') %>%
  
  select(Variable1, Variable2, Variance, Mean) %>%
  mutate(Variable_1 = str_replace(Variable1, "mean", ""),
         Variable_2 = str_replace(Variable2, "var", "")) %>%
  filter(Variable_2==Variable_1) %>%
  rename(Variable=Variable_1) %>%
  select(Variable, Mean, Variance) %>%
  mutate(x=c(1,2,3,4,5,6,7,8,9,10,11,12,13,14))
```



```{r, message=FALSE, warning=FALSE, include=FALSE, echo=FALSE}
# Plotting Averages i, coursetpy 2



quantiles <- quantile(abs(LBootstrapData$Mean), probs=c(.25, .75))


CT2iplot <-  ggplot(data=LBootstrapData, aes(y=abs(Mean), x=x)) +
  geom_point()  +
  geom_label_repel(aes(label=Variable)) +
  geom_errorbar(aes(ymin=Mean-sqrt(Variance), ymax=Mean+sqrt(Variance)), width=.3) +
  #geom_jitter(height=0, width=.5) +
  theme_minimal() +
  scale_x_continuous(breaks = (7),
                     minor_breaks= NULL,
                     labels=("Separation Factor"))+
  annotate("rect", xmin=-1, xmax=15, ymin=0, ymax=quantiles[1], fill="red", alpha=.2) +
  annotate("rect", xmin=-1, xmax=15, ymin=quantiles[1], ymax=quantiles[2], fill="yellow", alpha=.2) +
  annotate("rect", xmin=-1, xmax=15, ymin=quantiles[2], ymax=.27, fill="green", alpha=.2) +
  #annotate('text', x=.5, y=(quantiles[2]-.05), label="Top 25% of Coefficients", color='forestgreen') +
  #annotate('text', x=.5, y=(quantiles[2]-.04), label="Middle 50% of Coefficients", color='yellow4') +
  #annotate('text', x=.5, y=(quantiles[2]-.03), label="Bottom 25% of Coefficients", color='firebrick4') +
  labs(title="MKT Core Courses",
       x="",
       y="")

```



```{r, message=FALSE, warning=FALSE, include=FALSE, echo=FALSE}


# Boostrap Model for Overall Rating Using Standardized Predictors for CourseType 3 Instructor Questions

set.seed(09272024)

## BOOTSRAPPING BY HAND

sample_coef_intercept <- NULL
sample_coef_df_x1 <- NULL
sample_coef_df_x2 <- NULL
sample_coef_df_x3 <- NULL
sample_coef_df_x4 <- NULL
sample_coef_df_x5 <- NULL
sample_coef_df_x6 <- NULL
sample_coef_df_x7 <- NULL
sample_coef_df_x8 <- NULL
sample_coef_df_x9 <- NULL
sample_coef_df_x10 <- NULL
sample_coef_df_x11 <- NULL
sample_coef_df_x12 <- NULL
sample_coef_df_x13 <- NULL
sample_coef_df_x14 <- NULL


for (i in 1:1000) {
  #Creating a resampled dataset from the sample data
  sample_d = CTStdz_3[sample(1:nrow(CTStdz_3), nrow(CTStdz_3), replace = TRUE), ]
 # sample_d_totalcompleted <-  sample_d %>% summarize(totalcomp = sum(Completed))
  sample_d_w <- sample_d %>%
    mutate(weight = Completed/sum(Completed))
  
  #Running the regression on these data
  model_bootstrap  <- lmer(iRating ~ ((s_iAnalyProb+ s_iAskQues+ s_iChallenged+ s_iConcepts+ s_iDemo + s_iEnthusiasm+ s_iHours+ s_iParticipate+ s_iPrepared+ s_iQuesEffect+ s_iStandards+ s_iTopic+ s_iUnderstand+ s_iWelQues) + (1 | eInstID)), weights=weight, data = sample_d_w)
  bootsum <- summary(model_bootstrap)
  
    #Saving the coefficients
  sample_coef_intercept <-
    c(sample_coef_intercept, bootsum$coefficients[1])
  
  sample_coef_df_x1 <- c(sample_coef_df_x1, bootsum$coefficients[2])
  sample_coef_df_x2 <- c(sample_coef_df_x2, bootsum$coefficients[3])
  sample_coef_df_x3 <- c(sample_coef_df_x3, bootsum$coefficients[4])
  sample_coef_df_x4 <- c(sample_coef_df_x4, bootsum$coefficients[5])
  sample_coef_df_x5 <- c(sample_coef_df_x5, bootsum$coefficients[6])
  sample_coef_df_x6 <- c(sample_coef_df_x6, bootsum$coefficients[7])
  sample_coef_df_x7 <- c(sample_coef_df_x7, bootsum$coefficients[8])
  sample_coef_df_x8 <- c(sample_coef_df_x8, bootsum$coefficients[9])
  sample_coef_df_x9 <- c(sample_coef_df_x9, bootsum$coefficients[10])
  sample_coef_df_x10 <- c(sample_coef_df_x10, bootsum$coefficients[11])
  sample_coef_df_x11 <- c(sample_coef_df_x11, bootsum$coefficients[12])
  sample_coef_df_x12 <- c(sample_coef_df_x12, bootsum$coefficients[13])
  sample_coef_df_x13 <- c(sample_coef_df_x13, bootsum$coefficients[14])
  sample_coef_df_x14 <- c(sample_coef_df_x14, bootsum$coefficients[15])
}

## Want ABSOLUTE values to show overall affect on iRating (-.3 has as much of an effect as .3)
absCoefsDF <- data.frame(iAnalyProbC=abs(sample_coef_df_x1), 
                      iAskQuesC=abs(sample_coef_df_x2),
                      iChallengedC=abs(sample_coef_df_x3),
                      iConceptsC=abs(sample_coef_df_x4),
                      iDemoC=abs(sample_coef_df_x5),
                      iEnthusiasmC=abs(sample_coef_df_x6),
                      iHoursC=abs(sample_coef_df_x7),
                      iParticipateC=abs(sample_coef_df_x8),
                      iPreparedC=abs(sample_coef_df_x9),
                      iQuesEffectC=abs(sample_coef_df_x10),
                      iStandardsC=abs(sample_coef_df_x11),
                      iTopicC=abs(sample_coef_df_x12),
                      iUnderstandC=abs(sample_coef_df_x13),
                      iWelQuesC=abs(sample_coef_df_x14))

BootstrapData <- absCoefsDF %>%
  summarize(meaniAnalyProbC = mean(iAnalyProbC), variAnalyProbC = var(iAnalyProbC),q1iAnalyProbC = quantile(iAnalyProbC, probs=.25), q2iAnalyProbC = quantile(iAnalyProbC, probs=.5), q3iAnalyProbC = quantile(iAnalyProbC, probs=.75),
            meaniAskQuesC = mean(iAskQuesC), variAskQuesC = var(iAskQuesC), q1iAskQuesC = quantile(iAskQuesC, probs=.25), q2iAskQuesC = quantile(iAskQuesC, probs=.5), q3iAskQuesC = quantile(iAskQuesC, probs=.75),
            meaniChallengedC = mean(iChallengedC), variChallengedC = var(iChallengedC), q1iChallengedC = quantile(iChallengedC, probs=.25), q2iChallengedC = quantile(iChallengedC, probs=.5), q3iChallengedC = quantile(iChallengedC, probs=.75),
            meaniConceptsC = mean(iConceptsC), variConceptsC = var(iConceptsC), q1iConceptsC = quantile(iConceptsC, probs=.25), q2iConceptsC = quantile(iConceptsC, probs=.5), q3iConceptsC = quantile(iConceptsC, probs=.75),
            meaniDemoC = mean(iDemoC), variDemoC = var(iDemoC), q1iDemoC = quantile(iDemoC, probs=.25), q2iDemoC = quantile(iDemoC, probs=.5), q3iDemoC = quantile(iDemoC, probs=.75), 
            meaniEnthusiasmC = mean(iEnthusiasmC), variEnthusiasmC = var(iEnthusiasmC), q1iEnthusiasmC = quantile(iEnthusiasmC, probs=.25), q2iEnthusiasmC = quantile(iEnthusiasmC, probs=.5), q3iEnthusiasmC = quantile(iEnthusiasmC, probs=.75),
            meaniHoursC = mean(iHoursC), variHoursC = var(iHoursC), q1iHoursC = quantile(iHoursC, probs=.25), q2iHoursC = quantile(iHoursC, probs=.5), q3iHoursC = quantile(iHoursC, probs=.75),
            meaniParticipateC = mean(iParticipateC), variParticipateC = var(iParticipateC), q1iParticipateC = quantile(iParticipateC, probs=.25), q2iParticipateC = quantile(iParticipateC, probs=.5), q3iParticipateC = quantile(iParticipateC, probs=.75),
            meaniPreparedC = mean(iPreparedC), variPreparedC = var(iPreparedC), q1iPreparedC = quantile(iPreparedC, probs=.25), q2iPreparedC = quantile(iPreparedC, probs=.5), q3iPreparedC = quantile(iPreparedC, probs=.75),
            meaniQuesEffectC = mean(iQuesEffectC), variQuesEffectC = var(iQuesEffectC), q1iQuesEffectC = quantile(iQuesEffectC, probs=.25), q2iQuesEffectC = quantile(iQuesEffectC, probs=.5), q3iQuesEffectC = quantile(iQuesEffectC, probs=.75),
            meaniStandardsC = mean(iStandardsC), variStandardsC = var(iStandardsC), q1iStandardsC = quantile(iStandardsC, probs=.25),  q2iStandardsC = quantile(iStandardsC, probs=.5), q3iStandardsC = quantile(iStandardsC, probs=.75),
            meaniTopicC = mean(iTopicC), variTopicC = var(iTopicC), q1iTopicC = quantile(iTopicC, probs=.25), q2iTopicC = quantile(iTopicC, probs=.5), q3iTopicC = quantile(iTopicC, probs=.75),
            meaniUnderstandC = mean(iUnderstandC), variUnderstandC = var(iUnderstandC), q1iUnderstandC = quantile(iUnderstandC, probs=.25), q2iUnderstandC = quantile(iUnderstandC, probs=.5), q3iUnderstandC = quantile(iUnderstandC, probs=.75),
            meaniWelQuesC = mean(iWelQuesC), variWelQuesC = var(iWelQuesC), q1iWelQuesC = quantile(iWelQuesC, probs=.25), q2iWelQuesC = quantile(iWelQuesC, probs=.5), q3iWelQuesC = quantile(iWelQuesC, probs=.75))

# Pivot Data
LBootstrapData <- BootstrapData %>% pivot_longer(cols=c(meaniAnalyProbC,  meaniAskQuesC, meaniChallengedC , meaniConceptsC,  meaniDemoC, meaniEnthusiasmC, meaniHoursC, meaniParticipateC, meaniPreparedC, meaniQuesEffectC, meaniStandardsC, meaniTopicC, meaniUnderstandC, meaniWelQuesC),
                                        names_to='Variable1',
                                        values_to='Mean')
## Pivot again for variance
LBootstrapData <- LBootstrapData %>% pivot_longer(cols=c(variAnalyProbC, variAskQuesC,  variChallengedC ,  variConceptsC, variDemoC, variEnthusiasmC, variHoursC, variParticipateC, variPreparedC, variQuesEffectC, variStandardsC, variTopicC , variUnderstandC, variWelQuesC),
                                        names_to='Variable2',
                                        values_to='Variance') %>%
  
  select(Variable1, Variable2, Variance, Mean) %>%
  mutate(Variable_1 = str_replace(Variable1, "mean", ""),
         Variable_2 = str_replace(Variable2, "var", "")) %>%
  filter(Variable_2==Variable_1) %>%
  rename(Variable=Variable_1) %>%
  select(Variable, Mean, Variance) %>%
  mutate(x=c(1,2,3,4,5,6,7,8,9,10,11,12,13,14))
```




```{r, message=FALSE, warning=FALSE, include=FALSE, echo=FALSE}

# Plot i vars for Coursetype 3

quantiles <- quantile(abs(LBootstrapData$Mean), probs=c(.25, .75))


CT3iplot <- ggplot(data=LBootstrapData, aes(y=abs(Mean), x=x)) +
  geom_point()  +
  geom_label_repel(aes(label=Variable)) +
  geom_errorbar(aes(ymin=Mean-sqrt(Variance), ymax=Mean+sqrt(Variance)), width=.3) +
  #geom_jitter(height=0, width=.5) +
  theme_minimal() +
  scale_x_continuous(breaks = (7),
                     minor_breaks= NULL,
                     labels=("Separation Factor"))+
  annotate("rect", xmin=-1, xmax=15, ymin=0, ymax=quantiles[1], fill="red", alpha=.2) +
  annotate("rect", xmin=-1, xmax=15, ymin=quantiles[1], ymax=quantiles[2], fill="yellow", alpha=.2) +
  annotate("rect", xmin=-1, xmax=15, ymin=quantiles[2], ymax=.27, fill="green", alpha=.2) +
  #annotate('text', x=1.5, y=(quantiles[2]+.1), label="Top 25% of Coefficients", color='forestgreen') +
  #annotate('text', x=1.5, y=(quantiles[2]+.09), label="Middle 50% of Coefficients", color='yellow4') +
  #annotate('text', x=1.5, y=(quantiles[2]+.08), label="Bottom 25% of Coefficients", color='firebrick4') +
  labs(title="MKT Elective Courses",
       x="",
       y="")

```



```{r, message=FALSE, warning=FALSE, include=FALSE, echo=FALSE}



# Bootstrap Model for Overall Rating Using Standardized Predictors for CourseType 4 Instructor Questions


set.seed(09272024)

## Idea for full model
##full.modeli.1 <- lm(data=Teacher1Stdz, iRating ~ iAskQuesS + iAnalyProbS + iChallengedS + iConceptsS +iDemoS +iEnthusiasmS +iHoursS + iParticipateS + iPreparedS + iQuesEffectS + iStandardsS + iTopicS + iUnderstandS + iWelQuesS )
##summary(full.modeli.1)

## BOOTSRAPPING BY HAND

sample_coef_intercept <- NULL
sample_coef_df_x1 <- NULL
sample_coef_df_x2 <- NULL
sample_coef_df_x3 <- NULL
sample_coef_df_x4 <- NULL
sample_coef_df_x5 <- NULL
sample_coef_df_x6 <- NULL
sample_coef_df_x7 <- NULL
sample_coef_df_x8 <- NULL
sample_coef_df_x9 <- NULL
sample_coef_df_x10 <- NULL
sample_coef_df_x11 <- NULL
sample_coef_df_x12 <- NULL
sample_coef_df_x13 <- NULL
sample_coef_df_x14 <- NULL


for (i in 1:1000) {
  #Creating a resampled dataset from the sample data
  sample_d = CTStdz_4[sample(1:nrow(CTStdz_4), nrow(CTStdz_4), replace = TRUE), ]
 # sample_d_totalcompleted <-  sample_d %>% summarize(totalcomp = sum(Completed))
  sample_d_w <- sample_d %>%
    mutate(weight = Completed/sum(Completed))
  
  #Running the regression on these data
  model_bootstrap  <- lmer(iRating ~ ((s_iAnalyProb+ s_iAskQues+ s_iChallenged+ s_iConcepts+ s_iDemo + s_iEnthusiasm+ s_iHours+ s_iParticipate+ s_iPrepared+ s_iQuesEffect+ s_iStandards+ s_iTopic+ s_iUnderstand+ s_iWelQues) + (1 | eInstID)), weights=weight, data = sample_d_w)
  bootsum <- summary(model_bootstrap)
  
    #Saving the coefficients
  sample_coef_intercept <-
    c(sample_coef_intercept, bootsum$coefficients[1])
  
  sample_coef_df_x1 <- c(sample_coef_df_x1, bootsum$coefficients[2])
  sample_coef_df_x2 <- c(sample_coef_df_x2, bootsum$coefficients[3])
  sample_coef_df_x3 <- c(sample_coef_df_x3, bootsum$coefficients[4])
  sample_coef_df_x4 <- c(sample_coef_df_x4, bootsum$coefficients[5])
  sample_coef_df_x5 <- c(sample_coef_df_x5, bootsum$coefficients[6])
  sample_coef_df_x6 <- c(sample_coef_df_x6, bootsum$coefficients[7])
  sample_coef_df_x7 <- c(sample_coef_df_x7, bootsum$coefficients[8])
  sample_coef_df_x8 <- c(sample_coef_df_x8, bootsum$coefficients[9])
  sample_coef_df_x9 <- c(sample_coef_df_x9, bootsum$coefficients[10])
  sample_coef_df_x10 <- c(sample_coef_df_x10, bootsum$coefficients[11])
  sample_coef_df_x11 <- c(sample_coef_df_x11, bootsum$coefficients[12])
  sample_coef_df_x12 <- c(sample_coef_df_x12, bootsum$coefficients[13])
  sample_coef_df_x13 <- c(sample_coef_df_x13, bootsum$coefficients[14])
  sample_coef_df_x14 <- c(sample_coef_df_x14, bootsum$coefficients[15])
}

## Want ABSOLUTE values to show overall affect on iRating (-.3 has as much of an effect as .3)
absCoefsDF <- data.frame(iAnalyProbC=abs(sample_coef_df_x1), 
                      iAskQuesC=abs(sample_coef_df_x2),
                      iChallengedC=abs(sample_coef_df_x3),
                      iConceptsC=abs(sample_coef_df_x4),
                      iDemoC=abs(sample_coef_df_x5),
                      iEnthusiasmC=abs(sample_coef_df_x6),
                      iHoursC=abs(sample_coef_df_x7),
                      iParticipateC=abs(sample_coef_df_x8),
                      iPreparedC=abs(sample_coef_df_x9),
                      iQuesEffectC=abs(sample_coef_df_x10),
                      iStandardsC=abs(sample_coef_df_x11),
                      iTopicC=abs(sample_coef_df_x12),
                      iUnderstandC=abs(sample_coef_df_x13),
                      iWelQuesC=abs(sample_coef_df_x14))

BootstrapData <- absCoefsDF %>%
  summarize(meaniAnalyProbC = mean(iAnalyProbC), variAnalyProbC = var(iAnalyProbC),q1iAnalyProbC = quantile(iAnalyProbC, probs=.25), q2iAnalyProbC = quantile(iAnalyProbC, probs=.5), q3iAnalyProbC = quantile(iAnalyProbC, probs=.75),
            meaniAskQuesC = mean(iAskQuesC), variAskQuesC = var(iAskQuesC), q1iAskQuesC = quantile(iAskQuesC, probs=.25), q2iAskQuesC = quantile(iAskQuesC, probs=.5), q3iAskQuesC = quantile(iAskQuesC, probs=.75),
            meaniChallengedC = mean(iChallengedC), variChallengedC = var(iChallengedC), q1iChallengedC = quantile(iChallengedC, probs=.25), q2iChallengedC = quantile(iChallengedC, probs=.5), q3iChallengedC = quantile(iChallengedC, probs=.75),
            meaniConceptsC = mean(iConceptsC), variConceptsC = var(iConceptsC), q1iConceptsC = quantile(iConceptsC, probs=.25), q2iConceptsC = quantile(iConceptsC, probs=.5), q3iConceptsC = quantile(iConceptsC, probs=.75),
            meaniDemoC = mean(iDemoC), variDemoC = var(iDemoC), q1iDemoC = quantile(iDemoC, probs=.25), q2iDemoC = quantile(iDemoC, probs=.5), q3iDemoC = quantile(iDemoC, probs=.75), 
            meaniEnthusiasmC = mean(iEnthusiasmC), variEnthusiasmC = var(iEnthusiasmC), q1iEnthusiasmC = quantile(iEnthusiasmC, probs=.25), q2iEnthusiasmC = quantile(iEnthusiasmC, probs=.5), q3iEnthusiasmC = quantile(iEnthusiasmC, probs=.75),
            meaniHoursC = mean(iHoursC), variHoursC = var(iHoursC), q1iHoursC = quantile(iHoursC, probs=.25), q2iHoursC = quantile(iHoursC, probs=.5), q3iHoursC = quantile(iHoursC, probs=.75),
            meaniParticipateC = mean(iParticipateC), variParticipateC = var(iParticipateC), q1iParticipateC = quantile(iParticipateC, probs=.25), q2iParticipateC = quantile(iParticipateC, probs=.5), q3iParticipateC = quantile(iParticipateC, probs=.75),
            meaniPreparedC = mean(iPreparedC), variPreparedC = var(iPreparedC), q1iPreparedC = quantile(iPreparedC, probs=.25), q2iPreparedC = quantile(iPreparedC, probs=.5), q3iPreparedC = quantile(iPreparedC, probs=.75),
            meaniQuesEffectC = mean(iQuesEffectC), variQuesEffectC = var(iQuesEffectC), q1iQuesEffectC = quantile(iQuesEffectC, probs=.25), q2iQuesEffectC = quantile(iQuesEffectC, probs=.5), q3iQuesEffectC = quantile(iQuesEffectC, probs=.75),
            meaniStandardsC = mean(iStandardsC), variStandardsC = var(iStandardsC), q1iStandardsC = quantile(iStandardsC, probs=.25),  q2iStandardsC = quantile(iStandardsC, probs=.5), q3iStandardsC = quantile(iStandardsC, probs=.75),
            meaniTopicC = mean(iTopicC), variTopicC = var(iTopicC), q1iTopicC = quantile(iTopicC, probs=.25), q2iTopicC = quantile(iTopicC, probs=.5), q3iTopicC = quantile(iTopicC, probs=.75),
            meaniUnderstandC = mean(iUnderstandC), variUnderstandC = var(iUnderstandC), q1iUnderstandC = quantile(iUnderstandC, probs=.25), q2iUnderstandC = quantile(iUnderstandC, probs=.5), q3iUnderstandC = quantile(iUnderstandC, probs=.75),
            meaniWelQuesC = mean(iWelQuesC), variWelQuesC = var(iWelQuesC), q1iWelQuesC = quantile(iWelQuesC, probs=.25), q2iWelQuesC = quantile(iWelQuesC, probs=.5), q3iWelQuesC = quantile(iWelQuesC, probs=.75))

# Pivot Data
LBootstrapData <- BootstrapData %>% pivot_longer(cols=c(meaniAnalyProbC,  meaniAskQuesC, meaniChallengedC , meaniConceptsC,  meaniDemoC, meaniEnthusiasmC, meaniHoursC, meaniParticipateC, meaniPreparedC, meaniQuesEffectC, meaniStandardsC, meaniTopicC, meaniUnderstandC, meaniWelQuesC),
                                        names_to='Variable1',
                                        values_to='Mean')
## Pivot again for variance
LBootstrapData <- LBootstrapData %>% pivot_longer(cols=c(variAnalyProbC, variAskQuesC,  variChallengedC ,  variConceptsC, variDemoC, variEnthusiasmC, variHoursC, variParticipateC, variPreparedC, variQuesEffectC, variStandardsC, variTopicC , variUnderstandC, variWelQuesC),
                                        names_to='Variable2',
                                        values_to='Variance') %>%
  
  select(Variable1, Variable2, Variance, Mean) %>%
  mutate(Variable_1 = str_replace(Variable1, "mean", ""),
         Variable_2 = str_replace(Variable2, "var", "")) %>%
  filter(Variable_2==Variable_1) %>%
  rename(Variable=Variable_1) %>%
  select(Variable, Mean, Variance) %>%
  mutate(x=c(1,2,3,4,5,6,7,8,9,10,11,12,13,14))
```


```{r, message=FALSE, warning=FALSE, include=FALSE, echo=FALSE}

# Plot i Coursetype 4

quantiles <- quantile(abs(LBootstrapData$Mean), probs=c(.25, .75))


CT4iplot <- ggplot(data=LBootstrapData, aes(y=abs(Mean), x=x)) +
  geom_point()  +
  geom_label_repel(aes(label=Variable)) +
  geom_errorbar(aes(ymin=Mean-sqrt(Variance), ymax=Mean+sqrt(Variance)), width=.3) +
  #geom_jitter(height=0, width=.5) +
  theme_minimal() +
  scale_x_continuous(breaks = (7),
                     minor_breaks= NULL,
                     labels=("Separation Factor"))+
  annotate("rect", xmin=-1, xmax=15, ymin=0, ymax=quantiles[1], fill="red", alpha=.2) +
  annotate("rect", xmin=-1, xmax=15, ymin=quantiles[1], ymax=quantiles[2], fill="yellow", alpha=.2) +
  annotate("rect", xmin=-1, xmax=15, ymin=quantiles[2], ymax=.27, fill="green", alpha=.2) +
  #annotate('text', x=1.5, y=(quantiles[2]+.1), label="Top 25% of Coefficients", color='forestgreen') +
  #annotate('text', x=1.5, y=(quantiles[2]+.09), label="Middle 50% of Coefficients", color='yellow4') +
  #annotate('text', x=1.5, y=(quantiles[2]+.08), label="Bottom 25% of Coefficients", color='firebrick4') +
  labs(title='MKT Capston Courses',
       y="Average of Absolute Value of Beta Coefficients of Standardized Questions",
       x="Values do not Matter, Just here to Separate Coefficeint Averages",
       x="",
       y="")

```

### Figure 07: Comparing Instructor Average Coefficients for Instructor Questions
```{r, echo=FALSE, warning=FALSE}
par(mfrow=c(2,2))
CT1iplot
CT2iplot
CT3iplot
CT4iplot  
```



```{r, include=FALSE, echo=FALSE, warning=FALSE}
# CourseType 1, s vars bootstrap


set.seed(09272024)

## Idea for full model
##full.modeli.1 <- lm(data=Teacher1Stdz, iRating ~ iAskQuesS + iAnalyProbS + iChallengedS + iConceptsS +iDemoS +iEnthusiasmS +iHoursS + iParticipateS + iPreparedS + iQuesEffectS + iStandardsS + iTopicS + iUnderstandS + iWelQuesS )
##summary(full.modeli.1)

## BOOTSRAPPING BY HAND

sample_coef_intercept <- NULL
sample_coef_df_x1 <- NULL
sample_coef_df_x2 <- NULL
sample_coef_df_x3 <- NULL
sample_coef_df_x4 <- NULL
sample_coef_df_x5 <- NULL
sample_coef_df_x6 <- NULL
sample_coef_df_x7 <- NULL


for (i in 1:1000) {
  #Creating a resampled dataset from the sample data
  sample_d = CTStdz_1[sample(1:nrow(CTStdz_1), nrow(CTStdz_1), replace = TRUE), ]
 # sample_d_totalcompleted <-  sample_d %>% summarize(totalcomp = sum(Completed))
  sample_d_w <- sample_d %>%
    mutate(weight = Completed/sum(Completed))
  
  #Running the regression on these data
  model_bootstrap  <- lmer(iRating ~ ((s_sAttended+ s_sEngaged+ s_sHelp+ s_sPrepared+ s_sPositive + s_sUpToDate) + (1 | eInstID)), weights=weight, data = sample_d_w)
  bootsum <- summary(model_bootstrap)
  
    #Saving the coefficients
  sample_coef_intercept <-
    c(sample_coef_intercept, bootsum$coefficients[1])
  
  sample_coef_df_x1 <- c(sample_coef_df_x1, bootsum$coefficients[2])
  sample_coef_df_x2 <- c(sample_coef_df_x2, bootsum$coefficients[3])
  sample_coef_df_x3 <- c(sample_coef_df_x3, bootsum$coefficients[4])
  sample_coef_df_x4 <- c(sample_coef_df_x4, bootsum$coefficients[5])
  sample_coef_df_x5 <- c(sample_coef_df_x5, bootsum$coefficients[6])
  sample_coef_df_x6 <- c(sample_coef_df_x6, bootsum$coefficients[7])
}

## Want ABSOLUTE values to show overall affect on iRating (-.3 has as much of an effect as .3)
absCoefsDF <- data.frame(sAttendedC=abs(sample_coef_df_x1), 
                      sEngagedC=abs(sample_coef_df_x2),
                      sHelpC=abs(sample_coef_df_x3),
                      sPreparedC=abs(sample_coef_df_x4),
                      sPositiveC=abs(sample_coef_df_x5),
                      sUpToDateC=abs(sample_coef_df_x6))

BootstrapData <- absCoefsDF %>%
  summarize(meansAttendedC = mean(sAttendedC), varsAttendedC = var(sAttendedC),q1sAttendedC = quantile(sAttendedC, probs=.25), q2sAttendedC = quantile(sAttendedC, probs=.5), q3sAttendedC = quantile(sAttendedC, probs=.75),
            meansEngagedC = mean(sEngagedC), varsEngagedC = var(sEngagedC), q1sEngagedC = quantile(sEngagedC, probs=.25), q2sEngagedC = quantile(sEngagedC, probs=.5), q3sEngagedC = quantile(sEngagedC, probs=.75),
            meansHelpC = mean(sHelpC), varsHelpC = var(sHelpC), q1sHelpC = quantile(sHelpC, probs=.25), q2sHelpC = quantile(sHelpC, probs=.5), q3sHelpC = quantile(sHelpC, probs=.75),
            meansPreparedC = mean(sPreparedC), varsPreparedC = var(sPreparedC), q1sPreparedC = quantile(sPreparedC, probs=.25), q2sPreparedC = quantile(sPreparedC, probs=.5), q3sPreparedC = quantile(sPreparedC, probs=.75),
            meansPositiveC = mean(sPositiveC), varsPositiveC = var(sPositiveC), q1sPositiveC = quantile(sPositiveC, probs=.25), q2sPositiveC = quantile(sPositiveC, probs=.5), q3sPositiveC = quantile(sPositiveC, probs=.75), 
            meansUpToDateC = mean(sUpToDateC), varsUpToDateC = var(sUpToDateC), q1sUpToDateC = quantile(sUpToDateC, probs=.25), q2sUpToDateC = quantile(sUpToDateC, probs=.5), q3sUpToDateC = quantile(sUpToDateC, probs=.75) )

# Pivot Data
LBootstrapData <- BootstrapData %>% pivot_longer(cols=c(meansAttendedC,  meansEngagedC, meansHelpC , meansPreparedC,  meansPositiveC, meansUpToDateC),
                                        names_to='Variable1',
                                        values_to='Mean')
## Pivot again for variance
LBootstrapData <- LBootstrapData %>% pivot_longer(cols=c(varsAttendedC,  varsEngagedC, varsHelpC , varsPreparedC,  varsPositiveC, varsUpToDateC),
                                        names_to='Variable2',
                                        values_to='Variance') %>%
  
  select(Variable1, Variable2, Variance, Mean) %>%
  mutate(Variable_1 = str_replace(Variable1, "mean", ""),
         Variable_2 = str_replace(Variable2, "var", "")) %>%
  filter(Variable_2==Variable_1) %>%
  rename(Variable=Variable_1) %>%
  select(Variable, Mean, Variance) %>%
  mutate(x=c(1,2,3,4,5,6))
```

```{r, include=FALSE, echo=FALSE, warning=FALSE}

# CourseType 1, s vars plot

quantiles <- quantile(abs(LBootstrapData$Mean), probs=c(.25, .75))


CT1splot <- ggplot(data=LBootstrapData, aes(y=abs(Mean), x=x)) +
  geom_point()  +
  geom_label_repel(aes(label=Variable)) +
  geom_errorbar(aes(ymin=Mean-sqrt(Variance), ymax=Mean+sqrt(Variance)), width=.3) +
  #geom_jitter(height=0, width=.5) +
  theme_minimal() +
  scale_x_continuous(breaks = (3.5),
                     minor_breaks= NULL,
                     labels=("Separation Factor"))+
  annotate("rect", xmin=0, xmax=7, ymin=0, ymax=quantiles[1], fill="red", alpha=.2) +
  annotate("rect", xmin=0, xmax=7, ymin=quantiles[1], ymax=quantiles[2], fill="yellow", alpha=.2) +
  annotate("rect", xmin=0, xmax=7, ymin=quantiles[2], ymax=.32, fill="green", alpha=.2) +
  #annotate('text', x=1.5, y=(quantiles[2]+.1), label="Top 25% of Coefficients", color='forestgreen') +
  #annotate('text', x=1.5, y=(quantiles[2]+.09), label="Middle 50% of Coefficients", color='yellow4') +
  #annotate('text', x=1.5, y=(quantiles[2]+.08), label="Bottom 25% of Coefficients", color='firebrick4') +
  labs(title='Beta Coefficient Averages of Standardized test Variables for FSB Core Instructors',
       subtitle='Ignoring horizontal placement, variables with the highest average absolute value of their beta coefficient have\n the largest affect on a teachers rating when all variables are treated on the same scale',
       y="Average of Absolute Value of Beta Coefficients of Standardized Questions",
       x="Values do not Matter, Just here to Separate Coefficeint Averages")

```


```{r, include=FALSE, echo=FALSE, warning=FALSE}
# CourseType 2, s vars

set.seed(09272024)

## Idea for full model
##full.modeli.1 <- lm(data=Teacher1Stdz, iRating ~ iAskQuesS + iAnalyProbS + iChallengedS + iConceptsS +iDemoS +iEnthusiasmS +iHoursS + iParticipateS + iPreparedS + iQuesEffectS + iStandardsS + iTopicS + iUnderstandS + iWelQuesS )
##summary(full.modeli.1)

## BOOTSRAPPING BY HAND

sample_coef_intercept <- NULL
sample_coef_df_x1 <- NULL
sample_coef_df_x2 <- NULL
sample_coef_df_x3 <- NULL
sample_coef_df_x4 <- NULL
sample_coef_df_x5 <- NULL
sample_coef_df_x6 <- NULL
sample_coef_df_x7 <- NULL


for (i in 1:1000) {
  #Creating a resampled dataset from the sample data
  sample_d = CTStdz_2[sample(1:nrow(CTStdz_2), nrow(CTStdz_2), replace = TRUE), ]
 # sample_d_totalcompleted <-  sample_d %>% summarize(totalcomp = sum(Completed))
  sample_d_w <- sample_d %>%
    mutate(weight = Completed/sum(Completed))
  
  #Running the regression on these data
  model_bootstrap  <- lmer(iRating ~ ((s_sAttended+ s_sEngaged+ s_sHelp+ s_sPrepared+ s_sPositive + s_sUpToDate) + (1 | eInstID)), weights=weight, data = sample_d_w)
  bootsum <- summary(model_bootstrap)
  
    #Saving the coefficients
  sample_coef_intercept <-
    c(sample_coef_intercept, bootsum$coefficients[1])
  
  sample_coef_df_x1 <- c(sample_coef_df_x1, bootsum$coefficients[2])
  sample_coef_df_x2 <- c(sample_coef_df_x2, bootsum$coefficients[3])
  sample_coef_df_x3 <- c(sample_coef_df_x3, bootsum$coefficients[4])
  sample_coef_df_x4 <- c(sample_coef_df_x4, bootsum$coefficients[5])
  sample_coef_df_x5 <- c(sample_coef_df_x5, bootsum$coefficients[6])
  sample_coef_df_x6 <- c(sample_coef_df_x6, bootsum$coefficients[7])
}

## Want ABSOLUTE values to show overall affect on iRating (-.3 has as much of an effect as .3)
absCoefsDF <- data.frame(sAttendedC=abs(sample_coef_df_x1), 
                      sEngagedC=abs(sample_coef_df_x2),
                      sHelpC=abs(sample_coef_df_x3),
                      sPreparedC=abs(sample_coef_df_x4),
                      sPositiveC=abs(sample_coef_df_x5),
                      sUpToDateC=abs(sample_coef_df_x6))

BootstrapData <- absCoefsDF %>%
  summarize(meansAttendedC = mean(sAttendedC), varsAttendedC = var(sAttendedC),q1sAttendedC = quantile(sAttendedC, probs=.25), q2sAttendedC = quantile(sAttendedC, probs=.5), q3sAttendedC = quantile(sAttendedC, probs=.75),
            meansEngagedC = mean(sEngagedC), varsEngagedC = var(sEngagedC), q1sEngagedC = quantile(sEngagedC, probs=.25), q2sEngagedC = quantile(sEngagedC, probs=.5), q3sEngagedC = quantile(sEngagedC, probs=.75),
            meansHelpC = mean(sHelpC), varsHelpC = var(sHelpC), q1sHelpC = quantile(sHelpC, probs=.25), q2sHelpC = quantile(sHelpC, probs=.5), q3sHelpC = quantile(sHelpC, probs=.75),
            meansPreparedC = mean(sPreparedC), varsPreparedC = var(sPreparedC), q1sPreparedC = quantile(sPreparedC, probs=.25), q2sPreparedC = quantile(sPreparedC, probs=.5), q3sPreparedC = quantile(sPreparedC, probs=.75),
            meansPositiveC = mean(sPositiveC), varsPositiveC = var(sPositiveC), q1sPositiveC = quantile(sPositiveC, probs=.25), q2sPositiveC = quantile(sPositiveC, probs=.5), q3sPositiveC = quantile(sPositiveC, probs=.75), 
            meansUpToDateC = mean(sUpToDateC), varsUpToDateC = var(sUpToDateC), q1sUpToDateC = quantile(sUpToDateC, probs=.25), q2sUpToDateC = quantile(sUpToDateC, probs=.5), q3sUpToDateC = quantile(sUpToDateC, probs=.75) )

# Pivot Data
LBootstrapData <- BootstrapData %>% pivot_longer(cols=c(meansAttendedC,  meansEngagedC, meansHelpC , meansPreparedC,  meansPositiveC, meansUpToDateC),
                                        names_to='Variable1',
                                        values_to='Mean')
## Pivot again for variance
LBootstrapData <- LBootstrapData %>% pivot_longer(cols=c(varsAttendedC,  varsEngagedC, varsHelpC , varsPreparedC,  varsPositiveC, varsUpToDateC),
                                        names_to='Variable2',
                                        values_to='Variance') %>%
  
  select(Variable1, Variable2, Variance, Mean) %>%
  mutate(Variable_1 = str_replace(Variable1, "mean", ""),
         Variable_2 = str_replace(Variable2, "var", "")) %>%
  filter(Variable_2==Variable_1) %>%
  rename(Variable=Variable_1) %>%
  select(Variable, Mean, Variance) %>%
  mutate(x=c(1,2,3,4,5,6))
```

```{r, include=FALSE, echo=FALSE, warning=FALSE}

# Student Variables Average Coefficient Plot CourseType 2


quantiles <- quantile(abs(LBootstrapData$Mean), probs=c(.25, .75))


CT2splot <- ggplot(data=LBootstrapData, aes(y=abs(Mean), x=x)) +
  geom_point()  +
  geom_label_repel(aes(label=Variable)) +
  geom_errorbar(aes(ymin=Mean-sqrt(Variance), ymax=Mean+sqrt(Variance)), width=.3) +
  #geom_jitter(height=0, width=.5) +
  theme_minimal() +
  scale_x_continuous(breaks = (3.5),
                     minor_breaks= NULL,
                     labels=("Separation Factor"))+
  annotate("rect", xmin=0, xmax=7, ymin=0, ymax=quantiles[1], fill="red", alpha=.2) +
  annotate("rect", xmin=0, xmax=7, ymin=quantiles[1], ymax=quantiles[2], fill="yellow", alpha=.2) +
  annotate("rect", xmin=0, xmax=7, ymin=quantiles[2], ymax=.32, fill="green", alpha=.2) +
  #annotate('text', x=1.5, y=(quantiles[2]+.1), label="Top 25% of Coefficients", color='forestgreen') +
  #annotate('text', x=1.5, y=(quantiles[2]+.09), label="Middle 50% of Coefficients", color='yellow4') +
  #annotate('text', x=1.5, y=(quantiles[2]+.08), label="Bottom 25% of Coefficients", color='firebrick4') +
  labs(title="MKT Core Courses",
       x="",
       y="")

```




```{r, include=FALSE, echo=FALSE, warning=FALSE}
# CourseType 3, s vars

set.seed(09272024)

## Idea for full model
##full.modeli.1 <- lm(data=Teacher1Stdz, iRating ~ iAskQuesS + iAnalyProbS + iChallengedS + iConceptsS +iDemoS +iEnthusiasmS +iHoursS + iParticipateS + iPreparedS + iQuesEffectS + iStandardsS + iTopicS + iUnderstandS + iWelQuesS )
##summary(full.modeli.1)

## BOOTSRAPPING BY HAND

sample_coef_intercept <- NULL
sample_coef_df_x1 <- NULL
sample_coef_df_x2 <- NULL
sample_coef_df_x3 <- NULL
sample_coef_df_x4 <- NULL
sample_coef_df_x5 <- NULL
sample_coef_df_x6 <- NULL
sample_coef_df_x7 <- NULL


for (i in 1:1000) {
  #Creating a resampled dataset from the sample data
  sample_d = CTStdz_3[sample(1:nrow(CTStdz_3), nrow(CTStdz_3), replace = TRUE), ]
 # sample_d_totalcompleted <-  sample_d %>% summarize(totalcomp = sum(Completed))
  sample_d_w <- sample_d %>%
    mutate(weight = Completed/sum(Completed))
  
  #Running the regression on these data
  model_bootstrap  <- lmer(iRating ~ ((s_sAttended+ s_sEngaged+ s_sHelp+ s_sPrepared+ s_sPositive + s_sUpToDate) + (1 | eInstID)), weights=weight, data = sample_d_w)
  bootsum <- summary(model_bootstrap)
  
    #Saving the coefficients
  sample_coef_intercept <-
    c(sample_coef_intercept, bootsum$coefficients[1])
  
  sample_coef_df_x1 <- c(sample_coef_df_x1, bootsum$coefficients[2])
  sample_coef_df_x2 <- c(sample_coef_df_x2, bootsum$coefficients[3])
  sample_coef_df_x3 <- c(sample_coef_df_x3, bootsum$coefficients[4])
  sample_coef_df_x4 <- c(sample_coef_df_x4, bootsum$coefficients[5])
  sample_coef_df_x5 <- c(sample_coef_df_x5, bootsum$coefficients[6])
  sample_coef_df_x6 <- c(sample_coef_df_x6, bootsum$coefficients[7])
}

## Want ABSOLUTE values to show overall affect on iRating (-.3 has as much of an effect as .3)
absCoefsDF <- data.frame(sAttendedC=abs(sample_coef_df_x1), 
                      sEngagedC=abs(sample_coef_df_x2),
                      sHelpC=abs(sample_coef_df_x3),
                      sPreparedC=abs(sample_coef_df_x4),
                      sPositiveC=abs(sample_coef_df_x5),
                      sUpToDateC=abs(sample_coef_df_x6))

BootstrapData <- absCoefsDF %>%
  summarize(meansAttendedC = mean(sAttendedC), varsAttendedC = var(sAttendedC),q1sAttendedC = quantile(sAttendedC, probs=.25), q2sAttendedC = quantile(sAttendedC, probs=.5), q3sAttendedC = quantile(sAttendedC, probs=.75),
            meansEngagedC = mean(sEngagedC), varsEngagedC = var(sEngagedC), q1sEngagedC = quantile(sEngagedC, probs=.25), q2sEngagedC = quantile(sEngagedC, probs=.5), q3sEngagedC = quantile(sEngagedC, probs=.75),
            meansHelpC = mean(sHelpC), varsHelpC = var(sHelpC), q1sHelpC = quantile(sHelpC, probs=.25), q2sHelpC = quantile(sHelpC, probs=.5), q3sHelpC = quantile(sHelpC, probs=.75),
            meansPreparedC = mean(sPreparedC), varsPreparedC = var(sPreparedC), q1sPreparedC = quantile(sPreparedC, probs=.25), q2sPreparedC = quantile(sPreparedC, probs=.5), q3sPreparedC = quantile(sPreparedC, probs=.75),
            meansPositiveC = mean(sPositiveC), varsPositiveC = var(sPositiveC), q1sPositiveC = quantile(sPositiveC, probs=.25), q2sPositiveC = quantile(sPositiveC, probs=.5), q3sPositiveC = quantile(sPositiveC, probs=.75), 
            meansUpToDateC = mean(sUpToDateC), varsUpToDateC = var(sUpToDateC), q1sUpToDateC = quantile(sUpToDateC, probs=.25), q2sUpToDateC = quantile(sUpToDateC, probs=.5), q3sUpToDateC = quantile(sUpToDateC, probs=.75) )

# Pivot Data
LBootstrapData <- BootstrapData %>% pivot_longer(cols=c(meansAttendedC,  meansEngagedC, meansHelpC , meansPreparedC,  meansPositiveC, meansUpToDateC),
                                        names_to='Variable1',
                                        values_to='Mean')
## Pivot again for variance
LBootstrapData <- LBootstrapData %>% pivot_longer(cols=c(varsAttendedC,  varsEngagedC, varsHelpC , varsPreparedC,  varsPositiveC, varsUpToDateC),
                                        names_to='Variable2',
                                        values_to='Variance') %>%
  
  select(Variable1, Variable2, Variance, Mean) %>%
  mutate(Variable_1 = str_replace(Variable1, "mean", ""),
         Variable_2 = str_replace(Variable2, "var", "")) %>%
  filter(Variable_2==Variable_1) %>%
  rename(Variable=Variable_1) %>%
  select(Variable, Mean, Variance) %>%
  mutate(x=c(1,2,3,4,5,6))
```


```{r, include=FALSE, echo=FALSE, warning=FALSE}

# Student Variables Average Coefficient Plot CourseType 3

quantiles <- quantile(abs(LBootstrapData$Mean), probs=c(.25, .75))


CT3splot <- ggplot(data=LBootstrapData, aes(y=abs(Mean), x=x)) +
  geom_point()  +
  geom_label_repel(aes(label=Variable)) +
  geom_errorbar(aes(ymin=Mean-sqrt(Variance), ymax=Mean+sqrt(Variance)), width=.3) +
  #geom_jitter(height=0, width=.5) +
  theme_minimal() +
  scale_x_continuous(breaks = (3.5),
                     minor_breaks= NULL,
                     labels=("Separation Factor"))+
  annotate("rect", xmin=0, xmax=7, ymin=0, ymax=quantiles[1], fill="red", alpha=.2) +
  annotate("rect", xmin=0, xmax=7, ymin=quantiles[1], ymax=quantiles[2], fill="yellow", alpha=.2) +
  annotate("rect", xmin=0, xmax=7, ymin=quantiles[2], ymax=.32, fill="green", alpha=.2) +
  #annotate('text', x=.5, y=(quantiles[2]-.05), label="Top 25% of Coefficients", color='forestgreen') +
  #annotate('text', x=.5, y=(quantiles[2]-.04), label="Middle 50% of Coefficients", color='yellow4') +
  #annotate('text', x=.5, y=(quantiles[2]-.03), label="Bottom 25% of Coefficients", color='firebrick4') +
  labs(title="MKT Elective Courses",
       x="",
       y="")
```




```{r, include=FALSE, echo=FALSE, warning=FALSE}
# CourseType 4, s vars
set.seed(09272024)

## Idea for full model
##full.modeli.1 <- lm(data=Teacher1Stdz, iRating ~ iAskQuesS + iAnalyProbS + iChallengedS + iConceptsS +iDemoS +iEnthusiasmS +iHoursS + iParticipateS + iPreparedS + iQuesEffectS + iStandardsS + iTopicS + iUnderstandS + iWelQuesS )
##summary(full.modeli.1)

## BOOTSRAPPING BY HAND

sample_coef_intercept <- NULL
sample_coef_df_x1 <- NULL
sample_coef_df_x2 <- NULL
sample_coef_df_x3 <- NULL
sample_coef_df_x4 <- NULL
sample_coef_df_x5 <- NULL
sample_coef_df_x6 <- NULL
sample_coef_df_x7 <- NULL


for (i in 1:1000) {
  #Creating a resampled dataset from the sample data
  sample_d = CTStdz_4[sample(1:nrow(CTStdz_4), nrow(CTStdz_4), replace = TRUE), ]
 # sample_d_totalcompleted <-  sample_d %>% summarize(totalcomp = sum(Completed))
  sample_d_w <- sample_d %>%
    mutate(weight = Completed/sum(Completed))
  
  #Running the regression on these data
  model_bootstrap  <- lmer(iRating ~ ((s_sAttended+ s_sEngaged+ s_sHelp+ s_sPrepared+ s_sPositive + s_sUpToDate) + (1 | eInstID)), weights=weight, data = sample_d_w)
  bootsum <- summary(model_bootstrap)
  
    #Saving the coefficients
  sample_coef_intercept <-
    c(sample_coef_intercept, bootsum$coefficients[1])
  
  sample_coef_df_x1 <- c(sample_coef_df_x1, bootsum$coefficients[2])
  sample_coef_df_x2 <- c(sample_coef_df_x2, bootsum$coefficients[3])
  sample_coef_df_x3 <- c(sample_coef_df_x3, bootsum$coefficients[4])
  sample_coef_df_x4 <- c(sample_coef_df_x4, bootsum$coefficients[5])
  sample_coef_df_x5 <- c(sample_coef_df_x5, bootsum$coefficients[6])
  sample_coef_df_x6 <- c(sample_coef_df_x6, bootsum$coefficients[7])
}

## Want ABSOLUTE values to show overall affect on iRating (-.3 has as much of an effect as .3)
absCoefsDF <- data.frame(sAttendedC=abs(sample_coef_df_x1), 
                      sEngagedC=abs(sample_coef_df_x2),
                      sHelpC=abs(sample_coef_df_x3),
                      sPreparedC=abs(sample_coef_df_x4),
                      sPositiveC=abs(sample_coef_df_x5),
                      sUpToDateC=abs(sample_coef_df_x6))

BootstrapData <- absCoefsDF %>%
  summarize(meansAttendedC = mean(sAttendedC), varsAttendedC = var(sAttendedC),q1sAttendedC = quantile(sAttendedC, probs=.25), q2sAttendedC = quantile(sAttendedC, probs=.5), q3sAttendedC = quantile(sAttendedC, probs=.75),
            meansEngagedC = mean(sEngagedC), varsEngagedC = var(sEngagedC), q1sEngagedC = quantile(sEngagedC, probs=.25), q2sEngagedC = quantile(sEngagedC, probs=.5), q3sEngagedC = quantile(sEngagedC, probs=.75),
            meansHelpC = mean(sHelpC), varsHelpC = var(sHelpC), q1sHelpC = quantile(sHelpC, probs=.25), q2sHelpC = quantile(sHelpC, probs=.5), q3sHelpC = quantile(sHelpC, probs=.75),
            meansPreparedC = mean(sPreparedC), varsPreparedC = var(sPreparedC), q1sPreparedC = quantile(sPreparedC, probs=.25), q2sPreparedC = quantile(sPreparedC, probs=.5), q3sPreparedC = quantile(sPreparedC, probs=.75),
            meansPositiveC = mean(sPositiveC), varsPositiveC = var(sPositiveC), q1sPositiveC = quantile(sPositiveC, probs=.25), q2sPositiveC = quantile(sPositiveC, probs=.5), q3sPositiveC = quantile(sPositiveC, probs=.75), 
            meansUpToDateC = mean(sUpToDateC), varsUpToDateC = var(sUpToDateC), q1sUpToDateC = quantile(sUpToDateC, probs=.25), q2sUpToDateC = quantile(sUpToDateC, probs=.5), q3sUpToDateC = quantile(sUpToDateC, probs=.75) )

# Pivot Data
LBootstrapData <- BootstrapData %>% pivot_longer(cols=c(meansAttendedC,  meansEngagedC, meansHelpC , meansPreparedC,  meansPositiveC, meansUpToDateC),
                                        names_to='Variable1',
                                        values_to='Mean')
## Pivot again for variance
LBootstrapData <- LBootstrapData %>% pivot_longer(cols=c(varsAttendedC,  varsEngagedC, varsHelpC , varsPreparedC,  varsPositiveC, varsUpToDateC),
                                        names_to='Variable2',
                                        values_to='Variance') %>%
  
  select(Variable1, Variable2, Variance, Mean) %>%
  mutate(Variable_1 = str_replace(Variable1, "mean", ""),
         Variable_2 = str_replace(Variable2, "var", "")) %>%
  filter(Variable_2==Variable_1) %>%
  rename(Variable=Variable_1) %>%
  select(Variable, Mean, Variance) %>%
  mutate(x=c(1,2,3,4,5,6))
```


```{r, include=FALSE, echo=FALSE, warning=FALSE}
# Student Variables Average Coefficient Plot CourseType 4

quantiles <- quantile(abs(LBootstrapData$Mean), probs=c(.25, .75))


CT4splot <- ggplot(data=LBootstrapData, aes(y=abs(Mean), x=x)) +
  geom_point()  +
  geom_label_repel(aes(label=Variable)) +
  geom_errorbar(aes(ymin=Mean-sqrt(Variance), ymax=Mean+sqrt(Variance)), width=.3) +
  #geom_jitter(height=0, width=.5) +
  theme_minimal() +
  scale_x_continuous(breaks = (3.5),
                     minor_breaks= NULL,
                     labels=("Separation Factor"))+
  annotate("rect", xmin=0, xmax=7, ymin=0, ymax=quantiles[1], fill="red", alpha=.2) +
  annotate("rect", xmin=0, xmax=7, ymin=quantiles[1], ymax=quantiles[2], fill="yellow", alpha=.2) +
  annotate("rect", xmin=0, xmax=7, ymin=quantiles[2], ymax=.32, fill="green", alpha=.2) +
  #annotate('text', x=3.5, y=(quantiles[2]+.1), label="Top 25% of Coefficients", color='forestgreen') +
  #annotate('text', x=3.5, y=(quantiles[2]+.09), label="Middle 50% of Coefficients", color='yellow4') +
 # annotate('text', x=3.5, y=(quantiles[2]+.08), label="Bottom 25% of Coefficients", color='firebrick4') +
  labs(title="MKT Capstone Courses",
       y="Average of Absolute Value of Beta Coefficients of Standardized Questions",
       x="Values do not Matter, Just here to Separate Coefficeint Averages")

```

### Figure 08: Comparing Average Coefficients for Student Behavior Questions
```{r, echo=FALSE, warning=FALSE}
## Plot all S

par(mfrow=c(2,2))
CT1splot
CT2splot
CT3splot
CT4splot

```

Furthermore when testing the Course Type Model, which included course type as a 3 dummy variable predictor, revealed its significant impact on the relationship between instructor performance and overall ratings in Figure 09. When FSB core courses were used as the baseline, there was no significant addition to the model when accounting for MKT core courses (p-value: 0.33, t-value: 0.971 on 205 df), but both dummy variables for MKT elective and MKT capstone courses were found to be significant (p-value: <0.001, t-value: 5.368, on 101 df and p-value: <0.001, t-value: 8.276, on 144 df respoectively). This result confirms that different course types can affect how instructor performance is perceived and rated by students. By modeling both instructor and student variables separately, we obtained a more nuanced understanding of the drivers of instructor ratings across different course types.

In Figure 10, it can be seen that coursetype3 and coursetype4 dummy variables have the highest coefficients by far. However, these variables are not standardized, and are dummy variables so they cannot be treated on the same scale as the other predictors. However, when instructor variables and student variables are modeled together, it seems to show that instructor variables overall are more effective at modeling overall instructor rating, and for the most part the same variables as suggested by figure 07. 




### Figure 09: Course Type Model Summary
```{r, echo=FALSE, warning=FALSE}

## Model looking into course type as predictor


# Mixed-effects model with CourseType as a predictor
model_full <- lmer(iRating ~ CourseType + 
                    (s_iAnalyProb + s_iAskQues + s_iChallenged + s_iConcepts + s_iDemo +
                     s_iEnthusiasm + s_iHours + s_iParticipate + s_iPrepared + s_iQuesEffect +
                     s_iStandards + s_iTopic + s_iUnderstand + s_iWelQues + s_sAttended + s_sEngaged +
                       s_sHelp + s_sPrepared + s_sPositive + s_sUpToDate) + 
                     (1 | eInstID), 
                  weights = weights, 
                  data = CTStdz_all)
#summary(model_full)
# Extract model summary as a tidy table
tidy_model <- broom.mixed::tidy(model_full)

# Create a clean table using gt
tidy_model %>%
  gt() %>%
  tab_header(
    title = "Course Type Model Summary",
    subtitle = "Detailed output of the fixed effects"
  ) %>%
  fmt_number(
    columns = vars(estimate, std.error, statistic, p.value),
    decimals = 3
  ) %>%
  cols_label(
    term = "Predictor",
    estimate = "Estimate",
    std.error = "Std. Error",
    statistic = "t-Value",
    p.value = "P-Value"
  )


```

```{r, echo=FALSE, warning=FALSE}
# Set seed for reproducibility
set.seed(09272024)

# Initialize empty lists to store coefficients for each predictor
sample_coef_intercept <- NULL
sample_coef_df_course_type2 <- NULL  # For CourseType
sample_coef_df_course_type3 <- NULL  # For CourseType
sample_coef_df_course_type4 <- NULL  # For CourseType
sample_coef_df_x1 <- NULL
sample_coef_df_x2 <- NULL
sample_coef_df_x3 <- NULL
sample_coef_df_x4 <- NULL
sample_coef_df_x5 <- NULL
sample_coef_df_x6 <- NULL
sample_coef_df_x7 <- NULL
sample_coef_df_x8 <- NULL
sample_coef_df_x9 <- NULL
sample_coef_df_x10 <- NULL
sample_coef_df_x11 <- NULL
sample_coef_df_x12 <- NULL
sample_coef_df_x13 <- NULL
sample_coef_df_x14 <- NULL
sample_coef_df_x15 <- NULL
sample_coef_df_x16 <- NULL
sample_coef_df_x17 <- NULL
sample_coef_df_x18 <- NULL
sample_coef_df_x19 <- NULL
sample_coef_df_x20 <- NULL
sample_coef_df_x21 <- NULL
sample_coef_df_x22 <- NULL
sample_coef_df_x23 <- NULL
sample_coef_df_x24 <- NULL

 

# Bootstrapping loop (1000 iterations)
for (i in 1:1000) {
  # Resample the dataset with replacement
  sample_d <- CTStdz_all[sample(1:nrow(CTStdz_all), nrow(CTStdz_all), replace = TRUE), ]
  
  # Compute weights based on the 'Completed' variable
  sample_d_w <- sample_d %>%
    mutate(weight = Completed / sum(Completed))
  
  # Fit the linear mixed model with CourseType as a predictor
  model_bootstrap <- lmer(iRating ~ CourseType + 
                            (s_iAnalyProb + s_iAskQues + s_iChallenged + s_iConcepts + s_iDemo + 
                             s_iEnthusiasm + s_iHours + s_iParticipate + s_iPrepared + 
                             s_iQuesEffect + s_iStandards + s_iTopic + s_iUnderstand + 
                             s_iWelQues + s_sAttended + s_sEngaged + s_sHelp + s_sPrepared
                             + s_sPositive + s_sUpToDate) + (1 | eInstID), 
                           weights = weight, data = sample_d_w)
  
  # Extract coefficients
  bootsum <- summary(model_bootstrap)
  
  # Save the coefficients for each variable
  sample_coef_intercept <- c(sample_coef_intercept, bootsum$coefficients[1])
  sample_coef_df_course_type2 <- c(sample_coef_df_course_type2, bootsum$coefficients[2])  # CourseType
  sample_coef_df_course_type3 <- c(sample_coef_df_course_type3, bootsum$coefficients[3])  # CourseType
  sample_coef_df_course_type4 <- c(sample_coef_df_course_type4, bootsum$coefficients[4])  # CourseType
  sample_coef_df_x1 <- c(sample_coef_df_x1, bootsum$coefficients[5])
  sample_coef_df_x2 <- c(sample_coef_df_x2, bootsum$coefficients[6])
  sample_coef_df_x3 <- c(sample_coef_df_x3, bootsum$coefficients[7])
  sample_coef_df_x4 <- c(sample_coef_df_x4, bootsum$coefficients[8])
  sample_coef_df_x5 <- c(sample_coef_df_x5, bootsum$coefficients[9])
  sample_coef_df_x6 <- c(sample_coef_df_x6, bootsum$coefficients[10])
  sample_coef_df_x7 <- c(sample_coef_df_x7, bootsum$coefficients[11])
  sample_coef_df_x8 <- c(sample_coef_df_x8, bootsum$coefficients[12])
  sample_coef_df_x9 <- c(sample_coef_df_x9, bootsum$coefficients[13])
  sample_coef_df_x10 <- c(sample_coef_df_x10, bootsum$coefficients[14])
  sample_coef_df_x11 <- c(sample_coef_df_x11, bootsum$coefficients[15])
  sample_coef_df_x12 <- c(sample_coef_df_x12, bootsum$coefficients[16])
  sample_coef_df_x13 <- c(sample_coef_df_x13, bootsum$coefficients[17])
  sample_coef_df_x14 <- c(sample_coef_df_x14, bootsum$coefficients[18])
  sample_coef_df_x15 <- c(sample_coef_df_x15, bootsum$coefficients[19])
  sample_coef_df_x16 <- c(sample_coef_df_x16, bootsum$coefficients[20])
  sample_coef_df_x17 <- c(sample_coef_df_x17, bootsum$coefficients[21])
  sample_coef_df_x18 <- c(sample_coef_df_x18, bootsum$coefficients[22])
  sample_coef_df_x19 <- c(sample_coef_df_x19, bootsum$coefficients[23])
  sample_coef_df_x20 <- c(sample_coef_df_x20, bootsum$coefficients[24])
}

# Create a data frame with absolute coefficients to represent their magnitude
absCoefsDF <- data.frame(
  CourseType2 = abs(sample_coef_df_course_type2),  # CourseType effect
  CourseType3 = abs(sample_coef_df_course_type3),  # CourseType effect
  CourseType4 = abs(sample_coef_df_course_type4),  # CourseType effect
  iAnalyProbC = abs(sample_coef_df_x1), 
  iAskQuesC = abs(sample_coef_df_x2),
  iChallengedC = abs(sample_coef_df_x3),
  iConceptsC = abs(sample_coef_df_x4),
  iDemoC = abs(sample_coef_df_x5),
  iEnthusiasmC = abs(sample_coef_df_x6),
  iHoursC = abs(sample_coef_df_x7),
  iParticipateC = abs(sample_coef_df_x8),
  iPreparedC = abs(sample_coef_df_x9),
  iQuesEffectC = abs(sample_coef_df_x10),
  iStandardsC = abs(sample_coef_df_x11),
  iTopicC = abs(sample_coef_df_x12),
  iUnderstandC = abs(sample_coef_df_x13),
  iWelQuesC = abs(sample_coef_df_x14),
  sAttendedC = abs(sample_coef_df_x15),
  sEngagedC = abs(sample_coef_df_x16),
  sHelpC = abs(sample_coef_df_x17),
  sPreparedC = abs(sample_coef_df_x18),
  sPositiveC = abs(sample_coef_df_x19),
  sUpToDateC = abs(sample_coef_df_x20))

```

```{r, echo=FALSE, warning=FALSE}
# Step 1: Summarize the bootstrapped coefficients as you did before
BootstrapData <- absCoefsDF %>%
  summarize(
    meanCourseType2 = mean(CourseType2), varCourseType2 = var(CourseType2), 
    meanCourseType3 = mean(CourseType3), varCourseType3 = var(CourseType3), 
    meanCourseType4 = mean(CourseType4), varCourseType4 = var(CourseType4), 
    meaniAnalyProbC = mean(iAnalyProbC), variAnalyProbC = var(iAnalyProbC), 
    meaniAskQuesC = mean(iAskQuesC), variAskQuesC = var(iAskQuesC), 
    meaniChallengedC = mean(iChallengedC), variChallengedC = var(iChallengedC), 
    meaniConceptsC = mean(iConceptsC), variConceptsC = var(iConceptsC), 
    meaniDemoC = mean(iDemoC), variDemoC = var(iDemoC), 
    meaniEnthusiasmC = mean(iEnthusiasmC), variEnthusiasmC = var(iEnthusiasmC), 
    meaniHoursC = mean(iHoursC), variHoursC = var(iHoursC), 
    meaniParticipateC = mean(iParticipateC), variParticipateC = var(iParticipateC), 
    meaniPreparedC = mean(iPreparedC), variPreparedC = var(iPreparedC), 
    meaniQuesEffectC = mean(iQuesEffectC), variQuesEffectC = var(iQuesEffectC), 
    meaniStandardsC = mean(iStandardsC), variStandardsC = var(iStandardsC), 
    meaniTopicC = mean(iTopicC), variTopicC = var(iTopicC), 
    meaniUnderstandC = mean(iUnderstandC), variUnderstandC = var(iUnderstandC), 
    meaniWelQuesC = mean(iWelQuesC), variWelQuesC = var(iWelQuesC),
    meansAttendedC = mean(sAttendedC), varsAttendedC = var(sAttendedC), 
    meansEngagedC = mean(sEngagedC), varsEngagedC = var(sEngagedC), 
    meansHelpC = mean(sHelpC), varsHelpC = var(sHelpC), 
    meansPreparedC = mean(sPreparedC), varsPreparedC = var(sPreparedC), 
    meansPositiveC = mean(sPositiveC), varsPositiveC = var(sPositiveC), 
    meansUpToDateC = mean(sUpToDateC), varsUpToDateC = var(sUpToDateC)
  )
```
### Figure 10: Coefficients of Course Type Model
```{r, echo=FALSE, warning=FALSE}
# Pivot Data
LBootstrapData <- BootstrapData%>% pivot_longer(cols=c(meanCourseType2, meanCourseType3, meanCourseType4, meaniAnalyProbC,  meaniAskQuesC, meaniChallengedC , meaniConceptsC,  meaniDemoC, meaniEnthusiasmC, meaniHoursC, meaniParticipateC, meaniPreparedC, meaniQuesEffectC, meaniStandardsC, meaniTopicC, meaniUnderstandC, meaniWelQuesC, meansAttendedC, meansEngagedC, meansHelpC, meansPreparedC, meansPositiveC, meansUpToDateC),
                                        names_to='Variable1',
                                        values_to='Mean')
## Pivot again for variance
LBootstrapData <- LBootstrapData %>% pivot_longer(cols=c(varCourseType2, varCourseType3, varCourseType4, variAnalyProbC, variAskQuesC,  variChallengedC ,  variConceptsC, variDemoC, variEnthusiasmC, variHoursC, variParticipateC, variPreparedC, variQuesEffectC, variStandardsC, variTopicC , variUnderstandC, variWelQuesC, varsAttendedC, varsEngagedC, varsHelpC, varsPreparedC, varsPositiveC, varsUpToDateC),
                                        names_to='Variable2',
                                        values_to='Variance') %>%
  
  select(Variable1, Variable2, Variance, Mean) %>%
  mutate(Variable_1 = str_replace(Variable1, "mean", ""),
         Variable_2 = str_replace(Variable2, "var", "")) %>%
  filter(Variable_2==Variable_1) %>%
  rename(Variable=Variable_1) %>%
  select(Variable, Mean, Variance) %>%
  mutate(x=c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23))


# Step 4: Calculate quantiles for highlighting
quantiles <- quantile(abs(LBootstrapData$Mean), probs = c(0.25, 0.75))

# Step 5: Create the plot
CTplot <- ggplot(data = LBootstrapData, aes(y = abs(Mean), x = x)) +
  geom_point() +
  geom_label_repel(aes(label = Variable)) +
  geom_errorbar(aes(ymin=Mean-sqrt(Variance), ymax=Mean+sqrt(Variance)), width=.3) +
  theme_minimal() +
  
  # Customize the x-axis
  scale_x_continuous(breaks = (3.5), 
                     minor_breaks = NULL, 
                     labels = ("Separation Factor")) +
  
  # Adding colored regions based on quantiles
  annotate("rect", xmin = 0, xmax = 24, ymin = 0, ymax = quantiles[1], fill = "red", alpha = 0.2) +
  annotate("rect", xmin = 0, xmax = 24, ymin = quantiles[1], ymax = quantiles[2], fill = "yellow", alpha = 0.2) +
  annotate("rect", xmin = 0, xmax = 24, ymin = max(quantiles[2]), ymax = max(abs(LBootstrapData$Mean)), fill = "green", alpha = 0.2) +
  annotate('text', x=10.5, y=(quantiles[2]+.1), label="Top 25% of Coefficients", color='forestgreen') +
  annotate('text', x=10.5, y=(quantiles[2]+.09), label="Middle 50% of Coefficients", color='yellow4') +
  annotate('text', x=10.5, y=(quantiles[2]+.08), label="Bottom 25% of Coefficients", color='firebrick4') +
  
  # Adding labels and titles
  labs(title = 'Beta Coefficient Averages of Standardized Variables',
       subtitle = 'Variables with the highest average absolute value of their beta coefficients\n have the largest effect on teacher ratings when all variables are treated on the same scale',
       y = "Average of Absolute Value of Beta Coefficients",
       x = "Values do not Matter, Just here to Separate Coefficients")

# Step 6: Display the plot
CTplot


```

```{r, echo=FALSE, warning=FALSE}
# Install lmerTest if you haven't already
#install.packages("lmerTest")


# Define your full mixed-effects model
model_full1 <- lmer(iRating ~ CourseType + 
                   (s_iAnalyProb + s_iAskQues + s_iChallenged + s_iConcepts + s_iDemo +
                    s_iEnthusiasm + s_iHours + s_iParticipate + s_iPrepared + s_iQuesEffect +
                    s_iStandards + s_iTopic + s_iUnderstand + s_iWelQues+s_sAttended+s_sEngaged+s_sHelp+s_sPrepared+s_sPositive+s_sUpToDate) + 
                    (1 | eInstID), 
                   weights = weights, 
                   data = CTStdz_all)
# Perform stepwise model selection
# Output the summary of the stepwise-selected model
#summary(stepwise_model)
# Perform stepwise selection on the mixed-effects model
stepwise_model <- step(model_full1, direction="forward")

# Check the components of stepwise_model to understand the structure
# print(names(stepwise_model))

# Extract the final selected model
final_model <- stepwise_model$finalModel  # Adjust this if the name is different

# Output the summary of the final model
#summary(final_model)
#print(stepwise_model)
```

Lastly, after fitting the full model, a forward stepwise regression was performed to triple check the bootstrapping results. The resulting model is as follows:
*Stepwise Regression Model*
$$iRating = \beta_{1}si_{AnalyProb} + +\beta_{2}si_{Challenged} + \beta_{3}si_{Demo} +$$ $$\beta_{4}si_{Enthusiasm} +\beta_{5}si_{Prepared} +
\beta_{6}si_{QuesEffect} +\beta_{7}si_{Topic} +\beta_{8}si_{WelQues} +$$
$$\beta_{9}ss_{Engaged}+\beta_{10}ss_{Help}+\beta_{11}CT_{2}+\beta_{12}CT_{3}+\beta_{13}CT_{4}$$

All of these variables performed near the top or at least respectably in the shapely analysis. The instructor variables selected include all variables that were in any of the top 25% of any course except iUnderstand (only MKT elective courses), and with only 1 or 2 exceptions in one course type, do not include variables in the bottom 25%. sEngaged has already been discussed as one of the best student behavior questions in terms of predicting overall instructor rating, so it is no surprise it is chosen again in the stepwise model. However, sHelp is chosen, which performed very well in the shapely regression, but poorly in the bootstrapping. In other words, the main analysis suggests it to be a poorer question, but both methods to double check the analysis disagree. Lastly, coursetype is chosen, suggesting a difference in instructor rating across course types, as suggested before.


### Figure 10: Stepwise Model Selected
```{r, echo=FALSE, warning=FALSE}


# Refit the final model after stepwise selection
final_model <- lmer(iRating ~ CourseType + s_iAnalyProb + s_iChallenged + s_iDemo + s_iEnthusiasm + s_iPrepared + s_iQuesEffect + s_iTopic + s_iWelQues + s_sEngaged + s_sHelp + (1 | eInstID),
                    weights = weights, 
                    data = CTStdz_all)


# Extract model summary as a tidy table
tidy_model <- broom.mixed::tidy(final_model)

# Create a clean table using gt
tidy_model %>%
  gt() %>%
  tab_header(
    title = "Final Model Summary",
    subtitle = "Detailed output of the fixed effects"
  ) %>%
  fmt_number(
    columns = vars(estimate, std.error, statistic, p.value),
    decimals = 3
  ) %>%
  cols_label(
    term = "Predictor",
    estimate = "Estimate",
    std.error = "Std. Error",
    statistic = "t-Value",
    p.value = "P-Value"
  )

```

# Conclusion

This analysis of instructor evaluations from Miami University's Marketing courses underscores key factors influencing student assessments of teaching effectiveness, particularly the importance of course challenge, instructor enthusiasm, and clarity of communication. These variables emerged as consistent predictors of higher instructor ratings across different course types. The findings suggest that aligning instructional strategies with these aspects can potentially improve educational quality and student satisfaction.
However, it is important to note that this analysis does not establish causality, as other factors—such as student demographics, course format, and prior expectations—were not included in the model. Additionally, the presence of multicollinearity and limited sample size pose challenges to the interpretation of results. Future research should address these limitations by incorporating qualitative data, such as student feedback or interviews, to gain a more holistic view of student experiences. Expanding the analysis to include diverse academic settings and a wider range of variables will help to better understand the broader determinants of teaching effectiveness.
Across course types there was variety over which questions, both instructor and student related, resulted in the best outcomes. Therefore, if the marketing department wants to keep a consistent evaluation across most courses, the only reccomendation would be to take into account whether or not to keep variables that performed poorly across all analyses, such as iHours, iStandards and sAttended, in the evaluations. It also may be nice to inform professors, depedning on the course they are teaching, which values students find most important when it comes to giving an overall rating, since there is variation across course types.


# References
Bock, T. (2020a, December 9). What are Variance Inflation Factors (VIFs)? | Displayr.com. Displayr. https://www.displayr.com/variance-inflation-factors-vifs/#:~:text=Use%20techniques%20designed%20to%20work%20better%20with%20high,are%20less%20correlated%20%28e.g.%2C%20by%20conducting%20an%20experiment%29

Bock, T. (2020, December 9). What is Shapley Value Regression? | Displayr.com. Displayr. https://www.displayr.com/shapley-value-regression/#:~:text=Shapley%20Value%20regression%20is%20a%20technique

Bootstrap resampling and tidy regression models – tidymodels. (n.d.). https://www.tidymodels.org/learn/statistics/bootstrap/


Date, S. (2024, June 24). The Random Effects Regression model for panel data sets - Statistical modeling and forecasting. Statistical Modeling and Forecasting. https://timeseriesreasoning.com/contents/the-random-effects-regression-model-for-panel-data-sets/#:~:text=How%20to%20implement%20the%20Random%20Effects#:~:text=How%20to%20implement%20the%20Random%20Effects

Frost, Jim. Intro to Bootstrapping in Statistics with an Example (n.d.). https://statisticsbyjim.com/hypothesis-testing/bootstrapping/

Hughes, Micheal (2024, September) Data Analytics Practicum

Insert picture/table in R Markdown. (n.d.). Stack Overflow. https://stackoverflow.com/questions/25166624/insert-picture-table-in-r-markdown#:~:text=So%20I%20want%20to%20insert%20a%20table%20AND%20a#:~:text=So%20I%20want%20to%20insert%20a%20table%20AND%20a

R: The R Project for Statistical Computing. (n.d.). https://www.r-project.org/

Riederer, Y. X. C. D. E. (2024, September 17). R Markdown Cookbook. https://bookdown.org/yihui/rmarkdown-cookbook/

What is Shapley value regression and how does one implement it? (n.d.). Cross Validated. https://stats.stackexchange.com/questions/234874/what-is-shapley-value-regression-and-how-does-one-implement-it#:~:text=The%20Shapley%20Value%20Regression:%20Shapley

# Appendix

## Code
```{r, eval=FALSE}

knitr::opts_chunk$set(echo = TRUE)
if (!require("knitr")) install.packages("knitr")
if (!require("ggplot2")) install.packages("ggplot2")
if (!require("dplyr")) install.packages("dplyr")
if (!require("tidyverse")) install.packages("tidyverse")
if (!require("gridExtra")) install.packages("gridExtra")
if (!require("ggcorrplot")) install.packages("ggcorrplot")
if (!require("viridis")) install.packages("viridis")
if (!require("pheatmap")) install.packages("pheatmap")
if (!require("ggrepel")) install.packages("ggrepel")
if (!require("tidymodels")) install.packages("tidymodels")
if (!require("car")) install.packages("car")
if (!require("ShapleyValue")) install.packages("ShapleyValue")
if (!require("lme4")) install.packages("lme4")
if(!require("kableExtra")) install.packages("kableExtra")
if (!require("broom.mixed")) install.packages("broom.mixed")
if(!require("gt")) install.packages("gt")
if(!require("sjPlot")) install.packages("sjPlot")
library(knitr)
library(kableExtra)
library(ggplot2)
library(dplyr)
library(tidyverse)
library(gridExtra)
library(rstatix)
library(gridExtra)
library(ggcorrplot)
library(viridis)
library(pheatmap)
library(ggrepel)
library(tidymodels)
library(car)
library(ShapleyValue)

# May need to run this if lme4 isnt loading properly
#utils::install.packages("lme4", type = "source")
library(lme4)
library(lmerTest)
library(broom.mixed)
library(gt)
library(sjPlot)




knitr::include_graphics('C:/DESKTOP/SEMESTER 7/STA 660/MKT Faculty Evaluation Investigation/TeacherQuestions.jpg') 
knitr::include_graphics('C:/DESKTOP/SEMESTER 7/STA 660/MKT Faculty Evaluation Investigation/StudentQuestions.jpg') 

## Could not get website upload to work
#knitr::include_graphics('https://tinypic.host/image/TeacherQuestions.2Pz0X1')




#### Load in data


# Immediately, want at least 6 completed surveys or 75% completion rate (lowest class enrollment is 8, would give 6 out of 8)
MKTRaw <- read.csv("C:/DESKTOP/SEMESTER 7/STA 660/MKT Faculty Evaluation Investigation/CombinedData.csv") 


shapleyi <- read.csv("C:/DESKTOP/SEMESTER 7/STA 660/MKT Faculty Evaluation Investigation/ShapleyDatai.csv", header=TRUE) %>%
  rename(iChallenged = iChalleneged)

MKTRaw <- MKTRaw %>%
  mutate(CompRate = Completed/Enrolled) %>%
  filter(CompRate > .75 | Completed >= 6)




## Summary Statistics and correlation plots
MKTSumStats <- MKTRaw %>% select(-Term, -InstID, -CourseType) %>%
 summarise(across(where(is.numeric), .fns = 
                     list(Mean = mean,
                          Stdev = sd,
                          Min = min,
                          Q25 = ~quantile(., 0.25),
                          Median = median,
                          Q75 = ~quantile(., 0.75),
                          Max = max))) %>%
  pivot_longer(everything(), names_sep='_', names_to=c('Variable', '.value')) %>%
  mutate(Mean = round(Mean, digits=2),
         Stdev = round(Stdev, digits=2))

kable(MKTSumStats, booktabs = TRUE) %>%
  kable_styling(font_size = 8)



# Standardizing



## Grouping by CourseType

  #Weighting and then Standardizing:

# Step 2: Standardize the weighted variables
# Standardize all the weighted instructor and student behavior variables
CT <- MKTRaw  %>%
  group_by(CourseType) %>%
  rename(eInstID = InstID) %>%
  mutate(CourseType = factor(CourseType))


# Step 1: Weight the variables by the number of completed evaluations
# Create a new dataframe with weighted variables
WeightedData <- CT %>%
  mutate(across(starts_with("i"), ~ .x * Completed, .names = "w_{col}")) %>%
  mutate(across(starts_with("s"), ~ .x * Completed, .names = "w_{col}"))

# Step 2: Standardize the variables
# Standardize all the weighted instructor and student behavior variables
## FOR EACH COURSE TYPE
CTStdz_1 <- WeightedData %>%
  filter(CourseType==1) %>%
  mutate(across(starts_with("i"), ~ (scale(.x))[,1], .names = "s_{col}"),
         across(starts_with("s"), ~(scale(.x))[,1], .names = "s_{col}"),
         weights = Completed/sum(Completed)) %>%
  select(iRating, s_iAnalyProb, s_iAskQues, s_iChallenged, s_iConcepts, s_iDemo, s_iEnthusiasm, s_iHours, s_iParticipate, s_iPrepared, s_iQuesEffect, s_iStandards, s_iTopic, s_iUnderstand, s_iWelQues, s_sAttended, s_sEngaged, s_sHelp,  s_sPrepared, s_sPositive, s_sUpToDate, Completed, eInstID, weights)


CTStdz_2 <- WeightedData %>%
  filter(CourseType==2) %>%
  mutate(across(starts_with("i"), ~ (scale(.x))[,1], .names = "s_{col}"),
         across(starts_with("s"), ~(scale(.x))[,1], .names = "s_{col}"),
         weights = Completed/sum(Completed)) %>%
  select(iRating, s_iAnalyProb, s_iAskQues, s_iChallenged, s_iConcepts, s_iDemo, s_iEnthusiasm, s_iHours, s_iParticipate, s_iPrepared, s_iQuesEffect, s_iStandards, s_iTopic, s_iUnderstand, s_iWelQues, s_sAttended, s_sEngaged, s_sHelp,  s_sPrepared, s_sPositive, s_sUpToDate, Completed, eInstID, weights)


CTStdz_3 <- WeightedData %>%
  filter(CourseType==3) %>%
  mutate(across(starts_with("i"), ~ (scale(.x))[,1], .names = "s_{col}"),
         across(starts_with("s"), ~(scale(.x))[,1], .names = "s_{col}"),
         weights = Completed/sum(Completed)) %>%
  select(iRating, s_iAnalyProb, s_iAskQues, s_iChallenged, s_iConcepts, s_iDemo, s_iEnthusiasm, s_iHours, s_iParticipate, s_iPrepared, s_iQuesEffect, s_iStandards, s_iTopic, s_iUnderstand, s_iWelQues, s_sAttended, s_sEngaged, s_sHelp,  s_sPrepared, s_sPositive, s_sUpToDate, Completed, eInstID, weights)


CTStdz_4 <- WeightedData %>%
  filter(CourseType==4) %>%
  mutate(across(starts_with("i"), ~ (scale(.x))[,1], .names = "s_{col}"),
         across(starts_with("s"), ~(scale(.x))[,1], .names = "s_{col}"),
         weights = Completed/sum(Completed)) %>%
  select(iRating, s_iAnalyProb, s_iAskQues, s_iChallenged, s_iConcepts, s_iDemo, s_iEnthusiasm, s_iHours, s_iParticipate, s_iPrepared, s_iQuesEffect, s_iStandards, s_iTopic, s_iUnderstand, s_iWelQues, s_sAttended, s_sEngaged, s_sHelp,  s_sPrepared, s_sPositive, s_sUpToDate, Completed, eInstID, weights)
# Now, "std_weighted_*" columns contain standardized values


CTStdz_all <- WeightedData %>%
  mutate(across(starts_with("i"), ~ (scale(.x))[,1], .names = "s_{col}"),
         across(starts_with("s"), ~(scale(.x))[,1], .names = "s_{col}"),
         weights = Completed/sum(Completed)) %>%
  select(iRating, s_iAnalyProb, s_iAskQues, s_iChallenged, s_iConcepts, s_iDemo, s_iEnthusiasm, s_iHours, s_iParticipate, s_iPrepared, s_iQuesEffect, s_iStandards, s_iTopic, s_iUnderstand, s_iWelQues, s_sAttended, s_sEngaged, s_sHelp,  s_sPrepared, s_sPositive, s_sUpToDate, Completed, eInstID, weights)

# View a sample of the data

# Get the names of all standardized variables except the target variable
#CTStdz_i1 <- CTStdz_1 %>%
#  select(-s_sAttended, -s_sEngaged, -s_sHelp,  -s_sPrepared, -s_sPositive, -s_sUpToDate)
#predictor_vars_i <- names(CTStdz_i1)[grepl("^s_", names(CTStdz_i1)) & names(CTStdz_i1) != "std_iRating"]
#CTStdz_s1 <- CTStdz_1 %>%
#  select(s_sAttended, s_sEngaged, s_sHelp,  s_sPrepared, s_sPositive, s_sUpToDate, eInstID, Completed)
#predictor_vars_s <- names(CTStdz_s1)[grepl("^s_", names(CTStdz_s1)) & names(CTStdz_s1) != "s_iRating"]







model.CT1i  <- lmer(iRating ~ ((s_iAnalyProb+ s_iAskQues+ s_iChallenged+ s_iConcepts+ s_iDemo + s_iEnthusiasm+ s_iHours+ s_iParticipate+ s_iPrepared+ s_iQuesEffect+ s_iStandards+ s_iTopic+ s_iUnderstand+ s_iWelQues) + (1 | eInstID)), weights=weights, data = CTStdz_1)
#summary(model.CT1i)

## Create CourseType 1 data set to show difference
CT1_vifTest <- MKTRaw  %>%
  filter(CourseType==1) %>%
  mutate(weights = Completed/sum(Completed))

model.CT1i_noStdz  <- lmer(iRating ~ ((iAnalyProb+ iAskQues+ iChallenged+ iConcepts+ iDemo + iEnthusiasm+ iHours+ iParticipate+ iPrepared+ iQuesEffect+ iStandards+ iTopic+ iUnderstand+ iWelQues) + (1 | InstID)), weights=weights, data = CT1_vifTest)
#summary(model.CT1i_noStdz)

# Calculate VIF values and compare
vif_values_stdz <- vif(model.CT1i)
vif_values_reg <-vif(model.CT1i_noStdz)
vifComp <- data.frame(Standardized = vif_values_stdz, Regular=vif_values_reg) %>%
  mutate(Difference = Standardized-Regular)

kable(vifComp, booktabs = TRUE) %>%
  kable_styling(font_size = 8)



citation('knitr')
citation('kableExtra')
citation('ggplot2')
citation('dplyr')
citation('tidyverse')
citation('gridExtra')
citation('rstatix')
citation('ggcorrplot')
citation('viridis')
citation('pheatmap')
citation('ggrepel')
citation('tidymodels')
citation('car')
citation('ShapleyValue')
citation('lme4')




# Select numeric columns from the dataset
survey_data <- MKTRaw %>%
  select_if(is.numeric)

# Calculate the correlation matrix using complete observations
corr_matrix <- cor(survey_data, use = "complete.obs")

# Plot the heatmap with clustering
pheatmap(corr_matrix,
         clustering_distance_rows = "euclidean",  # Can be changed to "correlation" for a correlation-based distance
         clustering_distance_cols = "euclidean",
         clustering_method = "complete",          # Clustering method, e.g., "complete", "average", "single"
         color = viridis::viridis(100),           # Use the viridis color scale
         main = "Correlation Heatmap with Clustering",
         display_numbers = FALSE,                 # Remove numbers from the cells
         fontsize_row = 10,                       # Adjust row font size for readability
         fontsize_col = 10,                       # Adjust column font size for readability
         legend = TRUE                            # Display the color legend
)





# Look at average student self eval scores versus teacher evaluation rating
MKTOverall <- MKTRaw %>%
  mutate(sRating = round((sPositive+sAttended+sPrepared+sEngaged+sUpToDate+sHelp)/6, digits=2),
         CourseType=factor(CourseType),
         TotaliRating = Completed*iRating,
         TotalsRating = Completed*sRating) %>%
# Notice if no one filled out evaluation, then scores are 0, can remove
  filter(Completed!=0)

ggplot(MKTOverall, aes(x=sRating, y=iRating, color=CourseType)) +
  geom_point()+
  theme_minimal() +
  scale_x_continuous(limits = c(0,4)) +
  scale_y_continuous(limits = c(0,4)) +
  labs(title="Student Self-Eval Average Rating versus Professors Rating",
       y="Instructor Rating",
       x="Student Average Rating")





## Grouping by professor
TeacherGroup <- MKTOverall %>%
  group_by(InstID, CourseType) %>%
  mutate(CompletedTotal = sum(Completed),
         iRatingTotal = sum(TotaliRating),
         iRatingAverage = iRatingTotal/CompletedTotal,
         sRatingTotal = sum(TotalsRating),
         sRatingAverage = sRatingTotal/CompletedTotal) %>%
  select(iRatingAverage, CompletedTotal, iRatingTotal, sRatingTotal, sRatingAverage, CourseType, InstID) %>%
  distinct()

TeacherGroup1 <- TeacherGroup %>% filter(CourseType==1)
TeacherGroup2 <- TeacherGroup %>% filter(CourseType==2)
TeacherGroup3 <- TeacherGroup %>% filter(CourseType==3)
TeacherGroup4 <- TeacherGroup %>% filter(CourseType==4)
#model1 <- lm(iRatingAverage~sRatingAverage, data=TeacherGroup1)
#summary(model1)
group1x <- 1.9883
group1start <- -4.3299 + 2.1777*group1x
group1end <- -4.3299 + 2.1777*4
#model2 <- lm(iRatingAverage~sRatingAverage, data=TeacherGroup2)
#summary(model2)
group2x <- 1.4
group2start <- -2.1017 + 1.5011*group2x
group2end <- -2.1017 + 1.5011*4
#model3 <- lm(iRatingAverage~sRatingAverage, data=TeacherGroup3)
#summary(model3)

group3x <- 0.7215
group3start <- -0.8469 + 1.1738*group3x
group3end <- -0.8469 + 1.1738*4
#model4 <- lm(iRatingAverage~sRatingAverage, data=TeacherGroup4)
#summary(model4)

group4x <- 2.7851
group4start <- -9.692 + 3.480*group4x
group4end <- -9.692 + 3.480*4

ggplot(data=TeacherGroup, aes(x=sRatingAverage, y=iRatingAverage, color=CourseType)) +
  geom_point() +
  theme_minimal() +
  scale_x_continuous(limits=c(0, 4)) +
  #scale_y_continuous(limits=c(0,4)) +
  labs(title="Student Self-Eval Average Rating versus Professors Rating",
  subtitle="Teacher and Student ratings averaged across all of a professors courses, with a regression line for each course type",
       y="Instructor Average Rating",
       x="Student Average Rating") +
  annotate(geom="segment", x=group1x, xend=4, y=group1start, yend=group1end, color="red", size=.75) +
  annotate(geom="segment", x=group2x, xend=4, y=group2start, yend=group2end, color="green", size=.75) +
  annotate(geom="segment", x=group3x, xend=4, y=group3start, yend=group3end, color="skyblue3", size=.75) +
  annotate(geom="segment", x=group4x, xend=4, y=group4start, yend=group4end, color="purple1", size=.75)






plotAnalyProb <- ggplot(MKTOverall, aes(y=iRating, x=iAnalyProb, color=CourseType)) +
  geom_point() +
  theme_minimal() +
  theme(legend.position="none")
#  labs(title="Professors Overall Rating versus AnalyProb Rating",
#       y="Instructor Average Rating",
#       x="AnalyProb Rating")

plotChallenged <- ggplot(MKTOverall, aes(y=iRating, x=iChallenged, color=CourseType)) +
  geom_point() +
  theme_minimal() +
  theme(legend.position="none")
#  labs(title="Professors Overall Rating versus Challenged Rating",
#       y="Instructor Average Rating",
#       x="Challenged Rating")


plotConcepts <- ggplot(MKTOverall, aes(y=iRating, x=iConcepts, color=CourseType)) +
  geom_point() +
  theme_minimal() +
  theme(legend.position="none")
 # labs(title="Professors Overall Rating versus Concepts Rating",
#       y="Instructor Average Rating",
#       x="Concepts Rating")


plotDemo <- ggplot(MKTOverall, aes(y=iRating, x=iDemo, color=CourseType)) +
  geom_point() +
  theme_minimal() +
  theme(legend.position="none")
#  labs(title="Professors Overall Rating versus Demo Rating",
#       y="Instructor Average Rating",
#       x="Demo Rating")

plotHours <- ggplot(MKTOverall, aes(y=iRating, x=iHours, color=CourseType)) +
  geom_point() +
  theme_minimal() +
  theme(legend.position="none")
#  labs(title="Professors Overall Rating versus Hours Rating",
#       y="Instructor Average Rating",
#       x="Hours Rating")

plotParticipate <- ggplot(MKTOverall, aes(y=iRating, x=iParticipate, color=CourseType)) +
  geom_point() +
  theme_minimal() +
  theme(legend.position="none")
#  labs(title="Professors Overall Rating versus Participate Rating",
#       y="Instructor Average Rating",
#       x="Participate Rating")

plotPrepared <- ggplot(MKTOverall, aes(y=iRating, x=iPrepared, color=CourseType)) +
  geom_point() +
  theme_minimal() +
  theme(legend.position="none")
#  labs(title="Professors Overall Rating versus Prepared Rating",
#       y="Instructor Average Rating",
#       x="Prepared Rating")

plotQuesEffect <- ggplot(MKTOverall, aes(y=iRating, x=iQuesEffect, color=CourseType)) +
  geom_point() +
  theme_minimal() +
  theme(legend.position="none")
#  labs(title="Professors Overall Rating versus QuesEffect Rating",
#       y="Instructor Average Rating",
#       x="QuesEffect Rating")

plotStandards <- ggplot(MKTOverall, aes(y=iRating, x=iStandards, color=CourseType)) +
  geom_point() +
  theme_minimal() +
  theme(legend.position="none")
#  labs(title="Professors Overall Rating versus Standards Rating",
#       y="Instructor Average Rating",
#       x="Standards Rating")

plotTopic <- ggplot(MKTOverall, aes(y=iRating, x=iTopic, color=CourseType)) +
  geom_point() +
  theme_minimal() +
  theme(legend.position="none")
 # labs(title="Professors Overall Rating versus Topic Rating",
 #      y="Instructor Average Rating",
#       x="Topic Rating")

plotUnderstand <- ggplot(MKTOverall, aes(y=iRating, x=iUnderstand, color=CourseType)) +
  geom_point() +
  theme_minimal() +
  theme(legend.position="none")
  #labs(title="Professors Overall Rating versus Understand Rating",
 #      y="Instructor Average Rating",
 #      x="Understand Rating")

plotWelQues <- ggplot(MKTOverall, aes(y=iRating, x=iWelQues, color=CourseType)) +
  geom_point() +
  theme_minimal() +
  theme(legend.position="none")
 # labs(title="Professors Overall Rating versus WelQues Rating",
#       y="Instructor Average Rating",
 #      x="WelQues Rating")


grid.arrange(plotAnalyProb, plotChallenged,
plotConcepts,
plotDemo,
plotHours,
plotParticipate,
plotPrepared,
plotQuesEffect,
plotStandards,
plotTopic,
plotUnderstand,
plotWelQues,
ncol=3, nrow = 4)




plotAttended <- ggplot(MKTOverall, aes(y=iRating, x=sAttended, color=CourseType)) +
  geom_point() +
  theme_minimal() +
  theme(legend.position="none")
#  labs(title="Professors Overall Rating versus student Attended Rating",
#       y="Instructor Average Rating",
#       x="Prepared Rating")

plotEngaged <- ggplot(MKTOverall, aes(y=iRating, x=sEngaged, color=CourseType)) +
  geom_point() +
  theme_minimal() +
  theme(legend.position="none")
#  labs(title="Professors Overall Rating versus student Engaged Rating",
#       y="Instructor Average Rating",
#       x="QuesEffect Rating")

plotHelp <- ggplot(MKTOverall, aes(y=iRating, x=sHelp, color=CourseType)) +
  geom_point() +
  theme_minimal() +
  theme(legend.position="none")
#  labs(title="Professors Overall Rating versus student Help Rating",
#       y="Instructor Average Rating",
#       x="Standards Rating")

plotPrepared <- ggplot(MKTOverall, aes(y=iRating, x=sPrepared, color=CourseType)) +
  geom_point() +
  theme_minimal() +
  theme(legend.position="none")
 # labs(title="Professors Overall Rating versus student Prepared Rating",
 #      y="Instructor Average Rating",
#       x="Topic Rating")

plotPositive <- ggplot(MKTOverall, aes(y=iRating, x=sPositive, color=CourseType)) +
  geom_point() +
  theme_minimal() +
  theme(legend.position="none")
  #labs(title="Professors Overall Rating versus student Positive Rating",
 #      y="Instructor Average Rating",
 #      x="Understand Rating")

plotUpToDate <- ggplot(MKTOverall, aes(y=iRating, x=sUpToDate, color=CourseType)) +
  geom_point() +
  theme_minimal() +
  theme(legend.position="none")
 # labs(title="Professors Overall Rating versus student UpToDate Rating",
#       y="Instructor Average Rating",
 #      x="WelQues Rating")


grid.arrange(plotAttended, plotEngaged, plotHelp, plotPrepared, plotPositive, plotUpToDate,
ncol=2, nrow = 3)



#iRating <- CT1_vifTest$iRating
#x <- as.data.frame(CT1_vifTest[,12:26]) %>%
 # select(-iRating)
#shapleyvalue(iRating, x)
shapleyiTable <- shapleyi %>% pivot_longer(cols=c('iAnalyProb', 'iAskQues', 'iChallenged', 'iConcepts', 'iDemo', 'iEnthusiasm', 'iHours', 'iParticipate', 'iPrepared', 'iQuesEffect', 'iStandards', 'iTopic', 'iUnderstand', 'iWelQues'),
                          names_to="Variable",
                          values_to="Shapely") %>%
  arrange(desc(Shapely)) %>%
  filter(S=='Standardized Shapley Value')
kable(shapleyiTable)




iRating <- CT1_vifTest$iRating
xs <- as.data.frame(CT1_vifTest[,6:11])
 # select(-iRating)
shapleys <- shapleyvalue(iRating, xs) %>%
  mutate(S = c('Shapely Value', 'Standardized Shapley Value'))
shapleysTable <- shapleys %>% pivot_longer(cols=c('sAttended', 'sEngaged', 'sHelp', 'sPositive', 'sPrepared', 'sUpToDate'),
                          names_to="Variable",
                          values_to="Shapely") %>%
  arrange(desc(Shapely)) %>%
  filter(S=='Standardized Shapley Value')
kable(shapleysTable)





## Bootstrap 1000 models for CourseType 1 instructor variables


set.seed(09272024)

## Idea for full model
##full.modeli.1 <- lm(data=Teacher1Stdz, iRating ~ iAskQuesS + iAnalyProbS + iChallengedS + iConceptsS +iDemoS +iEnthusiasmS +iHoursS + iParticipateS + iPreparedS + iQuesEffectS + iStandardsS + iTopicS + iUnderstandS + iWelQuesS )
##summary(full.modeli.1)

## BOOTSRAPPING BY HAND

sample_coef_intercept <- NULL
sample_coef_df_x1 <- NULL
sample_coef_df_x2 <- NULL
sample_coef_df_x3 <- NULL
sample_coef_df_x4 <- NULL
sample_coef_df_x5 <- NULL
sample_coef_df_x6 <- NULL
sample_coef_df_x7 <- NULL
sample_coef_df_x8 <- NULL
sample_coef_df_x9 <- NULL
sample_coef_df_x10 <- NULL
sample_coef_df_x11 <- NULL
sample_coef_df_x12 <- NULL
sample_coef_df_x13 <- NULL
sample_coef_df_x14 <- NULL


for (i in 1:1000) {
  #Creating a resampled dataset from the sample data
  sample_d = CTStdz_1[sample(1:nrow(CTStdz_1), nrow(CTStdz_1), replace = TRUE), ]
 # sample_d_totalcompleted <-  sample_d %>% summarize(totalcomp = sum(Completed))
  sample_d_w <- sample_d %>%
    mutate(weight = Completed/sum(Completed))
  
  #Running the regression on these data
  model_bootstrap  <- lmer(iRating ~ ((s_iAnalyProb+ s_iAskQues+ s_iChallenged+ s_iConcepts+ s_iDemo + s_iEnthusiasm+ s_iHours+ s_iParticipate+ s_iPrepared+ s_iQuesEffect+ s_iStandards+ s_iTopic+ s_iUnderstand+ s_iWelQues) + (1 | eInstID)), weights=weight, data = sample_d_w)
  bootsum <- summary(model_bootstrap)
  
    #Saving the coefficients
  sample_coef_intercept <-
    c(sample_coef_intercept, bootsum$coefficients[1])
  
  sample_coef_df_x1 <- c(sample_coef_df_x1, bootsum$coefficients[2])
  sample_coef_df_x2 <- c(sample_coef_df_x2, bootsum$coefficients[3])
  sample_coef_df_x3 <- c(sample_coef_df_x3, bootsum$coefficients[4])
  sample_coef_df_x4 <- c(sample_coef_df_x4, bootsum$coefficients[5])
  sample_coef_df_x5 <- c(sample_coef_df_x5, bootsum$coefficients[6])
  sample_coef_df_x6 <- c(sample_coef_df_x6, bootsum$coefficients[7])
  sample_coef_df_x7 <- c(sample_coef_df_x7, bootsum$coefficients[8])
  sample_coef_df_x8 <- c(sample_coef_df_x8, bootsum$coefficients[9])
  sample_coef_df_x9 <- c(sample_coef_df_x9, bootsum$coefficients[10])
  sample_coef_df_x10 <- c(sample_coef_df_x10, bootsum$coefficients[11])
  sample_coef_df_x11 <- c(sample_coef_df_x11, bootsum$coefficients[12])
  sample_coef_df_x12 <- c(sample_coef_df_x12, bootsum$coefficients[13])
  sample_coef_df_x13 <- c(sample_coef_df_x13, bootsum$coefficients[14])
  sample_coef_df_x14 <- c(sample_coef_df_x14, bootsum$coefficients[15])
}

## Want ABSOLUTE values to show overall affect on iRating (-.3 has as much of an effect as .3)
absCoefsDF <- data.frame(iAnalyProbC=abs(sample_coef_df_x1), 
                      iAskQuesC=abs(sample_coef_df_x2),
                      iChallengedC=abs(sample_coef_df_x3),
                      iConceptsC=abs(sample_coef_df_x4),
                      iDemoC=abs(sample_coef_df_x5),
                      iEnthusiasmC=abs(sample_coef_df_x6),
                      iHoursC=abs(sample_coef_df_x7),
                      iParticipateC=abs(sample_coef_df_x8),
                      iPreparedC=abs(sample_coef_df_x9),
                      iQuesEffectC=abs(sample_coef_df_x10),
                      iStandardsC=abs(sample_coef_df_x11),
                      iTopicC=abs(sample_coef_df_x12),
                      iUnderstandC=abs(sample_coef_df_x13),
                      iWelQuesC=abs(sample_coef_df_x14))

BootstrapData <- absCoefsDF %>%
  summarize(meaniAnalyProbC = mean(iAnalyProbC), variAnalyProbC = var(iAnalyProbC),q1iAnalyProbC = quantile(iAnalyProbC, probs=.25), q2iAnalyProbC = quantile(iAnalyProbC, probs=.5), q3iAnalyProbC = quantile(iAnalyProbC, probs=.75),
            meaniAskQuesC = mean(iAskQuesC), variAskQuesC = var(iAskQuesC), q1iAskQuesC = quantile(iAskQuesC, probs=.25), q2iAskQuesC = quantile(iAskQuesC, probs=.5), q3iAskQuesC = quantile(iAskQuesC, probs=.75),
            meaniChallengedC = mean(iChallengedC), variChallengedC = var(iChallengedC), q1iChallengedC = quantile(iChallengedC, probs=.25), q2iChallengedC = quantile(iChallengedC, probs=.5), q3iChallengedC = quantile(iChallengedC, probs=.75),
            meaniConceptsC = mean(iConceptsC), variConceptsC = var(iConceptsC), q1iConceptsC = quantile(iConceptsC, probs=.25), q2iConceptsC = quantile(iConceptsC, probs=.5), q3iConceptsC = quantile(iConceptsC, probs=.75),
            meaniDemoC = mean(iDemoC), variDemoC = var(iDemoC), q1iDemoC = quantile(iDemoC, probs=.25), q2iDemoC = quantile(iDemoC, probs=.5), q3iDemoC = quantile(iDemoC, probs=.75), 
            meaniEnthusiasmC = mean(iEnthusiasmC), variEnthusiasmC = var(iEnthusiasmC), q1iEnthusiasmC = quantile(iEnthusiasmC, probs=.25), q2iEnthusiasmC = quantile(iEnthusiasmC, probs=.5), q3iEnthusiasmC = quantile(iEnthusiasmC, probs=.75),
            meaniHoursC = mean(iHoursC), variHoursC = var(iHoursC), q1iHoursC = quantile(iHoursC, probs=.25), q2iHoursC = quantile(iHoursC, probs=.5), q3iHoursC = quantile(iHoursC, probs=.75),
            meaniParticipateC = mean(iParticipateC), variParticipateC = var(iParticipateC), q1iParticipateC = quantile(iParticipateC, probs=.25), q2iParticipateC = quantile(iParticipateC, probs=.5), q3iParticipateC = quantile(iParticipateC, probs=.75),
            meaniPreparedC = mean(iPreparedC), variPreparedC = var(iPreparedC), q1iPreparedC = quantile(iPreparedC, probs=.25), q2iPreparedC = quantile(iPreparedC, probs=.5), q3iPreparedC = quantile(iPreparedC, probs=.75),
            meaniQuesEffectC = mean(iQuesEffectC), variQuesEffectC = var(iQuesEffectC), q1iQuesEffectC = quantile(iQuesEffectC, probs=.25), q2iQuesEffectC = quantile(iQuesEffectC, probs=.5), q3iQuesEffectC = quantile(iQuesEffectC, probs=.75),
            meaniStandardsC = mean(iStandardsC), variStandardsC = var(iStandardsC), q1iStandardsC = quantile(iStandardsC, probs=.25),  q2iStandardsC = quantile(iStandardsC, probs=.5), q3iStandardsC = quantile(iStandardsC, probs=.75),
            meaniTopicC = mean(iTopicC), variTopicC = var(iTopicC), q1iTopicC = quantile(iTopicC, probs=.25), q2iTopicC = quantile(iTopicC, probs=.5), q3iTopicC = quantile(iTopicC, probs=.75),
            meaniUnderstandC = mean(iUnderstandC), variUnderstandC = var(iUnderstandC), q1iUnderstandC = quantile(iUnderstandC, probs=.25), q2iUnderstandC = quantile(iUnderstandC, probs=.5), q3iUnderstandC = quantile(iUnderstandC, probs=.75),
            meaniWelQuesC = mean(iWelQuesC), variWelQuesC = var(iWelQuesC), q1iWelQuesC = quantile(iWelQuesC, probs=.25), q2iWelQuesC = quantile(iWelQuesC, probs=.5), q3iWelQuesC = quantile(iWelQuesC, probs=.75))

# Pivot Data
LBootstrapData <- BootstrapData%>% pivot_longer(cols=c(meaniAnalyProbC,  meaniAskQuesC, meaniChallengedC , meaniConceptsC,  meaniDemoC, meaniEnthusiasmC, meaniHoursC, meaniParticipateC, meaniPreparedC, meaniQuesEffectC, meaniStandardsC, meaniTopicC, meaniUnderstandC, meaniWelQuesC),
                                        names_to='Variable1',
                                        values_to='Mean')
## Pivot again for variance
LBootstrapData <- LBootstrapData %>% pivot_longer(cols=c(variAnalyProbC, variAskQuesC,  variChallengedC ,  variConceptsC, variDemoC, variEnthusiasmC, variHoursC, variParticipateC, variPreparedC, variQuesEffectC, variStandardsC, variTopicC , variUnderstandC, variWelQuesC),
                                        names_to='Variable2',
                                        values_to='Variance') %>%
  
  select(Variable1, Variable2, Variance, Mean) %>%
  mutate(Variable_1 = str_replace(Variable1, "mean", ""),
         Variable_2 = str_replace(Variable2, "var", "")) %>%
  filter(Variable_2==Variable_1) %>%
  rename(Variable=Variable_1) %>%
  select(Variable, Mean, Variance) %>%
  mutate(x=c(1,2,3,4,5,6,7,8,9,10,11,12,13,14))




# Plotting Averages i, coursetyp 1
# Plotting Coursetype 1 instructor vars
quantiles <- quantile(abs(LBootstrapData$Mean), probs=c(.25, .75))


CT1iplot <- ggplot(data=LBootstrapData, aes(y=abs(Mean), x=x)) +
  geom_point()  +
  geom_errorbar(aes(ymin=Mean-sqrt(Variance), ymax=Mean+sqrt(Variance)), width=.3) +
  geom_label_repel(aes(label=Variable)) +
  #geom_jitter(height=0, width=.5) +
  theme_minimal() +
  scale_x_continuous(breaks = (7),
                     minor_breaks= NULL,
                     labels=("Separation Factor"))+
  annotate("rect", xmin=-1, xmax=15, ymin=0, ymax=quantiles[1], fill="red", alpha=.2) +
  annotate("rect", xmin=-1, xmax=15, ymin=quantiles[1], ymax=quantiles[2], fill="yellow", alpha=.2) +
  annotate("rect", xmin=-1, xmax=15, ymin=quantiles[2], ymax=.27, fill="green", alpha=.2) +
  #annotate('text', x=1.5, y=(quantiles[2]+.1), label="Top 25% of Coefficients", color='forestgreen') +
  #annotate('text', x=1.5, y=(quantiles[2]+.09), label="Middle 50% of Coefficients", color='yellow4') +
  #annotate('text', x=1.5, y=(quantiles[2]+.08), label="Bottom 25% of Coefficients", color='firebrick4') +
  labs(title='Beta Coefficient Averages of Standardized test Variables for FSB Core Instructors',
       subtitle='Ignoring horizontal placement, variables with the highest absolute value of their beta coefficient have\n the largest affect on a teachers rating when all variables are treated on the same scale',
       y="Average of Absolute Value of Beta Coefficients of Standardized\n Questions and 1 Standard Deviation Above and Below the Mean",
       x="Values do not Matter, Just here to Separate Coefficeint Averages in Alphabetical Order")




set.seed(09272024)

# Bootsrtapping Model for Overall Rating Using Standardized Predictors for CourseType 2 Instructor Questions


## BOOTSRAPPING BY HAND

sample_coef_intercept <- NULL
sample_coef_df_x1 <- NULL
sample_coef_df_x2 <- NULL
sample_coef_df_x3 <- NULL
sample_coef_df_x4 <- NULL
sample_coef_df_x5 <- NULL
sample_coef_df_x6 <- NULL
sample_coef_df_x7 <- NULL
sample_coef_df_x8 <- NULL
sample_coef_df_x9 <- NULL
sample_coef_df_x10 <- NULL
sample_coef_df_x11 <- NULL
sample_coef_df_x12 <- NULL
sample_coef_df_x13 <- NULL
sample_coef_df_x14 <- NULL


for (i in 1:1000) {
  #Creating a resampled dataset from the sample data
  sample_d = CTStdz_2[sample(1:nrow(CTStdz_2), nrow(CTStdz_2), replace = TRUE), ]
 # sample_d_totalcompleted <-  sample_d %>% summarize(totalcomp = sum(Completed))
  sample_d_w <- sample_d %>%
    mutate(weight = Completed/sum(Completed))
  
  #Running the regression on these data
  model_bootstrap  <- lmer(iRating ~ ((s_iAnalyProb+ s_iAskQues+ s_iChallenged+ s_iConcepts+ s_iDemo + s_iEnthusiasm+ s_iHours+ s_iParticipate+ s_iPrepared+ s_iQuesEffect+ s_iStandards+ s_iTopic+ s_iUnderstand+ s_iWelQues) + (1 | eInstID)), weights=weight, data = sample_d_w)
  bootsum <- summary(model_bootstrap)
  
    #Saving the coefficients
  sample_coef_intercept <-
    c(sample_coef_intercept, bootsum$coefficients[1])
  
  sample_coef_df_x1 <- c(sample_coef_df_x1, bootsum$coefficients[2])
  sample_coef_df_x2 <- c(sample_coef_df_x2, bootsum$coefficients[3])
  sample_coef_df_x3 <- c(sample_coef_df_x3, bootsum$coefficients[4])
  sample_coef_df_x4 <- c(sample_coef_df_x4, bootsum$coefficients[5])
  sample_coef_df_x5 <- c(sample_coef_df_x5, bootsum$coefficients[6])
  sample_coef_df_x6 <- c(sample_coef_df_x6, bootsum$coefficients[7])
  sample_coef_df_x7 <- c(sample_coef_df_x7, bootsum$coefficients[8])
  sample_coef_df_x8 <- c(sample_coef_df_x8, bootsum$coefficients[9])
  sample_coef_df_x9 <- c(sample_coef_df_x9, bootsum$coefficients[10])
  sample_coef_df_x10 <- c(sample_coef_df_x10, bootsum$coefficients[11])
  sample_coef_df_x11 <- c(sample_coef_df_x11, bootsum$coefficients[12])
  sample_coef_df_x12 <- c(sample_coef_df_x12, bootsum$coefficients[13])
  sample_coef_df_x13 <- c(sample_coef_df_x13, bootsum$coefficients[14])
  sample_coef_df_x14 <- c(sample_coef_df_x14, bootsum$coefficients[15])
}

## Want ABSOLUTE values to show overall affect on iRating (-.3 has as much of an effect as .3)
absCoefsDF <- data.frame(iAnalyProbC=abs(sample_coef_df_x1), 
                      iAskQuesC=abs(sample_coef_df_x2),
                      iChallengedC=abs(sample_coef_df_x3),
                      iConceptsC=abs(sample_coef_df_x4),
                      iDemoC=abs(sample_coef_df_x5),
                      iEnthusiasmC=abs(sample_coef_df_x6),
                      iHoursC=abs(sample_coef_df_x7),
                      iParticipateC=abs(sample_coef_df_x8),
                      iPreparedC=abs(sample_coef_df_x9),
                      iQuesEffectC=abs(sample_coef_df_x10),
                      iStandardsC=abs(sample_coef_df_x11),
                      iTopicC=abs(sample_coef_df_x12),
                      iUnderstandC=abs(sample_coef_df_x13),
                      iWelQuesC=abs(sample_coef_df_x14))

BootstrapData <- absCoefsDF %>%
  summarize(meaniAnalyProbC = mean(iAnalyProbC), variAnalyProbC = var(iAnalyProbC),q1iAnalyProbC = quantile(iAnalyProbC, probs=.25), q2iAnalyProbC = quantile(iAnalyProbC, probs=.5), q3iAnalyProbC = quantile(iAnalyProbC, probs=.75),
            meaniAskQuesC = mean(iAskQuesC), variAskQuesC = var(iAskQuesC), q1iAskQuesC = quantile(iAskQuesC, probs=.25), q2iAskQuesC = quantile(iAskQuesC, probs=.5), q3iAskQuesC = quantile(iAskQuesC, probs=.75),
            meaniChallengedC = mean(iChallengedC), variChallengedC = var(iChallengedC), q1iChallengedC = quantile(iChallengedC, probs=.25), q2iChallengedC = quantile(iChallengedC, probs=.5), q3iChallengedC = quantile(iChallengedC, probs=.75),
            meaniConceptsC = mean(iConceptsC), variConceptsC = var(iConceptsC), q1iConceptsC = quantile(iConceptsC, probs=.25), q2iConceptsC = quantile(iConceptsC, probs=.5), q3iConceptsC = quantile(iConceptsC, probs=.75),
            meaniDemoC = mean(iDemoC), variDemoC = var(iDemoC), q1iDemoC = quantile(iDemoC, probs=.25), q2iDemoC = quantile(iDemoC, probs=.5), q3iDemoC = quantile(iDemoC, probs=.75), 
            meaniEnthusiasmC = mean(iEnthusiasmC), variEnthusiasmC = var(iEnthusiasmC), q1iEnthusiasmC = quantile(iEnthusiasmC, probs=.25), q2iEnthusiasmC = quantile(iEnthusiasmC, probs=.5), q3iEnthusiasmC = quantile(iEnthusiasmC, probs=.75),
            meaniHoursC = mean(iHoursC), variHoursC = var(iHoursC), q1iHoursC = quantile(iHoursC, probs=.25), q2iHoursC = quantile(iHoursC, probs=.5), q3iHoursC = quantile(iHoursC, probs=.75),
            meaniParticipateC = mean(iParticipateC), variParticipateC = var(iParticipateC), q1iParticipateC = quantile(iParticipateC, probs=.25), q2iParticipateC = quantile(iParticipateC, probs=.5), q3iParticipateC = quantile(iParticipateC, probs=.75),
            meaniPreparedC = mean(iPreparedC), variPreparedC = var(iPreparedC), q1iPreparedC = quantile(iPreparedC, probs=.25), q2iPreparedC = quantile(iPreparedC, probs=.5), q3iPreparedC = quantile(iPreparedC, probs=.75),
            meaniQuesEffectC = mean(iQuesEffectC), variQuesEffectC = var(iQuesEffectC), q1iQuesEffectC = quantile(iQuesEffectC, probs=.25), q2iQuesEffectC = quantile(iQuesEffectC, probs=.5), q3iQuesEffectC = quantile(iQuesEffectC, probs=.75),
            meaniStandardsC = mean(iStandardsC), variStandardsC = var(iStandardsC), q1iStandardsC = quantile(iStandardsC, probs=.25),  q2iStandardsC = quantile(iStandardsC, probs=.5), q3iStandardsC = quantile(iStandardsC, probs=.75),
            meaniTopicC = mean(iTopicC), variTopicC = var(iTopicC), q1iTopicC = quantile(iTopicC, probs=.25), q2iTopicC = quantile(iTopicC, probs=.5), q3iTopicC = quantile(iTopicC, probs=.75),
            meaniUnderstandC = mean(iUnderstandC), variUnderstandC = var(iUnderstandC), q1iUnderstandC = quantile(iUnderstandC, probs=.25), q2iUnderstandC = quantile(iUnderstandC, probs=.5), q3iUnderstandC = quantile(iUnderstandC, probs=.75),
            meaniWelQuesC = mean(iWelQuesC), variWelQuesC = var(iWelQuesC), q1iWelQuesC = quantile(iWelQuesC, probs=.25), q2iWelQuesC = quantile(iWelQuesC, probs=.5), q3iWelQuesC = quantile(iWelQuesC, probs=.75))

# Pivot Data
LBootstrapData <- BootstrapData %>% pivot_longer(cols=c(meaniAnalyProbC,  meaniAskQuesC, meaniChallengedC , meaniConceptsC,  meaniDemoC, meaniEnthusiasmC, meaniHoursC, meaniParticipateC, meaniPreparedC, meaniQuesEffectC, meaniStandardsC, meaniTopicC, meaniUnderstandC, meaniWelQuesC),
                                        names_to='Variable1',
                                        values_to='Mean')
## Pivot again for variance
LBootstrapData <- LBootstrapData %>% pivot_longer(cols=c(variAnalyProbC, variAskQuesC,  variChallengedC ,  variConceptsC, variDemoC, variEnthusiasmC, variHoursC, variParticipateC, variPreparedC, variQuesEffectC, variStandardsC, variTopicC , variUnderstandC, variWelQuesC),
                                        names_to='Variable2',
                                        values_to='Variance') %>%
  
  select(Variable1, Variable2, Variance, Mean) %>%
  mutate(Variable_1 = str_replace(Variable1, "mean", ""),
         Variable_2 = str_replace(Variable2, "var", "")) %>%
  filter(Variable_2==Variable_1) %>%
  rename(Variable=Variable_1) %>%
  select(Variable, Mean, Variance) %>%
  mutate(x=c(1,2,3,4,5,6,7,8,9,10,11,12,13,14))



# Plotting Averages i, coursetpy 2



quantiles <- quantile(abs(LBootstrapData$Mean), probs=c(.25, .75))


CT2iplot <-  ggplot(data=LBootstrapData, aes(y=abs(Mean), x=x)) +
  geom_point()  +
  geom_label_repel(aes(label=Variable)) +
  geom_errorbar(aes(ymin=Mean-sqrt(Variance), ymax=Mean+sqrt(Variance)), width=.3) +
  #geom_jitter(height=0, width=.5) +
  theme_minimal() +
  scale_x_continuous(breaks = (7),
                     minor_breaks= NULL,
                     labels=("Separation Factor"))+
  annotate("rect", xmin=-1, xmax=15, ymin=0, ymax=quantiles[1], fill="red", alpha=.2) +
  annotate("rect", xmin=-1, xmax=15, ymin=quantiles[1], ymax=quantiles[2], fill="yellow", alpha=.2) +
  annotate("rect", xmin=-1, xmax=15, ymin=quantiles[2], ymax=.27, fill="green", alpha=.2) +
  #annotate('text', x=.5, y=(quantiles[2]-.05), label="Top 25% of Coefficients", color='forestgreen') +
  #annotate('text', x=.5, y=(quantiles[2]-.04), label="Middle 50% of Coefficients", color='yellow4') +
  #annotate('text', x=.5, y=(quantiles[2]-.03), label="Bottom 25% of Coefficients", color='firebrick4') +
  labs(title="MKT Core Courses",
       x="",
       y="")





# Boostrap Model for Overall Rating Using Standardized Predictors for CourseType 3 Instructor Questions

set.seed(09272024)

## Idea for full model
##full.modeli.1 <- lm(data=Teacher1Stdz, iRating ~ iAskQuesS + iAnalyProbS + iChallengedS + iConceptsS +iDemoS +iEnthusiasmS +iHoursS + iParticipateS + iPreparedS + iQuesEffectS + iStandardsS + iTopicS + iUnderstandS + iWelQuesS )
##summary(full.modeli.1)

## BOOTSRAPPING BY HAND

sample_coef_intercept <- NULL
sample_coef_df_x1 <- NULL
sample_coef_df_x2 <- NULL
sample_coef_df_x3 <- NULL
sample_coef_df_x4 <- NULL
sample_coef_df_x5 <- NULL
sample_coef_df_x6 <- NULL
sample_coef_df_x7 <- NULL
sample_coef_df_x8 <- NULL
sample_coef_df_x9 <- NULL
sample_coef_df_x10 <- NULL
sample_coef_df_x11 <- NULL
sample_coef_df_x12 <- NULL
sample_coef_df_x13 <- NULL
sample_coef_df_x14 <- NULL


for (i in 1:1000) {
  #Creating a resampled dataset from the sample data
  sample_d = CTStdz_3[sample(1:nrow(CTStdz_3), nrow(CTStdz_3), replace = TRUE), ]
 # sample_d_totalcompleted <-  sample_d %>% summarize(totalcomp = sum(Completed))
  sample_d_w <- sample_d %>%
    mutate(weight = Completed/sum(Completed))
  
  #Running the regression on these data
  model_bootstrap  <- lmer(iRating ~ ((s_iAnalyProb+ s_iAskQues+ s_iChallenged+ s_iConcepts+ s_iDemo + s_iEnthusiasm+ s_iHours+ s_iParticipate+ s_iPrepared+ s_iQuesEffect+ s_iStandards+ s_iTopic+ s_iUnderstand+ s_iWelQues) + (1 | eInstID)), weights=weight, data = sample_d_w)
  bootsum <- summary(model_bootstrap)
  
    #Saving the coefficients
  sample_coef_intercept <-
    c(sample_coef_intercept, bootsum$coefficients[1])
  
  sample_coef_df_x1 <- c(sample_coef_df_x1, bootsum$coefficients[2])
  sample_coef_df_x2 <- c(sample_coef_df_x2, bootsum$coefficients[3])
  sample_coef_df_x3 <- c(sample_coef_df_x3, bootsum$coefficients[4])
  sample_coef_df_x4 <- c(sample_coef_df_x4, bootsum$coefficients[5])
  sample_coef_df_x5 <- c(sample_coef_df_x5, bootsum$coefficients[6])
  sample_coef_df_x6 <- c(sample_coef_df_x6, bootsum$coefficients[7])
  sample_coef_df_x7 <- c(sample_coef_df_x7, bootsum$coefficients[8])
  sample_coef_df_x8 <- c(sample_coef_df_x8, bootsum$coefficients[9])
  sample_coef_df_x9 <- c(sample_coef_df_x9, bootsum$coefficients[10])
  sample_coef_df_x10 <- c(sample_coef_df_x10, bootsum$coefficients[11])
  sample_coef_df_x11 <- c(sample_coef_df_x11, bootsum$coefficients[12])
  sample_coef_df_x12 <- c(sample_coef_df_x12, bootsum$coefficients[13])
  sample_coef_df_x13 <- c(sample_coef_df_x13, bootsum$coefficients[14])
  sample_coef_df_x14 <- c(sample_coef_df_x14, bootsum$coefficients[15])
}

## Want ABSOLUTE values to show overall affect on iRating (-.3 has as much of an effect as .3)
absCoefsDF <- data.frame(iAnalyProbC=abs(sample_coef_df_x1), 
                      iAskQuesC=abs(sample_coef_df_x2),
                      iChallengedC=abs(sample_coef_df_x3),
                      iConceptsC=abs(sample_coef_df_x4),
                      iDemoC=abs(sample_coef_df_x5),
                      iEnthusiasmC=abs(sample_coef_df_x6),
                      iHoursC=abs(sample_coef_df_x7),
                      iParticipateC=abs(sample_coef_df_x8),
                      iPreparedC=abs(sample_coef_df_x9),
                      iQuesEffectC=abs(sample_coef_df_x10),
                      iStandardsC=abs(sample_coef_df_x11),
                      iTopicC=abs(sample_coef_df_x12),
                      iUnderstandC=abs(sample_coef_df_x13),
                      iWelQuesC=abs(sample_coef_df_x14))

BootstrapData <- absCoefsDF %>%
  summarize(meaniAnalyProbC = mean(iAnalyProbC), variAnalyProbC = var(iAnalyProbC),q1iAnalyProbC = quantile(iAnalyProbC, probs=.25), q2iAnalyProbC = quantile(iAnalyProbC, probs=.5), q3iAnalyProbC = quantile(iAnalyProbC, probs=.75),
            meaniAskQuesC = mean(iAskQuesC), variAskQuesC = var(iAskQuesC), q1iAskQuesC = quantile(iAskQuesC, probs=.25), q2iAskQuesC = quantile(iAskQuesC, probs=.5), q3iAskQuesC = quantile(iAskQuesC, probs=.75),
            meaniChallengedC = mean(iChallengedC), variChallengedC = var(iChallengedC), q1iChallengedC = quantile(iChallengedC, probs=.25), q2iChallengedC = quantile(iChallengedC, probs=.5), q3iChallengedC = quantile(iChallengedC, probs=.75),
            meaniConceptsC = mean(iConceptsC), variConceptsC = var(iConceptsC), q1iConceptsC = quantile(iConceptsC, probs=.25), q2iConceptsC = quantile(iConceptsC, probs=.5), q3iConceptsC = quantile(iConceptsC, probs=.75),
            meaniDemoC = mean(iDemoC), variDemoC = var(iDemoC), q1iDemoC = quantile(iDemoC, probs=.25), q2iDemoC = quantile(iDemoC, probs=.5), q3iDemoC = quantile(iDemoC, probs=.75), 
            meaniEnthusiasmC = mean(iEnthusiasmC), variEnthusiasmC = var(iEnthusiasmC), q1iEnthusiasmC = quantile(iEnthusiasmC, probs=.25), q2iEnthusiasmC = quantile(iEnthusiasmC, probs=.5), q3iEnthusiasmC = quantile(iEnthusiasmC, probs=.75),
            meaniHoursC = mean(iHoursC), variHoursC = var(iHoursC), q1iHoursC = quantile(iHoursC, probs=.25), q2iHoursC = quantile(iHoursC, probs=.5), q3iHoursC = quantile(iHoursC, probs=.75),
            meaniParticipateC = mean(iParticipateC), variParticipateC = var(iParticipateC), q1iParticipateC = quantile(iParticipateC, probs=.25), q2iParticipateC = quantile(iParticipateC, probs=.5), q3iParticipateC = quantile(iParticipateC, probs=.75),
            meaniPreparedC = mean(iPreparedC), variPreparedC = var(iPreparedC), q1iPreparedC = quantile(iPreparedC, probs=.25), q2iPreparedC = quantile(iPreparedC, probs=.5), q3iPreparedC = quantile(iPreparedC, probs=.75),
            meaniQuesEffectC = mean(iQuesEffectC), variQuesEffectC = var(iQuesEffectC), q1iQuesEffectC = quantile(iQuesEffectC, probs=.25), q2iQuesEffectC = quantile(iQuesEffectC, probs=.5), q3iQuesEffectC = quantile(iQuesEffectC, probs=.75),
            meaniStandardsC = mean(iStandardsC), variStandardsC = var(iStandardsC), q1iStandardsC = quantile(iStandardsC, probs=.25),  q2iStandardsC = quantile(iStandardsC, probs=.5), q3iStandardsC = quantile(iStandardsC, probs=.75),
            meaniTopicC = mean(iTopicC), variTopicC = var(iTopicC), q1iTopicC = quantile(iTopicC, probs=.25), q2iTopicC = quantile(iTopicC, probs=.5), q3iTopicC = quantile(iTopicC, probs=.75),
            meaniUnderstandC = mean(iUnderstandC), variUnderstandC = var(iUnderstandC), q1iUnderstandC = quantile(iUnderstandC, probs=.25), q2iUnderstandC = quantile(iUnderstandC, probs=.5), q3iUnderstandC = quantile(iUnderstandC, probs=.75),
            meaniWelQuesC = mean(iWelQuesC), variWelQuesC = var(iWelQuesC), q1iWelQuesC = quantile(iWelQuesC, probs=.25), q2iWelQuesC = quantile(iWelQuesC, probs=.5), q3iWelQuesC = quantile(iWelQuesC, probs=.75))

# Pivot Data
LBootstrapData <- BootstrapData %>% pivot_longer(cols=c(meaniAnalyProbC,  meaniAskQuesC, meaniChallengedC , meaniConceptsC,  meaniDemoC, meaniEnthusiasmC, meaniHoursC, meaniParticipateC, meaniPreparedC, meaniQuesEffectC, meaniStandardsC, meaniTopicC, meaniUnderstandC, meaniWelQuesC),
                                        names_to='Variable1',
                                        values_to='Mean')
## Pivot again for variance
LBootstrapData <- LBootstrapData %>% pivot_longer(cols=c(variAnalyProbC, variAskQuesC,  variChallengedC ,  variConceptsC, variDemoC, variEnthusiasmC, variHoursC, variParticipateC, variPreparedC, variQuesEffectC, variStandardsC, variTopicC , variUnderstandC, variWelQuesC),
                                        names_to='Variable2',
                                        values_to='Variance') %>%
  
  select(Variable1, Variable2, Variance, Mean) %>%
  mutate(Variable_1 = str_replace(Variable1, "mean", ""),
         Variable_2 = str_replace(Variable2, "var", "")) %>%
  filter(Variable_2==Variable_1) %>%
  rename(Variable=Variable_1) %>%
  select(Variable, Mean, Variance) %>%
  mutate(x=c(1,2,3,4,5,6,7,8,9,10,11,12,13,14))




# Plot i vars for Coursetype 3

quantiles <- quantile(abs(LBootstrapData$Mean), probs=c(.25, .75))


CT3iplot <- ggplot(data=LBootstrapData, aes(y=abs(Mean), x=x)) +
  geom_point()  +
  geom_label_repel(aes(label=Variable)) +
  geom_errorbar(aes(ymin=Mean-sqrt(Variance), ymax=Mean+sqrt(Variance)), width=.3) +
  #geom_jitter(height=0, width=.5) +
  theme_minimal() +
  scale_x_continuous(breaks = (7),
                     minor_breaks= NULL,
                     labels=("Separation Factor"))+
  annotate("rect", xmin=-1, xmax=15, ymin=0, ymax=quantiles[1], fill="red", alpha=.2) +
  annotate("rect", xmin=-1, xmax=15, ymin=quantiles[1], ymax=quantiles[2], fill="yellow", alpha=.2) +
  annotate("rect", xmin=-1, xmax=15, ymin=quantiles[2], ymax=.27, fill="green", alpha=.2) +
  #annotate('text', x=1.5, y=(quantiles[2]+.1), label="Top 25% of Coefficients", color='forestgreen') +
  #annotate('text', x=1.5, y=(quantiles[2]+.09), label="Middle 50% of Coefficients", color='yellow4') +
  #annotate('text', x=1.5, y=(quantiles[2]+.08), label="Bottom 25% of Coefficients", color='firebrick4') +
  labs(title="MKT Elective Courses",
       x="",
       y="")







# Bootstrap Model for Overall Rating Using Standardized Predictors for CourseType 4 Instructor Questions


set.seed(09272024)

## Idea for full model
##full.modeli.1 <- lm(data=Teacher1Stdz, iRating ~ iAskQuesS + iAnalyProbS + iChallengedS + iConceptsS +iDemoS +iEnthusiasmS +iHoursS + iParticipateS + iPreparedS + iQuesEffectS + iStandardsS + iTopicS + iUnderstandS + iWelQuesS )
##summary(full.modeli.1)

## BOOTSRAPPING BY HAND

sample_coef_intercept <- NULL
sample_coef_df_x1 <- NULL
sample_coef_df_x2 <- NULL
sample_coef_df_x3 <- NULL
sample_coef_df_x4 <- NULL
sample_coef_df_x5 <- NULL
sample_coef_df_x6 <- NULL
sample_coef_df_x7 <- NULL
sample_coef_df_x8 <- NULL
sample_coef_df_x9 <- NULL
sample_coef_df_x10 <- NULL
sample_coef_df_x11 <- NULL
sample_coef_df_x12 <- NULL
sample_coef_df_x13 <- NULL
sample_coef_df_x14 <- NULL


for (i in 1:1000) {
  #Creating a resampled dataset from the sample data
  sample_d = CTStdz_4[sample(1:nrow(CTStdz_4), nrow(CTStdz_4), replace = TRUE), ]
 # sample_d_totalcompleted <-  sample_d %>% summarize(totalcomp = sum(Completed))
  sample_d_w <- sample_d %>%
    mutate(weight = Completed/sum(Completed))
  
  #Running the regression on these data
  model_bootstrap  <- lmer(iRating ~ ((s_iAnalyProb+ s_iAskQues+ s_iChallenged+ s_iConcepts+ s_iDemo + s_iEnthusiasm+ s_iHours+ s_iParticipate+ s_iPrepared+ s_iQuesEffect+ s_iStandards+ s_iTopic+ s_iUnderstand+ s_iWelQues) + (1 | eInstID)), weights=weight, data = sample_d_w)
  bootsum <- summary(model_bootstrap)
  
    #Saving the coefficients
  sample_coef_intercept <-
    c(sample_coef_intercept, bootsum$coefficients[1])
  
  sample_coef_df_x1 <- c(sample_coef_df_x1, bootsum$coefficients[2])
  sample_coef_df_x2 <- c(sample_coef_df_x2, bootsum$coefficients[3])
  sample_coef_df_x3 <- c(sample_coef_df_x3, bootsum$coefficients[4])
  sample_coef_df_x4 <- c(sample_coef_df_x4, bootsum$coefficients[5])
  sample_coef_df_x5 <- c(sample_coef_df_x5, bootsum$coefficients[6])
  sample_coef_df_x6 <- c(sample_coef_df_x6, bootsum$coefficients[7])
  sample_coef_df_x7 <- c(sample_coef_df_x7, bootsum$coefficients[8])
  sample_coef_df_x8 <- c(sample_coef_df_x8, bootsum$coefficients[9])
  sample_coef_df_x9 <- c(sample_coef_df_x9, bootsum$coefficients[10])
  sample_coef_df_x10 <- c(sample_coef_df_x10, bootsum$coefficients[11])
  sample_coef_df_x11 <- c(sample_coef_df_x11, bootsum$coefficients[12])
  sample_coef_df_x12 <- c(sample_coef_df_x12, bootsum$coefficients[13])
  sample_coef_df_x13 <- c(sample_coef_df_x13, bootsum$coefficients[14])
  sample_coef_df_x14 <- c(sample_coef_df_x14, bootsum$coefficients[15])
}

## Want ABSOLUTE values to show overall affect on iRating (-.3 has as much of an effect as .3)
absCoefsDF <- data.frame(iAnalyProbC=abs(sample_coef_df_x1), 
                      iAskQuesC=abs(sample_coef_df_x2),
                      iChallengedC=abs(sample_coef_df_x3),
                      iConceptsC=abs(sample_coef_df_x4),
                      iDemoC=abs(sample_coef_df_x5),
                      iEnthusiasmC=abs(sample_coef_df_x6),
                      iHoursC=abs(sample_coef_df_x7),
                      iParticipateC=abs(sample_coef_df_x8),
                      iPreparedC=abs(sample_coef_df_x9),
                      iQuesEffectC=abs(sample_coef_df_x10),
                      iStandardsC=abs(sample_coef_df_x11),
                      iTopicC=abs(sample_coef_df_x12),
                      iUnderstandC=abs(sample_coef_df_x13),
                      iWelQuesC=abs(sample_coef_df_x14))

BootstrapData <- absCoefsDF %>%
  summarize(meaniAnalyProbC = mean(iAnalyProbC), variAnalyProbC = var(iAnalyProbC),q1iAnalyProbC = quantile(iAnalyProbC, probs=.25), q2iAnalyProbC = quantile(iAnalyProbC, probs=.5), q3iAnalyProbC = quantile(iAnalyProbC, probs=.75),
            meaniAskQuesC = mean(iAskQuesC), variAskQuesC = var(iAskQuesC), q1iAskQuesC = quantile(iAskQuesC, probs=.25), q2iAskQuesC = quantile(iAskQuesC, probs=.5), q3iAskQuesC = quantile(iAskQuesC, probs=.75),
            meaniChallengedC = mean(iChallengedC), variChallengedC = var(iChallengedC), q1iChallengedC = quantile(iChallengedC, probs=.25), q2iChallengedC = quantile(iChallengedC, probs=.5), q3iChallengedC = quantile(iChallengedC, probs=.75),
            meaniConceptsC = mean(iConceptsC), variConceptsC = var(iConceptsC), q1iConceptsC = quantile(iConceptsC, probs=.25), q2iConceptsC = quantile(iConceptsC, probs=.5), q3iConceptsC = quantile(iConceptsC, probs=.75),
            meaniDemoC = mean(iDemoC), variDemoC = var(iDemoC), q1iDemoC = quantile(iDemoC, probs=.25), q2iDemoC = quantile(iDemoC, probs=.5), q3iDemoC = quantile(iDemoC, probs=.75), 
            meaniEnthusiasmC = mean(iEnthusiasmC), variEnthusiasmC = var(iEnthusiasmC), q1iEnthusiasmC = quantile(iEnthusiasmC, probs=.25), q2iEnthusiasmC = quantile(iEnthusiasmC, probs=.5), q3iEnthusiasmC = quantile(iEnthusiasmC, probs=.75),
            meaniHoursC = mean(iHoursC), variHoursC = var(iHoursC), q1iHoursC = quantile(iHoursC, probs=.25), q2iHoursC = quantile(iHoursC, probs=.5), q3iHoursC = quantile(iHoursC, probs=.75),
            meaniParticipateC = mean(iParticipateC), variParticipateC = var(iParticipateC), q1iParticipateC = quantile(iParticipateC, probs=.25), q2iParticipateC = quantile(iParticipateC, probs=.5), q3iParticipateC = quantile(iParticipateC, probs=.75),
            meaniPreparedC = mean(iPreparedC), variPreparedC = var(iPreparedC), q1iPreparedC = quantile(iPreparedC, probs=.25), q2iPreparedC = quantile(iPreparedC, probs=.5), q3iPreparedC = quantile(iPreparedC, probs=.75),
            meaniQuesEffectC = mean(iQuesEffectC), variQuesEffectC = var(iQuesEffectC), q1iQuesEffectC = quantile(iQuesEffectC, probs=.25), q2iQuesEffectC = quantile(iQuesEffectC, probs=.5), q3iQuesEffectC = quantile(iQuesEffectC, probs=.75),
            meaniStandardsC = mean(iStandardsC), variStandardsC = var(iStandardsC), q1iStandardsC = quantile(iStandardsC, probs=.25),  q2iStandardsC = quantile(iStandardsC, probs=.5), q3iStandardsC = quantile(iStandardsC, probs=.75),
            meaniTopicC = mean(iTopicC), variTopicC = var(iTopicC), q1iTopicC = quantile(iTopicC, probs=.25), q2iTopicC = quantile(iTopicC, probs=.5), q3iTopicC = quantile(iTopicC, probs=.75),
            meaniUnderstandC = mean(iUnderstandC), variUnderstandC = var(iUnderstandC), q1iUnderstandC = quantile(iUnderstandC, probs=.25), q2iUnderstandC = quantile(iUnderstandC, probs=.5), q3iUnderstandC = quantile(iUnderstandC, probs=.75),
            meaniWelQuesC = mean(iWelQuesC), variWelQuesC = var(iWelQuesC), q1iWelQuesC = quantile(iWelQuesC, probs=.25), q2iWelQuesC = quantile(iWelQuesC, probs=.5), q3iWelQuesC = quantile(iWelQuesC, probs=.75))

# Pivot Data
LBootstrapData <- BootstrapData %>% pivot_longer(cols=c(meaniAnalyProbC,  meaniAskQuesC, meaniChallengedC , meaniConceptsC,  meaniDemoC, meaniEnthusiasmC, meaniHoursC, meaniParticipateC, meaniPreparedC, meaniQuesEffectC, meaniStandardsC, meaniTopicC, meaniUnderstandC, meaniWelQuesC),
                                        names_to='Variable1',
                                        values_to='Mean')
## Pivot again for variance
LBootstrapData <- LBootstrapData %>% pivot_longer(cols=c(variAnalyProbC, variAskQuesC,  variChallengedC ,  variConceptsC, variDemoC, variEnthusiasmC, variHoursC, variParticipateC, variPreparedC, variQuesEffectC, variStandardsC, variTopicC , variUnderstandC, variWelQuesC),
                                        names_to='Variable2',
                                        values_to='Variance') %>%
  
  select(Variable1, Variable2, Variance, Mean) %>%
  mutate(Variable_1 = str_replace(Variable1, "mean", ""),
         Variable_2 = str_replace(Variable2, "var", "")) %>%
  filter(Variable_2==Variable_1) %>%
  rename(Variable=Variable_1) %>%
  select(Variable, Mean, Variance) %>%
  mutate(x=c(1,2,3,4,5,6,7,8,9,10,11,12,13,14))



# Plot i Coursetype 4

quantiles <- quantile(abs(LBootstrapData$Mean), probs=c(.25, .75))


CT4iplot <- ggplot(data=LBootstrapData, aes(y=abs(Mean), x=x)) +
  geom_point()  +
  geom_label_repel(aes(label=Variable)) +
  geom_errorbar(aes(ymin=Mean-sqrt(Variance), ymax=Mean+sqrt(Variance)), width=.3) +
  #geom_jitter(height=0, width=.5) +
  theme_minimal() +
  scale_x_continuous(breaks = (7),
                     minor_breaks= NULL,
                     labels=("Separation Factor"))+
  annotate("rect", xmin=-1, xmax=15, ymin=0, ymax=quantiles[1], fill="red", alpha=.2) +
  annotate("rect", xmin=-1, xmax=15, ymin=quantiles[1], ymax=quantiles[2], fill="yellow", alpha=.2) +
  annotate("rect", xmin=-1, xmax=15, ymin=quantiles[2], ymax=.27, fill="green", alpha=.2) +
  #annotate('text', x=1.5, y=(quantiles[2]+.1), label="Top 25% of Coefficients", color='forestgreen') +
  #annotate('text', x=1.5, y=(quantiles[2]+.09), label="Middle 50% of Coefficients", color='yellow4') +
  #annotate('text', x=1.5, y=(quantiles[2]+.08), label="Bottom 25% of Coefficients", color='firebrick4') +
  labs(title='MKT Capston Courses',
       y="Average of Absolute Value of Beta Coefficients of Standardized Questions",
       x="Values do not Matter, Just here to Separate Coefficeint Averages",
       x="",
       y="")




par(mfrow=c(2,2))
CT1iplot
CT2iplot
CT3iplot
CT4iplot  




# CourseType 1, s vars bootstrap


set.seed(09272024)

## Idea for full model
##full.modeli.1 <- lm(data=Teacher1Stdz, iRating ~ iAskQuesS + iAnalyProbS + iChallengedS + iConceptsS +iDemoS +iEnthusiasmS +iHoursS + iParticipateS + iPreparedS + iQuesEffectS + iStandardsS + iTopicS + iUnderstandS + iWelQuesS )
##summary(full.modeli.1)

## BOOTSRAPPING BY HAND

sample_coef_intercept <- NULL
sample_coef_df_x1 <- NULL
sample_coef_df_x2 <- NULL
sample_coef_df_x3 <- NULL
sample_coef_df_x4 <- NULL
sample_coef_df_x5 <- NULL
sample_coef_df_x6 <- NULL
sample_coef_df_x7 <- NULL


for (i in 1:1000) {
  #Creating a resampled dataset from the sample data
  sample_d = CTStdz_1[sample(1:nrow(CTStdz_1), nrow(CTStdz_1), replace = TRUE), ]
 # sample_d_totalcompleted <-  sample_d %>% summarize(totalcomp = sum(Completed))
  sample_d_w <- sample_d %>%
    mutate(weight = Completed/sum(Completed))
  
  #Running the regression on these data
  model_bootstrap  <- lmer(iRating ~ ((s_sAttended+ s_sEngaged+ s_sHelp+ s_sPrepared+ s_sPositive + s_sUpToDate) + (1 | eInstID)), weights=weight, data = sample_d_w)
  bootsum <- summary(model_bootstrap)
  
    #Saving the coefficients
  sample_coef_intercept <-
    c(sample_coef_intercept, bootsum$coefficients[1])
  
  sample_coef_df_x1 <- c(sample_coef_df_x1, bootsum$coefficients[2])
  sample_coef_df_x2 <- c(sample_coef_df_x2, bootsum$coefficients[3])
  sample_coef_df_x3 <- c(sample_coef_df_x3, bootsum$coefficients[4])
  sample_coef_df_x4 <- c(sample_coef_df_x4, bootsum$coefficients[5])
  sample_coef_df_x5 <- c(sample_coef_df_x5, bootsum$coefficients[6])
  sample_coef_df_x6 <- c(sample_coef_df_x6, bootsum$coefficients[7])
}

## Want ABSOLUTE values to show overall affect on iRating (-.3 has as much of an effect as .3)
absCoefsDF <- data.frame(sAttendedC=abs(sample_coef_df_x1), 
                      sEngagedC=abs(sample_coef_df_x2),
                      sHelpC=abs(sample_coef_df_x3),
                      sPreparedC=abs(sample_coef_df_x4),
                      sPositiveC=abs(sample_coef_df_x5),
                      sUpToDateC=abs(sample_coef_df_x6))

BootstrapData <- absCoefsDF %>%
  summarize(meansAttendedC = mean(sAttendedC), varsAttendedC = var(sAttendedC),q1sAttendedC = quantile(sAttendedC, probs=.25), q2sAttendedC = quantile(sAttendedC, probs=.5), q3sAttendedC = quantile(sAttendedC, probs=.75),
            meansEngagedC = mean(sEngagedC), varsEngagedC = var(sEngagedC), q1sEngagedC = quantile(sEngagedC, probs=.25), q2sEngagedC = quantile(sEngagedC, probs=.5), q3sEngagedC = quantile(sEngagedC, probs=.75),
            meansHelpC = mean(sHelpC), varsHelpC = var(sHelpC), q1sHelpC = quantile(sHelpC, probs=.25), q2sHelpC = quantile(sHelpC, probs=.5), q3sHelpC = quantile(sHelpC, probs=.75),
            meansPreparedC = mean(sPreparedC), varsPreparedC = var(sPreparedC), q1sPreparedC = quantile(sPreparedC, probs=.25), q2sPreparedC = quantile(sPreparedC, probs=.5), q3sPreparedC = quantile(sPreparedC, probs=.75),
            meansPositiveC = mean(sPositiveC), varsPositiveC = var(sPositiveC), q1sPositiveC = quantile(sPositiveC, probs=.25), q2sPositiveC = quantile(sPositiveC, probs=.5), q3sPositiveC = quantile(sPositiveC, probs=.75), 
            meansUpToDateC = mean(sUpToDateC), varsUpToDateC = var(sUpToDateC), q1sUpToDateC = quantile(sUpToDateC, probs=.25), q2sUpToDateC = quantile(sUpToDateC, probs=.5), q3sUpToDateC = quantile(sUpToDateC, probs=.75) )

# Pivot Data
LBootstrapData <- BootstrapData %>% pivot_longer(cols=c(meansAttendedC,  meansEngagedC, meansHelpC , meansPreparedC,  meansPositiveC, meansUpToDateC),
                                        names_to='Variable1',
                                        values_to='Mean')
## Pivot again for variance
LBootstrapData <- LBootstrapData %>% pivot_longer(cols=c(varsAttendedC,  varsEngagedC, varsHelpC , varsPreparedC,  varsPositiveC, varsUpToDateC),
                                        names_to='Variable2',
                                        values_to='Variance') %>%
  
  select(Variable1, Variable2, Variance, Mean) %>%
  mutate(Variable_1 = str_replace(Variable1, "mean", ""),
         Variable_2 = str_replace(Variable2, "var", "")) %>%
  filter(Variable_2==Variable_1) %>%
  rename(Variable=Variable_1) %>%
  select(Variable, Mean, Variance) %>%
  mutate(x=c(1,2,3,4,5,6))



# CourseType 1, s vars plot

quantiles <- quantile(abs(LBootstrapData$Mean), probs=c(.25, .75))


CT1splot <- ggplot(data=LBootstrapData, aes(y=abs(Mean), x=x)) +
  geom_point()  +
  geom_label_repel(aes(label=Variable)) +
  geom_errorbar(aes(ymin=Mean-sqrt(Variance), ymax=Mean+sqrt(Variance)), width=.3) +
  #geom_jitter(height=0, width=.5) +
  theme_minimal() +
  scale_x_continuous(breaks = (3.5),
                     minor_breaks= NULL,
                     labels=("Separation Factor"))+
  annotate("rect", xmin=0, xmax=7, ymin=0, ymax=quantiles[1], fill="red", alpha=.2) +
  annotate("rect", xmin=0, xmax=7, ymin=quantiles[1], ymax=quantiles[2], fill="yellow", alpha=.2) +
  annotate("rect", xmin=0, xmax=7, ymin=quantiles[2], ymax=.32, fill="green", alpha=.2) +
  #annotate('text', x=1.5, y=(quantiles[2]+.1), label="Top 25% of Coefficients", color='forestgreen') +
  #annotate('text', x=1.5, y=(quantiles[2]+.09), label="Middle 50% of Coefficients", color='yellow4') +
  #annotate('text', x=1.5, y=(quantiles[2]+.08), label="Bottom 25% of Coefficients", color='firebrick4') +
  labs(title='Beta Coefficient Averages of Standardized test Variables for FSB Core Instructors',
       subtitle='Ignoring horizontal placement, variables with the highest average absolute value of their beta coefficient have\n the largest affect on a teachers rating when all variables are treated on the same scale',
       y="Average of Absolute Value of Beta Coefficients of Standardized Questions",
       x="Values do not Matter, Just here to Separate Coefficeint Averages")

# CourseType 2, s vars

set.seed(09272024)

## Idea for full model
##full.modeli.1 <- lm(data=Teacher1Stdz, iRating ~ iAskQuesS + iAnalyProbS + iChallengedS + iConceptsS +iDemoS +iEnthusiasmS +iHoursS + iParticipateS + iPreparedS + iQuesEffectS + iStandardsS + iTopicS + iUnderstandS + iWelQuesS )
##summary(full.modeli.1)

## BOOTSRAPPING BY HAND

sample_coef_intercept <- NULL
sample_coef_df_x1 <- NULL
sample_coef_df_x2 <- NULL
sample_coef_df_x3 <- NULL
sample_coef_df_x4 <- NULL
sample_coef_df_x5 <- NULL
sample_coef_df_x6 <- NULL
sample_coef_df_x7 <- NULL


for (i in 1:1000) {
  #Creating a resampled dataset from the sample data
  sample_d = CTStdz_2[sample(1:nrow(CTStdz_2), nrow(CTStdz_2), replace = TRUE), ]
 # sample_d_totalcompleted <-  sample_d %>% summarize(totalcomp = sum(Completed))
  sample_d_w <- sample_d %>%
    mutate(weight = Completed/sum(Completed))
  
  #Running the regression on these data
  model_bootstrap  <- lmer(iRating ~ ((s_sAttended+ s_sEngaged+ s_sHelp+ s_sPrepared+ s_sPositive + s_sUpToDate) + (1 | eInstID)), weights=weight, data = sample_d_w)
  bootsum <- summary(model_bootstrap)
  
    #Saving the coefficients
  sample_coef_intercept <-
    c(sample_coef_intercept, bootsum$coefficients[1])
  
  sample_coef_df_x1 <- c(sample_coef_df_x1, bootsum$coefficients[2])
  sample_coef_df_x2 <- c(sample_coef_df_x2, bootsum$coefficients[3])
  sample_coef_df_x3 <- c(sample_coef_df_x3, bootsum$coefficients[4])
  sample_coef_df_x4 <- c(sample_coef_df_x4, bootsum$coefficients[5])
  sample_coef_df_x5 <- c(sample_coef_df_x5, bootsum$coefficients[6])
  sample_coef_df_x6 <- c(sample_coef_df_x6, bootsum$coefficients[7])
}

## Want ABSOLUTE values to show overall affect on iRating (-.3 has as much of an effect as .3)
absCoefsDF <- data.frame(sAttendedC=abs(sample_coef_df_x1), 
                      sEngagedC=abs(sample_coef_df_x2),
                      sHelpC=abs(sample_coef_df_x3),
                      sPreparedC=abs(sample_coef_df_x4),
                      sPositiveC=abs(sample_coef_df_x5),
                      sUpToDateC=abs(sample_coef_df_x6))

BootstrapData <- absCoefsDF %>%
  summarize(meansAttendedC = mean(sAttendedC), varsAttendedC = var(sAttendedC),q1sAttendedC = quantile(sAttendedC, probs=.25), q2sAttendedC = quantile(sAttendedC, probs=.5), q3sAttendedC = quantile(sAttendedC, probs=.75),
            meansEngagedC = mean(sEngagedC), varsEngagedC = var(sEngagedC), q1sEngagedC = quantile(sEngagedC, probs=.25), q2sEngagedC = quantile(sEngagedC, probs=.5), q3sEngagedC = quantile(sEngagedC, probs=.75),
            meansHelpC = mean(sHelpC), varsHelpC = var(sHelpC), q1sHelpC = quantile(sHelpC, probs=.25), q2sHelpC = quantile(sHelpC, probs=.5), q3sHelpC = quantile(sHelpC, probs=.75),
            meansPreparedC = mean(sPreparedC), varsPreparedC = var(sPreparedC), q1sPreparedC = quantile(sPreparedC, probs=.25), q2sPreparedC = quantile(sPreparedC, probs=.5), q3sPreparedC = quantile(sPreparedC, probs=.75),
            meansPositiveC = mean(sPositiveC), varsPositiveC = var(sPositiveC), q1sPositiveC = quantile(sPositiveC, probs=.25), q2sPositiveC = quantile(sPositiveC, probs=.5), q3sPositiveC = quantile(sPositiveC, probs=.75), 
            meansUpToDateC = mean(sUpToDateC), varsUpToDateC = var(sUpToDateC), q1sUpToDateC = quantile(sUpToDateC, probs=.25), q2sUpToDateC = quantile(sUpToDateC, probs=.5), q3sUpToDateC = quantile(sUpToDateC, probs=.75) )

# Pivot Data
LBootstrapData <- BootstrapData %>% pivot_longer(cols=c(meansAttendedC,  meansEngagedC, meansHelpC , meansPreparedC,  meansPositiveC, meansUpToDateC),
                                        names_to='Variable1',
                                        values_to='Mean')
## Pivot again for variance
LBootstrapData <- LBootstrapData %>% pivot_longer(cols=c(varsAttendedC,  varsEngagedC, varsHelpC , varsPreparedC,  varsPositiveC, varsUpToDateC),
                                        names_to='Variable2',
                                        values_to='Variance') %>%
  
  select(Variable1, Variable2, Variance, Mean) %>%
  mutate(Variable_1 = str_replace(Variable1, "mean", ""),
         Variable_2 = str_replace(Variable2, "var", "")) %>%
  filter(Variable_2==Variable_1) %>%
  rename(Variable=Variable_1) %>%
  select(Variable, Mean, Variance) %>%
  mutate(x=c(1,2,3,4,5,6))




# Student Variables Average Coefficient Plot CourseType 2


quantiles <- quantile(abs(LBootstrapData$Mean), probs=c(.25, .75))


CT2splot <- ggplot(data=LBootstrapData, aes(y=abs(Mean), x=x)) +
  geom_point()  +
  geom_label_repel(aes(label=Variable)) +
  geom_errorbar(aes(ymin=Mean-sqrt(Variance), ymax=Mean+sqrt(Variance)), width=.3) +
  #geom_jitter(height=0, width=.5) +
  theme_minimal() +
  scale_x_continuous(breaks = (3.5),
                     minor_breaks= NULL,
                     labels=("Separation Factor"))+
  annotate("rect", xmin=0, xmax=7, ymin=0, ymax=quantiles[1], fill="red", alpha=.2) +
  annotate("rect", xmin=0, xmax=7, ymin=quantiles[1], ymax=quantiles[2], fill="yellow", alpha=.2) +
  annotate("rect", xmin=0, xmax=7, ymin=quantiles[2], ymax=.32, fill="green", alpha=.2) +
  #annotate('text', x=1.5, y=(quantiles[2]+.1), label="Top 25% of Coefficients", color='forestgreen') +
  #annotate('text', x=1.5, y=(quantiles[2]+.09), label="Middle 50% of Coefficients", color='yellow4') +
  #annotate('text', x=1.5, y=(quantiles[2]+.08), label="Bottom 25% of Coefficients", color='firebrick4') +
  labs(title="MKT Core Courses",
       x="",
       y="")




# CourseType 3, s vars

set.seed(09272024)

## Idea for full model
##full.modeli.1 <- lm(data=Teacher1Stdz, iRating ~ iAskQuesS + iAnalyProbS + iChallengedS + iConceptsS +iDemoS +iEnthusiasmS +iHoursS + iParticipateS + iPreparedS + iQuesEffectS + iStandardsS + iTopicS + iUnderstandS + iWelQuesS )
##summary(full.modeli.1)

## BOOTSRAPPING BY HAND

sample_coef_intercept <- NULL
sample_coef_df_x1 <- NULL
sample_coef_df_x2 <- NULL
sample_coef_df_x3 <- NULL
sample_coef_df_x4 <- NULL
sample_coef_df_x5 <- NULL
sample_coef_df_x6 <- NULL
sample_coef_df_x7 <- NULL


for (i in 1:1000) {
  #Creating a resampled dataset from the sample data
  sample_d = CTStdz_3[sample(1:nrow(CTStdz_3), nrow(CTStdz_3), replace = TRUE), ]
 # sample_d_totalcompleted <-  sample_d %>% summarize(totalcomp = sum(Completed))
  sample_d_w <- sample_d %>%
    mutate(weight = Completed/sum(Completed))
  
  #Running the regression on these data
  model_bootstrap  <- lmer(iRating ~ ((s_sAttended+ s_sEngaged+ s_sHelp+ s_sPrepared+ s_sPositive + s_sUpToDate) + (1 | eInstID)), weights=weight, data = sample_d_w)
  bootsum <- summary(model_bootstrap)
  
    #Saving the coefficients
  sample_coef_intercept <-
    c(sample_coef_intercept, bootsum$coefficients[1])
  
  sample_coef_df_x1 <- c(sample_coef_df_x1, bootsum$coefficients[2])
  sample_coef_df_x2 <- c(sample_coef_df_x2, bootsum$coefficients[3])
  sample_coef_df_x3 <- c(sample_coef_df_x3, bootsum$coefficients[4])
  sample_coef_df_x4 <- c(sample_coef_df_x4, bootsum$coefficients[5])
  sample_coef_df_x5 <- c(sample_coef_df_x5, bootsum$coefficients[6])
  sample_coef_df_x6 <- c(sample_coef_df_x6, bootsum$coefficients[7])
}

## Want ABSOLUTE values to show overall affect on iRating (-.3 has as much of an effect as .3)
absCoefsDF <- data.frame(sAttendedC=abs(sample_coef_df_x1), 
                      sEngagedC=abs(sample_coef_df_x2),
                      sHelpC=abs(sample_coef_df_x3),
                      sPreparedC=abs(sample_coef_df_x4),
                      sPositiveC=abs(sample_coef_df_x5),
                      sUpToDateC=abs(sample_coef_df_x6))

BootstrapData <- absCoefsDF %>%
  summarize(meansAttendedC = mean(sAttendedC), varsAttendedC = var(sAttendedC),q1sAttendedC = quantile(sAttendedC, probs=.25), q2sAttendedC = quantile(sAttendedC, probs=.5), q3sAttendedC = quantile(sAttendedC, probs=.75),
            meansEngagedC = mean(sEngagedC), varsEngagedC = var(sEngagedC), q1sEngagedC = quantile(sEngagedC, probs=.25), q2sEngagedC = quantile(sEngagedC, probs=.5), q3sEngagedC = quantile(sEngagedC, probs=.75),
            meansHelpC = mean(sHelpC), varsHelpC = var(sHelpC), q1sHelpC = quantile(sHelpC, probs=.25), q2sHelpC = quantile(sHelpC, probs=.5), q3sHelpC = quantile(sHelpC, probs=.75),
            meansPreparedC = mean(sPreparedC), varsPreparedC = var(sPreparedC), q1sPreparedC = quantile(sPreparedC, probs=.25), q2sPreparedC = quantile(sPreparedC, probs=.5), q3sPreparedC = quantile(sPreparedC, probs=.75),
            meansPositiveC = mean(sPositiveC), varsPositiveC = var(sPositiveC), q1sPositiveC = quantile(sPositiveC, probs=.25), q2sPositiveC = quantile(sPositiveC, probs=.5), q3sPositiveC = quantile(sPositiveC, probs=.75), 
            meansUpToDateC = mean(sUpToDateC), varsUpToDateC = var(sUpToDateC), q1sUpToDateC = quantile(sUpToDateC, probs=.25), q2sUpToDateC = quantile(sUpToDateC, probs=.5), q3sUpToDateC = quantile(sUpToDateC, probs=.75) )

# Pivot Data
LBootstrapData <- BootstrapData %>% pivot_longer(cols=c(meansAttendedC,  meansEngagedC, meansHelpC , meansPreparedC,  meansPositiveC, meansUpToDateC),
                                        names_to='Variable1',
                                        values_to='Mean')
## Pivot again for variance
LBootstrapData <- LBootstrapData %>% pivot_longer(cols=c(varsAttendedC,  varsEngagedC, varsHelpC , varsPreparedC,  varsPositiveC, varsUpToDateC),
                                        names_to='Variable2',
                                        values_to='Variance') %>%
  
  select(Variable1, Variable2, Variance, Mean) %>%
  mutate(Variable_1 = str_replace(Variable1, "mean", ""),
         Variable_2 = str_replace(Variable2, "var", "")) %>%
  filter(Variable_2==Variable_1) %>%
  rename(Variable=Variable_1) %>%
  select(Variable, Mean, Variance) %>%
  mutate(x=c(1,2,3,4,5,6))



# Student Variables Average Coefficient Plot CourseType 3

quantiles <- quantile(abs(LBootstrapData$Mean), probs=c(.25, .75))


CT3splot <- ggplot(data=LBootstrapData, aes(y=abs(Mean), x=x)) +
  geom_point()  +
  geom_label_repel(aes(label=Variable)) +
  geom_errorbar(aes(ymin=Mean-sqrt(Variance), ymax=Mean+sqrt(Variance)), width=.3) +
  #geom_jitter(height=0, width=.5) +
  theme_minimal() +
  scale_x_continuous(breaks = (3.5),
                     minor_breaks= NULL,
                     labels=("Separation Factor"))+
  annotate("rect", xmin=0, xmax=7, ymin=0, ymax=quantiles[1], fill="red", alpha=.2) +
  annotate("rect", xmin=0, xmax=7, ymin=quantiles[1], ymax=quantiles[2], fill="yellow", alpha=.2) +
  annotate("rect", xmin=0, xmax=7, ymin=quantiles[2], ymax=.32, fill="green", alpha=.2) +
  #annotate('text', x=.5, y=(quantiles[2]-.05), label="Top 25% of Coefficients", color='forestgreen') +
  #annotate('text', x=.5, y=(quantiles[2]-.04), label="Middle 50% of Coefficients", color='yellow4') +
  #annotate('text', x=.5, y=(quantiles[2]-.03), label="Bottom 25% of Coefficients", color='firebrick4') +
  labs(title="MKT Elective Courses",
       x="",
       y="")



# CourseType 4, s vars
set.seed(09272024)

## Idea for full model
##full.modeli.1 <- lm(data=Teacher1Stdz, iRating ~ iAskQuesS + iAnalyProbS + iChallengedS + iConceptsS +iDemoS +iEnthusiasmS +iHoursS + iParticipateS + iPreparedS + iQuesEffectS + iStandardsS + iTopicS + iUnderstandS + iWelQuesS )
##summary(full.modeli.1)

## BOOTSRAPPING BY HAND

sample_coef_intercept <- NULL
sample_coef_df_x1 <- NULL
sample_coef_df_x2 <- NULL
sample_coef_df_x3 <- NULL
sample_coef_df_x4 <- NULL
sample_coef_df_x5 <- NULL
sample_coef_df_x6 <- NULL
sample_coef_df_x7 <- NULL


for (i in 1:1000) {
  #Creating a resampled dataset from the sample data
  sample_d = CTStdz_4[sample(1:nrow(CTStdz_4), nrow(CTStdz_4), replace = TRUE), ]
 # sample_d_totalcompleted <-  sample_d %>% summarize(totalcomp = sum(Completed))
  sample_d_w <- sample_d %>%
    mutate(weight = Completed/sum(Completed))
  
  #Running the regression on these data
  model_bootstrap  <- lmer(iRating ~ ((s_sAttended+ s_sEngaged+ s_sHelp+ s_sPrepared+ s_sPositive + s_sUpToDate) + (1 | eInstID)), weights=weight, data = sample_d_w)
  bootsum <- summary(model_bootstrap)
  
    #Saving the coefficients
  sample_coef_intercept <-
    c(sample_coef_intercept, bootsum$coefficients[1])
  
  sample_coef_df_x1 <- c(sample_coef_df_x1, bootsum$coefficients[2])
  sample_coef_df_x2 <- c(sample_coef_df_x2, bootsum$coefficients[3])
  sample_coef_df_x3 <- c(sample_coef_df_x3, bootsum$coefficients[4])
  sample_coef_df_x4 <- c(sample_coef_df_x4, bootsum$coefficients[5])
  sample_coef_df_x5 <- c(sample_coef_df_x5, bootsum$coefficients[6])
  sample_coef_df_x6 <- c(sample_coef_df_x6, bootsum$coefficients[7])
}

## Want ABSOLUTE values to show overall affect on iRating (-.3 has as much of an effect as .3)
absCoefsDF <- data.frame(sAttendedC=abs(sample_coef_df_x1), 
                      sEngagedC=abs(sample_coef_df_x2),
                      sHelpC=abs(sample_coef_df_x3),
                      sPreparedC=abs(sample_coef_df_x4),
                      sPositiveC=abs(sample_coef_df_x5),
                      sUpToDateC=abs(sample_coef_df_x6))

BootstrapData <- absCoefsDF %>%
  summarize(meansAttendedC = mean(sAttendedC), varsAttendedC = var(sAttendedC),q1sAttendedC = quantile(sAttendedC, probs=.25), q2sAttendedC = quantile(sAttendedC, probs=.5), q3sAttendedC = quantile(sAttendedC, probs=.75),
            meansEngagedC = mean(sEngagedC), varsEngagedC = var(sEngagedC), q1sEngagedC = quantile(sEngagedC, probs=.25), q2sEngagedC = quantile(sEngagedC, probs=.5), q3sEngagedC = quantile(sEngagedC, probs=.75),
            meansHelpC = mean(sHelpC), varsHelpC = var(sHelpC), q1sHelpC = quantile(sHelpC, probs=.25), q2sHelpC = quantile(sHelpC, probs=.5), q3sHelpC = quantile(sHelpC, probs=.75),
            meansPreparedC = mean(sPreparedC), varsPreparedC = var(sPreparedC), q1sPreparedC = quantile(sPreparedC, probs=.25), q2sPreparedC = quantile(sPreparedC, probs=.5), q3sPreparedC = quantile(sPreparedC, probs=.75),
            meansPositiveC = mean(sPositiveC), varsPositiveC = var(sPositiveC), q1sPositiveC = quantile(sPositiveC, probs=.25), q2sPositiveC = quantile(sPositiveC, probs=.5), q3sPositiveC = quantile(sPositiveC, probs=.75), 
            meansUpToDateC = mean(sUpToDateC), varsUpToDateC = var(sUpToDateC), q1sUpToDateC = quantile(sUpToDateC, probs=.25), q2sUpToDateC = quantile(sUpToDateC, probs=.5), q3sUpToDateC = quantile(sUpToDateC, probs=.75) )

# Pivot Data
LBootstrapData <- BootstrapData %>% pivot_longer(cols=c(meansAttendedC,  meansEngagedC, meansHelpC , meansPreparedC,  meansPositiveC, meansUpToDateC),
                                        names_to='Variable1',
                                        values_to='Mean')
## Pivot again for variance
LBootstrapData <- LBootstrapData %>% pivot_longer(cols=c(varsAttendedC,  varsEngagedC, varsHelpC , varsPreparedC,  varsPositiveC, varsUpToDateC),
                                        names_to='Variable2',
                                        values_to='Variance') %>%
  
  select(Variable1, Variable2, Variance, Mean) %>%
  mutate(Variable_1 = str_replace(Variable1, "mean", ""),
         Variable_2 = str_replace(Variable2, "var", "")) %>%
  filter(Variable_2==Variable_1) %>%
  rename(Variable=Variable_1) %>%
  select(Variable, Mean, Variance) %>%
  mutate(x=c(1,2,3,4,5,6))




# Student Variables Average Coefficient Plot CourseType 4

quantiles <- quantile(abs(LBootstrapData$Mean), probs=c(.25, .75))


CT4splot <- ggplot(data=LBootstrapData, aes(y=abs(Mean), x=x)) +
  geom_point()  +
  geom_label_repel(aes(label=Variable)) +
  geom_errorbar(aes(ymin=Mean-sqrt(Variance), ymax=Mean+sqrt(Variance)), width=.3) +
  #geom_jitter(height=0, width=.5) +
  theme_minimal() +
  scale_x_continuous(breaks = (3.5),
                     minor_breaks= NULL,
                     labels=("Separation Factor"))+
  annotate("rect", xmin=0, xmax=7, ymin=0, ymax=quantiles[1], fill="red", alpha=.2) +
  annotate("rect", xmin=0, xmax=7, ymin=quantiles[1], ymax=quantiles[2], fill="yellow", alpha=.2) +
  annotate("rect", xmin=0, xmax=7, ymin=quantiles[2], ymax=.32, fill="green", alpha=.2) +
  #annotate('text', x=3.5, y=(quantiles[2]+.1), label="Top 25% of Coefficients", color='forestgreen') +
  #annotate('text', x=3.5, y=(quantiles[2]+.09), label="Middle 50% of Coefficients", color='yellow4') +
 # annotate('text', x=3.5, y=(quantiles[2]+.08), label="Bottom 25% of Coefficients", color='firebrick4') +
  labs(title="MKT Capstone Courses",
       y="Average of Absolute Value of Beta Coefficients of Standardized Questions",
       x="Values do not Matter, Just here to Separate Coefficeint Averages")



## Plot all S

par(mfrow=c(2,2))
CT1splot
CT2splot
CT3splot
CT4splot



## Model looking into course type as predictor


# Mixed-effects model with CourseType as a predictor
model_full <- lmer(iRating ~ CourseType + 
                    (s_iAnalyProb + s_iAskQues + s_iChallenged + s_iConcepts + s_iDemo +
                     s_iEnthusiasm + s_iHours + s_iParticipate + s_iPrepared + s_iQuesEffect +
                     s_iStandards + s_iTopic + s_iUnderstand + s_iWelQues) + 
                     (1 | eInstID), 
                  weights = weights, 
                  data = CTStdz_all)
#summary(model_full)
# Extract model summary as a tidy table
tidy_model <- broom.mixed::tidy(model_full)

# Create a clean table using gt
tidy_model %>%
  gt() %>%
  tab_header(
    title = "Course Type Model Summary",
    subtitle = "Detailed output of the fixed effects"
  ) %>%
  fmt_number(
    columns = vars(estimate, std.error, statistic, p.value),
    decimals = 3
  ) %>%
  cols_label(
    term = "Predictor",
    estimate = "Estimate",
    std.error = "Std. Error",
    statistic = "t-Value",
    p.value = "P-Value"
  )


# Set seed for reproducibility
set.seed(09272024)

# Initialize empty lists to store coefficients for each predictor
sample_coef_intercept <- NULL
sample_coef_df_course_type2 <- NULL  # For CourseType
sample_coef_df_course_type3 <- NULL  # For CourseType
sample_coef_df_course_type4 <- NULL  # For CourseType
sample_coef_df_x1 <- NULL
sample_coef_df_x2 <- NULL
sample_coef_df_x3 <- NULL
sample_coef_df_x4 <- NULL
sample_coef_df_x5 <- NULL
sample_coef_df_x6 <- NULL
sample_coef_df_x7 <- NULL
sample_coef_df_x8 <- NULL
sample_coef_df_x9 <- NULL
sample_coef_df_x10 <- NULL
sample_coef_df_x11 <- NULL
sample_coef_df_x12 <- NULL
sample_coef_df_x13 <- NULL
sample_coef_df_x14 <- NULL
sample_coef_df_x15 <- NULL
sample_coef_df_x16 <- NULL
sample_coef_df_x17 <- NULL
sample_coef_df_x18 <- NULL
sample_coef_df_x19 <- NULL
sample_coef_df_x20 <- NULL
sample_coef_df_x21 <- NULL
sample_coef_df_x22 <- NULL
sample_coef_df_x23 <- NULL
sample_coef_df_x24 <- NULL

 

# Bootstrapping loop (1000 iterations)
for (i in 1:1000) {
  # Resample the dataset with replacement
  sample_d <- CTStdz_all[sample(1:nrow(CTStdz_all), nrow(CTStdz_all), replace = TRUE), ]
  
  # Compute weights based on the 'Completed' variable
  sample_d_w <- sample_d %>%
    mutate(weight = Completed / sum(Completed))
  
  # Fit the linear mixed model with CourseType as a predictor
  model_bootstrap <- lmer(iRating ~ CourseType + 
                            (s_iAnalyProb + s_iAskQues + s_iChallenged + s_iConcepts + s_iDemo + 
                             s_iEnthusiasm + s_iHours + s_iParticipate + s_iPrepared + 
                             s_iQuesEffect + s_iStandards + s_iTopic + s_iUnderstand + 
                             s_iWelQues + s_sAttended + s_sEngaged + s_sHelp + s_sPrepared
                             + s_sPositive + s_sUpToDate) + (1 | eInstID), 
                           weights = weight, data = sample_d_w)
  
  # Extract coefficients
  bootsum <- summary(model_bootstrap)
  
  # Save the coefficients for each variable
  sample_coef_intercept <- c(sample_coef_intercept, bootsum$coefficients[1])
  sample_coef_df_course_type2 <- c(sample_coef_df_course_type2, bootsum$coefficients[2])  # CourseType
  sample_coef_df_course_type3 <- c(sample_coef_df_course_type3, bootsum$coefficients[3])  # CourseType
  sample_coef_df_course_type4 <- c(sample_coef_df_course_type4, bootsum$coefficients[4])  # CourseType
  sample_coef_df_x1 <- c(sample_coef_df_x1, bootsum$coefficients[5])
  sample_coef_df_x2 <- c(sample_coef_df_x2, bootsum$coefficients[6])
  sample_coef_df_x3 <- c(sample_coef_df_x3, bootsum$coefficients[7])
  sample_coef_df_x4 <- c(sample_coef_df_x4, bootsum$coefficients[8])
  sample_coef_df_x5 <- c(sample_coef_df_x5, bootsum$coefficients[9])
  sample_coef_df_x6 <- c(sample_coef_df_x6, bootsum$coefficients[10])
  sample_coef_df_x7 <- c(sample_coef_df_x7, bootsum$coefficients[11])
  sample_coef_df_x8 <- c(sample_coef_df_x8, bootsum$coefficients[12])
  sample_coef_df_x9 <- c(sample_coef_df_x9, bootsum$coefficients[13])
  sample_coef_df_x10 <- c(sample_coef_df_x10, bootsum$coefficients[14])
  sample_coef_df_x11 <- c(sample_coef_df_x11, bootsum$coefficients[15])
  sample_coef_df_x12 <- c(sample_coef_df_x12, bootsum$coefficients[16])
  sample_coef_df_x13 <- c(sample_coef_df_x13, bootsum$coefficients[17])
  sample_coef_df_x14 <- c(sample_coef_df_x14, bootsum$coefficients[18])
  sample_coef_df_x15 <- c(sample_coef_df_x15, bootsum$coefficients[19])
  sample_coef_df_x16 <- c(sample_coef_df_x16, bootsum$coefficients[20])
  sample_coef_df_x17 <- c(sample_coef_df_x17, bootsum$coefficients[21])
  sample_coef_df_x18 <- c(sample_coef_df_x18, bootsum$coefficients[22])
  sample_coef_df_x19 <- c(sample_coef_df_x19, bootsum$coefficients[23])
  sample_coef_df_x20 <- c(sample_coef_df_x20, bootsum$coefficients[24])
}

# Create a data frame with absolute coefficients to represent their magnitude
absCoefsDF <- data.frame(
  CourseType2 = abs(sample_coef_df_course_type2),  # CourseType effect
  CourseType3 = abs(sample_coef_df_course_type3),  # CourseType effect
  CourseType4 = abs(sample_coef_df_course_type4),  # CourseType effect
  iAnalyProbC = abs(sample_coef_df_x1), 
  iAskQuesC = abs(sample_coef_df_x2),
  iChallengedC = abs(sample_coef_df_x3),
  iConceptsC = abs(sample_coef_df_x4),
  iDemoC = abs(sample_coef_df_x5),
  iEnthusiasmC = abs(sample_coef_df_x6),
  iHoursC = abs(sample_coef_df_x7),
  iParticipateC = abs(sample_coef_df_x8),
  iPreparedC = abs(sample_coef_df_x9),
  iQuesEffectC = abs(sample_coef_df_x10),
  iStandardsC = abs(sample_coef_df_x11),
  iTopicC = abs(sample_coef_df_x12),
  iUnderstandC = abs(sample_coef_df_x13),
  iWelQuesC = abs(sample_coef_df_x14),
  sAttendedC = abs(sample_coef_df_x15),
  sEngagedC = abs(sample_coef_df_x16),
  sHelpC = abs(sample_coef_df_x17),
  sPreparedC = abs(sample_coef_df_x18),
  sPositiveC = abs(sample_coef_df_x19),
  sUpToDateC = abs(sample_coef_df_x20))



# Step 1: Summarize the bootstrapped coefficients as you did before
BootstrapData <- absCoefsDF %>%
  summarize(
    meanCourseType2 = mean(CourseType2), varCourseType2 = var(CourseType2), 
    meanCourseType3 = mean(CourseType3), varCourseType3 = var(CourseType3), 
    meanCourseType4 = mean(CourseType4), varCourseType4 = var(CourseType4), 
    meaniAnalyProbC = mean(iAnalyProbC), variAnalyProbC = var(iAnalyProbC), 
    meaniAskQuesC = mean(iAskQuesC), variAskQuesC = var(iAskQuesC), 
    meaniChallengedC = mean(iChallengedC), variChallengedC = var(iChallengedC), 
    meaniConceptsC = mean(iConceptsC), variConceptsC = var(iConceptsC), 
    meaniDemoC = mean(iDemoC), variDemoC = var(iDemoC), 
    meaniEnthusiasmC = mean(iEnthusiasmC), variEnthusiasmC = var(iEnthusiasmC), 
    meaniHoursC = mean(iHoursC), variHoursC = var(iHoursC), 
    meaniParticipateC = mean(iParticipateC), variParticipateC = var(iParticipateC), 
    meaniPreparedC = mean(iPreparedC), variPreparedC = var(iPreparedC), 
    meaniQuesEffectC = mean(iQuesEffectC), variQuesEffectC = var(iQuesEffectC), 
    meaniStandardsC = mean(iStandardsC), variStandardsC = var(iStandardsC), 
    meaniTopicC = mean(iTopicC), variTopicC = var(iTopicC), 
    meaniUnderstandC = mean(iUnderstandC), variUnderstandC = var(iUnderstandC), 
    meaniWelQuesC = mean(iWelQuesC), variWelQuesC = var(iWelQuesC),
    meansAttendedC = mean(sAttendedC), varsAttendedC = var(sAttendedC), 
    meansEngagedC = mean(sEngagedC), varsEngagedC = var(sEngagedC), 
    meansHelpC = mean(sHelpC), varsHelpC = var(sHelpC), 
    meansPreparedC = mean(sPreparedC), varsPreparedC = var(sPreparedC), 
    meansPositiveC = mean(sPositiveC), varsPositiveC = var(sPositiveC), 
    meansUpToDateC = mean(sUpToDateC), varsUpToDateC = var(sUpToDateC)
  )


# Pivot Data
LBootstrapData <- BootstrapData%>% pivot_longer(cols=c(meanCourseType2, meanCourseType3, meanCourseType4, meaniAnalyProbC,  meaniAskQuesC, meaniChallengedC , meaniConceptsC,  meaniDemoC, meaniEnthusiasmC, meaniHoursC, meaniParticipateC, meaniPreparedC, meaniQuesEffectC, meaniStandardsC, meaniTopicC, meaniUnderstandC, meaniWelQuesC, meansAttendedC, meansEngagedC, meansHelpC, meansPreparedC, meansPositiveC, meansUpToDateC),
                                        names_to='Variable1',
                                        values_to='Mean')
## Pivot again for variance
LBootstrapData <- LBootstrapData %>% pivot_longer(cols=c(varCourseType2, varCourseType3, varCourseType4, variAnalyProbC, variAskQuesC,  variChallengedC ,  variConceptsC, variDemoC, variEnthusiasmC, variHoursC, variParticipateC, variPreparedC, variQuesEffectC, variStandardsC, variTopicC , variUnderstandC, variWelQuesC, varsAttendedC, varsEngagedC, varsHelpC, varsPreparedC, varsPositiveC, varsUpToDateC),
                                        names_to='Variable2',
                                        values_to='Variance') %>%
  
  select(Variable1, Variable2, Variance, Mean) %>%
  mutate(Variable_1 = str_replace(Variable1, "mean", ""),
         Variable_2 = str_replace(Variable2, "var", "")) %>%
  filter(Variable_2==Variable_1) %>%
  rename(Variable=Variable_1) %>%
  select(Variable, Mean, Variance) %>%
  mutate(x=c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23))


# Step 4: Calculate quantiles for highlighting
quantiles <- quantile(abs(LBootstrapData$Mean), probs = c(0.25, 0.75))

# Step 5: Create the plot
CTplot <- ggplot(data = LBootstrapData, aes(y = abs(Mean), x = x)) +
  geom_point() +
  geom_label_repel(aes(label = Variable)) +
  geom_errorbar(aes(ymin=Mean-sqrt(Variance), ymax=Mean+sqrt(Variance)), width=.3) +
  theme_minimal() +
  
  # Customize the x-axis
  scale_x_continuous(breaks = (3.5), 
                     minor_breaks = NULL, 
                     labels = ("Separation Factor")) +
  
  # Adding colored regions based on quantiles
  annotate("rect", xmin = 0, xmax = 24, ymin = 0, ymax = quantiles[1], fill = "red", alpha = 0.2) +
  annotate("rect", xmin = 0, xmax = 24, ymin = quantiles[1], ymax = quantiles[2], fill = "yellow", alpha = 0.2) +
  annotate("rect", xmin = 0, xmax = 24, ymin = max(quantiles[2]), ymax = max(abs(LBootstrapData$Mean)), fill = "green", alpha = 0.2) +
  annotate('text', x=10.5, y=(quantiles[2]+.1), label="Top 25% of Coefficients", color='forestgreen') +
  annotate('text', x=10.5, y=(quantiles[2]+.09), label="Middle 50% of Coefficients", color='yellow4') +
  annotate('text', x=10.5, y=(quantiles[2]+.08), label="Bottom 25% of Coefficients", color='firebrick4') +
  
  # Adding labels and titles
  labs(title = 'Beta Coefficient Averages of Standardized Variables',
       subtitle = 'Variables with the highest average absolute value of their beta coefficients\n have the largest effect on teacher ratings when all variables are treated on the same scale',
       y = "Average of Absolute Value of Beta Coefficients",
       x = "Values do not Matter, Just here to Separate Coefficients")

# Step 6: Display the plot
CTplot


# Install lmerTest if you haven't already
#install.packages("lmerTest")


# Define your full mixed-effects model
model_full1 <- lmer(iRating ~ CourseType + 
                   (s_iAnalyProb + s_iAskQues + s_iChallenged + s_iConcepts + s_iDemo +
                    s_iEnthusiasm + s_iHours + s_iParticipate + s_iPrepared + s_iQuesEffect +
                    s_iStandards + s_iTopic + s_iUnderstand + s_iWelQues+s_sAttended+s_sEngaged+s_sHelp+s_sPrepared+s_sPositive+s_sUpToDate) + 
                    (1 | eInstID), 
                   weights = weights, 
                   data = CTStdz_all)
# Perform stepwise model selection
# Output the summary of the stepwise-selected model
#summary(stepwise_model)
# Perform stepwise selection on the mixed-effects model
stepwise_model <- step(model_full1, direction="forward")

# Check the components of stepwise_model to understand the structure
# print(names(stepwise_model))

# Extract the final selected model
final_model <- stepwise_model$finalModel  # Adjust this if the name is different

# Output the summary of the final model
#summary(final_model)
#print(stepwise_model)


# Refit the final model after stepwise selection
final_model <- lmer(iRating ~ CourseType + s_iAnalyProb + s_iChallenged + s_iDemo + s_iEnthusiasm + s_iPrepared + s_iQuesEffect + s_iTopic + s_iWelQues + s_sEngaged + s_sHelp + (1 | eInstID),
                    weights = weights, 
                    data = CTStdz_all)


# Extract model summary as a tidy table
tidy_model <- broom.mixed::tidy(final_model)

# Create a clean table using gt
tidy_model %>%
  gt() %>%
  tab_header(
    title = "Final Model Summary",
    subtitle = "Detailed output of the fixed effects"
  ) %>%
  fmt_number(
    columns = vars(estimate, std.error, statistic, p.value),
    decimals = 3
  ) %>%
  cols_label(
    term = "Predictor",
    estimate = "Estimate",
    std.error = "Std. Error",
    statistic = "t-Value",
    p.value = "P-Value"
  )


```